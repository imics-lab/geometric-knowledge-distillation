{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import math\n",
        "from typing import Dict, List, Tuple\n",
        "import time"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1741300162830
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SkeletonDataset(Dataset):\n",
        "    def __init__(self, data_path, split):\n",
        "        self.X = np.load(os.path.join(data_path, f'X_{split}.npy'))\n",
        "        self.y = np.load(os.path.join(data_path, f'y_{split}.npy'))\n",
        "        self.X = self.X.reshape(self.X.shape[0], self.X.shape[2], self.X.shape[1])\n",
        "        self.y = np.where(self.y == 27, 0, self.y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long)\n",
        "\n",
        "def get_dataloader(data_path, split, batch_size):\n",
        "    dataset = SkeletonDataset(data_path, split)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Create train, validation, and test loaders\n",
        "def get_all_dataloaders(data_path, batch_size):\n",
        "    train_loader = get_dataloader(data_path, 'train', batch_size)\n",
        "    test_loader = get_dataloader(data_path, 'test', batch_size)\n",
        "    return train_loader, test_loader\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1741300162951
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistillationNPYDataset(Dataset):\n",
        "    \"\"\"Dataset that loads precomputed skeleton data from separate .npy files and includes DTW distances.\"\"\"\n",
        "    def __init__(self, folder: str, split: str, dtw_distances: np.ndarray):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            folder (str): Path to the folder containing .npy files.\n",
        "            split (str): One of ['train', 'val', 'test'] to load the corresponding dataset.\n",
        "            dtw_distances (np.ndarray): Precomputed DTW distance matrix.\n",
        "        \"\"\"\n",
        "        self.X = np.load(os.path.join(folder, f'X_{split}.npy'))  # Load features\n",
        "        self.y = np.load(os.path.join(folder, f'y_{split}.npy'))  # Load labels\n",
        "        print(self.X.shape)\n",
        "        self.dtw_distances = dtw_distances\n",
        "        self.X = self.X.reshape(self.X.shape[0], self.X.shape[2], self.X.shape[1])\n",
        "        self.y = np.where(self.y == 27, 0, self.y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx: int):\n",
        "               \n",
        "        sample = {\n",
        "            'X': torch.tensor(self.X[idx], dtype=torch.float32),  \n",
        "            'y': torch.tensor(self.y[idx], dtype=torch.long),    \n",
        "            'dtw_distances': torch.tensor(self.dtw_distances[idx], dtype=torch.float32)\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "def get_distillation_dataloader_from_folder(folder: str, dtw_distances: np.ndarray, \n",
        "                                            batch_size: int = 16, shuffle: bool = False, \n",
        "                                            num_workers: int = 4):\n",
        "    \"\"\"Creates dataloaders from a given folder with precomputed NPY data and DTW distances.\"\"\"\n",
        "    \n",
        "    train_dataset = DistillationNPYDataset(folder, 'train', dtw_distances)\n",
        "    test_dataset = DistillationNPYDataset(folder, 'test', dtw_distances)\n",
        "    \n",
        "    def distillation_collate(batch):\n",
        "        \"\"\"Custom collate function for batches with DTW distances.\"\"\"\n",
        "        X = torch.stack([item['X'] for item in batch])\n",
        "        y = torch.tensor([item['y'] for item in batch])\n",
        "        dtw_distances = torch.tensor(np.stack([item['dtw_distances'] for item in batch]))\n",
        "        return {'X': X, 'y': y, 'dtw_distances': dtw_distances}\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, \n",
        "                              num_workers=num_workers, collate_fn=distillation_collate)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, \n",
        "                             num_workers=num_workers, collate_fn=distillation_collate)\n",
        "    \n",
        "    return train_loader, test_loader\n",
        "    \n",
        "def compute_teacher_probabilities(dtw_distances: torch.Tensor, \n",
        "                                train_labels: torch.Tensor,\n",
        "                                num_classes: int, \n",
        "                                temperature: float = 1.0) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute soft probability distributions from DTW distances\n",
        "    Args:\n",
        "        dtw_distances: tensor of shape (batch_size, num_training_examples)\n",
        "        train_labels: tensor of shape (num_training_examples) with class labels of all training examples\n",
        "        num_classes: total number of classes\n",
        "        temperature: temperature parameter for softening distributions\n",
        "    Returns:\n",
        "        soft probabilities of shape (batch_size, num_classes)\n",
        "    \"\"\"\n",
        "    # Convert distances to similarities (negative distances)\n",
        "    similarities = -dtw_distances / temperature\n",
        "    # Apply softmax to get example-wise probabilities\n",
        "    example_probs = F.softmax(similarities, dim=1)  # (batch_size, num_training_examples)\n",
        "    # Initialize class probabilities tensor\n",
        "    batch_size = dtw_distances.shape[0]\n",
        "    class_probs = torch.zeros(batch_size, num_classes, device=dtw_distances.device)\n",
        "    # For each class, sum the probabilities of examples belonging to that class\n",
        "    for i in range(num_classes):\n",
        "        class_indices = (train_labels == i).nonzero(as_tuple=True)[0]\n",
        "        if len(class_indices) > 0:\n",
        "            # Sum (not mean) probabilities of all examples of this class\n",
        "            class_probs[:, i] = example_probs[:, class_indices].sum(dim=1)\n",
        "    # Re-normalize to ensure proper probability distribution\n",
        "    # This is necessary because we're summing probabilities across examples\n",
        "    class_probs = class_probs / (class_probs.sum(dim=1, keepdim=True) + 1e-8)\n",
        "    return class_probs\n",
        "# def compute_teacher_probabilities(dtw_distances: torch.Tensor, y:torch.Tensor,\n",
        "#                                 num_classes:int, temperature: float = 1.0) -> torch.Tensor:\n",
        "#     \"\"\"\n",
        "#     Compute soft probability distributions from DTW distances\n",
        "#     Args:\n",
        "#         dtw_distances: tensor of shape (batch_size, num_training_examples)\n",
        "#         temperature: temperature parameter for softening distributions\n",
        "#     Returns:\n",
        "#         soft probabilities of shape (batch_size, num_classes)\n",
        "#     \"\"\"\n",
        "#     # Convert distances to similarities (negative distances)\n",
        "#     similarities = -dtw_distances / temperature\n",
        "#     class_similarity = torch.zeros(dtw_distances.shape[0], num_classes, device=dtw_distances.device)\n",
        "#     for i in range(num_classes):\n",
        "#         class_indices = (y == i).nonzero(as_tuple=True)[0]\n",
        "#         if len(class_indices) > 0:  # Avoid division by zero if there are no samples for the class\n",
        "#             class_similarity[:, i] = similarities[:, class_indices].mean(dim=1)\n",
        "#         # class_mask = (y == i).unsqueeze(1)  # Shape: (batch_size, 1)\n",
        "        \n",
        "#         # # For the current class, calculate the mean similarity over the relevant samples\n",
        "#         # # The `class_mask` is broadcasted to the shape of the similarities tensor\n",
        "#         # class_similarity[:, i] = (similarities * class_mask.float()).sum(dim=1) / class_mask.sum(dim=1).float()\n",
        "\n",
        "    \n",
        "#     # Apply softmax to get probabilities\n",
        "#     probabilities = F.softmax(class_similarity, dim=1)\n",
        "    \n",
        "#     return probabilities\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1741300163084
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, num_heads=8, num_layers=4, hidden_dim=256, dropout=0.1):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        # Transformer encoder layer\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=input_dim,  # Input dimension (features per frame)\n",
        "            nhead=num_heads,    # Number of attention heads\n",
        "            dim_feedforward=hidden_dim,  # Feedforward hidden layer size\n",
        "            dropout=dropout\n",
        "        )\n",
        "        \n",
        "        # Stacked transformer encoder\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layers, num_layers=num_layers\n",
        "        )\n",
        "        \n",
        "        # Classifier head\n",
        "        self.fc = nn.Linear(input_dim, num_classes)  # Final layer to output class probabilities\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch_size, time_steps, features)\n",
        "        \"\"\"\n",
        "        # Transformer expects input of shape (sequence_length, batch_size, input_dim)\n",
        "        x = x.permute(1, 0, 2)  # Shape: (time_steps, batch_size, features)\n",
        "        \n",
        "        # Apply transformer encoder\n",
        "        transformer_out = self.transformer_encoder(x)\n",
        "        \n",
        "        # We take the output of the last time step (or average pooling across time)\n",
        "        # For simplicity, let's use the last time step output (as a representation of the sequence)\n",
        "        x = transformer_out[-1, :, :]  # Shape: (batch_size, features)\n",
        "        \n",
        "        # Classifier head to predict the class\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1741300163247
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EnhancedTransformerClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, num_heads=8, num_layers=6, hidden_dim=512, dropout=0.2):\n",
        "        super(EnhancedTransformerClassifier, self).__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        # Transformer encoder layer with more depth, hidden layers, and dropout\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=input_dim,  # Input dimension (features per frame)\n",
        "            nhead=num_heads,    # Number of attention heads\n",
        "            dim_feedforward=hidden_dim,  # Feedforward hidden layer size\n",
        "            dropout=dropout\n",
        "        )\n",
        "        \n",
        "        # Stacked transformer encoder with more layers (increased depth)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layers, num_layers=num_layers\n",
        "        )\n",
        "        \n",
        "        # Use global average pooling instead of just the last time step output\n",
        "        self.pooling = nn.AdaptiveAvgPool1d(1)  # Global average pooling across the time dimension\n",
        "        \n",
        "        # Classifier head\n",
        "        self.fc = nn.Linear(input_dim, num_classes)  # Final layer to output class probabilities\n",
        "        \n",
        "        # Dropout for regularization\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        # Layer Normalization for better training\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch_size, time_steps, features)\n",
        "        \"\"\"\n",
        "        # Transformer expects input of shape (sequence_length, batch_size, input_dim)\n",
        "        x = x.permute(1, 0, 2)  # Shape: (time_steps, batch_size, features)\n",
        "        \n",
        "        # Apply transformer encoder\n",
        "        transformer_out = self.transformer_encoder(x)\n",
        "        \n",
        "        # Global average pooling (across time_steps)\n",
        "        x = transformer_out.mean(dim=0)  # Shape: (batch_size, features)\n",
        "        \n",
        "        # Alternatively, we could also try adaptive pooling\n",
        "        # x = self.pooling(transformer_out.permute(1, 2, 0)).squeeze(-1)  # Apply global average pooling\n",
        "        \n",
        "        # Layer normalization for better stability\n",
        "        x = self.layer_norm(x)\n",
        "        \n",
        "        # Dropout to regularize the output\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        # Classifier head to predict the class\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1741300163407
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_total_Y_distil(loader):\n",
        "    all_Y = []\n",
        "    for batch in loader:  # Iterate through the batches in the loader\n",
        "        Y_batch = batch['y']  # Extract 'y' from each batch\n",
        "        all_Y.append(Y_batch)\n",
        "    \n",
        "    total_Y = torch.cat(all_Y, dim=0)  # Concatenate all 'y' labels along the batch dimension\n",
        "    return total_Y\n",
        "\n",
        "def distillation_train_model(model: nn.Module, \n",
        "                           train_loader: DataLoader,\n",
        "                           device: torch.device,\n",
        "                           alpha: float = 0.5,\n",
        "                           beta: float = 0.5, \n",
        "                           temperature: float = 3.0,\n",
        "                           epochs: int = 10,\n",
        "                           lr: float = 1e-4) -> Dict:\n",
        "    \"\"\"\n",
        "    Train model using knowledge distillation\n",
        "    Args:\n",
        "        model: student model to be trained\n",
        "        train_loader: training data loader with DTW distances\n",
        "        val_loader: validation data loader\n",
        "        device: device to train on\n",
        "        alpha: weight for cross-entropy loss\n",
        "        beta: weight for KL divergence loss\n",
        "        temperature: temperature for softening distributions\n",
        "        epochs: number of training epochs\n",
        "        lr: learning rate\n",
        "    Returns:\n",
        "        training history\n",
        "    \"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    model.to(device)\n",
        "    \n",
        "    # Lists to store metrics\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    \n",
        "    train_y = get_total_Y_distil(train_loader)\n",
        "    num_classes = 27 #len(set([item['y'] for item in train_loader.dataset]))  # Number of unique glosses\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]',\n",
        "                         file=sys.stdout, leave=True)\n",
        "        \n",
        "        for batch in train_pbar:\n",
        "            X_batch = batch['X'].to(device)\n",
        "            y_batch = batch['y'].to(device)\n",
        "            dtw_distances = batch['dtw_distances'].to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Student predictions\n",
        "            student_logits = model(X_batch)\n",
        "            student_probs = F.softmax(student_logits / temperature, dim=1)\n",
        "            \n",
        "            # Teacher probabilities from DTW distances\n",
        "            teacher_probs = compute_teacher_probabilities(\n",
        "                dtw_distances, train_y, num_classes, temperature).to(device) \n",
        "            # Compute losses\n",
        "            ce_loss = criterion(student_logits, y_batch)\n",
        "            kl_loss = F.kl_div(\n",
        "                F.log_softmax(student_logits / temperature, dim=1),\n",
        "                teacher_probs,\n",
        "                reduction='batchmean'\n",
        "            ) * (temperature ** 2)\n",
        "            \n",
        "            # Combined loss\n",
        "            loss = alpha * ce_loss + beta * kl_loss\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            # Compute accuracy\n",
        "            _, predicted = torch.max(student_logits, 1)\n",
        "            total += y_batch.size(0)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            \n",
        "            epoch_loss = running_loss / (train_pbar.n + 1)\n",
        "            epoch_acc = 100 * correct / total\n",
        "            \n",
        "            train_pbar.set_postfix({\n",
        "                'loss': f'{epoch_loss:.4f}',\n",
        "                'acc': f'{epoch_acc:.2f}%'\n",
        "            })\n",
        "        \n",
        "        # Store metrics\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_acc)\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs} Summary:\")\n",
        "        print(f\"Training Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "        \n",
        "    \n",
        "    # Return history dictionary\n",
        "    return {\n",
        "        'train_loss': train_losses,\n",
        "        'train_acc': train_accuracies\n",
        "    }\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1741300163534
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# root_dir = \"./data/pose_hands_landmarks_iso_files\"\n",
        "# annotations_file = \"./data/signum_signs_anno_eng.txt\"\n",
        "\n",
        "# train_signer_ids = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
        "# val_signer_ids = [15, 16, 17, 18]\n",
        "# test_signer_ids = [19, 20, 21, 22, 23, 24, 25]\n",
        "\n",
        "# train_loader, val_loader, test_loader = get_dataloader(\n",
        "#     root_dir=root_dir,\n",
        "#     annotations_file=annotations_file,\n",
        "#     train_ids=train_signer_ids,\n",
        "#     val_ids=val_signer_ids,\n",
        "#     test_ids=test_signer_ids,\n",
        "#     batch_size=16,\n",
        "# )\n",
        "\n",
        "# # Check the shape of a batch\n",
        "# for X, y in train_loader:\n",
        "#     print(\"X shape (batch_size, window_size, num_channels):\", X.shape)  # Expected: (16, 80, 225)\n",
        "#     print(\"y (labels as numeric indices):\", y)  # List of numeric indices for gloss annotations\n",
        "#     break\n"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1741284239282
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total shape of train test and validation data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_total_X(loader):\n",
        "#     all_X = []\n",
        "#     for X_batch, _ in loader:  # We only need the X_batch here\n",
        "#         all_X.append(X_batch)\n",
        "#     total_X = torch.cat(all_X, dim=0)  # Concatenate along the batch dimension\n",
        "#     return total_X\n",
        "\n",
        "# # Total shapes for train, validation, and test sets\n",
        "# train_X = get_total_X(train_loader)\n",
        "# val_X = get_total_X(val_loader)\n",
        "# test_X = get_total_X(test_loader)\n",
        "\n",
        "# # Print the total shapes\n",
        "# print(\"Total X shape for train set:\", train_X.shape)\n",
        "# print(\"Total X shape for validation set:\", val_X.shape)\n",
        "# print(\"Total X shape for test set:\", test_X.shape)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1741284240203
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-computed DTW distances\n",
        "dtw_distances = np.load('../results_skeleton_test/distances_train_all.npy')\n",
        "folder_path = '../Skeleton_numpy'\n",
        "# Print the shape to verify\n",
        "print(f\"Loaded DTW distances shape: {dtw_distances.shape}\")\n",
        "print(f\"Contains NaN: {np.isnan(dtw_distances).any()}\")\n",
        "print(f\"Contains Inf: {np.isinf(dtw_distances).any()}\")\n",
        "\n",
        "# Verify non-negativity\n",
        "is_non_negative = (dtw_distances >= 0).all()\n",
        "print(f\"All distances are non-negative: {is_non_negative}\")\n",
        "\n",
        "# Dinstance nomralization\n",
        "dtw_distances = (dtw_distances - dtw_distances.min()) / (dtw_distances.max() - dtw_distances.min())\n",
        "# dtw_distances = (dtw_distances - dtw_distances.mean()) / dtw_distances.std()\n",
        "\n",
        "train_loader, test_loader = get_distillation_dataloader_from_folder(\n",
        "    folder=folder_path, dtw_distances=dtw_distances, batch_size=16\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Loaded DTW distances shape: (539, 539)\nContains NaN: False\nContains Inf: False\nAll distances are non-negative: True\n(539, 60, 125)\n(322, 60, 125)\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1741300163674
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 60  # Number of features (channels)\n",
        "seq_length = 125\n",
        "num_classes = 27 #len(set([item['y'] for item in train_loader.dataset]))  # Number of unique glosses\n",
        "num_heads = 12 #change\n",
        "print(num_classes)\n",
        "\n",
        "# Initialize model\n",
        "#model = TransformerClassifier(input_dim=input_dim, num_heads=num_heads, num_classes=num_classes)\n",
        "model = EnhancedTransformerClassifier(input_dim=input_dim, num_heads = num_heads, num_classes=num_classes)\n",
        "print(model)\n",
        "\n",
        "# Select device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train the model with distillation\n",
        "history = distillation_train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    device=device,\n",
        "    alpha=0.5,  # Weight for cross-entropy loss\n",
        "    beta=0.5,   # Weight for KL divergence loss\n",
        "    temperature=3.0,  # Temperature for softening distributions\n",
        "    epochs=2000,\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "# Test the model on test data\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        X_batch = batch['X']\n",
        "        y_batch = batch['y']\n",
        "\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move data to device\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 42.13it/s, loss=2.0762, acc=4.08%]\n\nEpoch 1/2000 Summary:\nTraining Loss: 2.0762, Accuracy: 4.08%\nEpoch 2/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=1.7394, acc=2.78%]\n\nEpoch 2/2000 Summary:\nTraining Loss: 1.7394, Accuracy: 2.78%\nEpoch 3/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.49it/s, loss=1.7956, acc=3.90%]\n\nEpoch 3/2000 Summary:\nTraining Loss: 1.7956, Accuracy: 3.90%\nEpoch 4/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.84it/s, loss=1.7848, acc=2.78%]\n\nEpoch 4/2000 Summary:\nTraining Loss: 1.7848, Accuracy: 2.78%\nEpoch 5/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=1.7862, acc=3.53%]\n\nEpoch 5/2000 Summary:\nTraining Loss: 1.7862, Accuracy: 3.53%\nEpoch 6/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=1.7549, acc=6.86%]\n\nEpoch 6/2000 Summary:\nTraining Loss: 1.7549, Accuracy: 6.86%\nEpoch 7/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=1.6962, acc=5.75%]\n\nEpoch 7/2000 Summary:\nTraining Loss: 1.6962, Accuracy: 5.75%\nEpoch 8/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=1.7315, acc=7.42%]\n\nEpoch 8/2000 Summary:\nTraining Loss: 1.7315, Accuracy: 7.42%\nEpoch 9/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=1.7224, acc=7.61%]\n\nEpoch 9/2000 Summary:\nTraining Loss: 1.7224, Accuracy: 7.61%\nEpoch 10/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.38it/s, loss=1.6658, acc=7.98%]\n\nEpoch 10/2000 Summary:\nTraining Loss: 1.6658, Accuracy: 7.98%\nEpoch 11/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.75it/s, loss=1.7091, acc=8.91%]\n\nEpoch 11/2000 Summary:\nTraining Loss: 1.7091, Accuracy: 8.91%\nEpoch 12/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.68it/s, loss=1.6410, acc=10.20%]\n\nEpoch 12/2000 Summary:\nTraining Loss: 1.6410, Accuracy: 10.20%\nEpoch 13/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=1.6306, acc=9.28%] \n\nEpoch 13/2000 Summary:\nTraining Loss: 1.6306, Accuracy: 9.28%\nEpoch 14/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=1.6893, acc=9.83%]\n\nEpoch 14/2000 Summary:\nTraining Loss: 1.6893, Accuracy: 9.83%\nEpoch 15/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=1.6800, acc=10.58%]\n\nEpoch 15/2000 Summary:\nTraining Loss: 1.6800, Accuracy: 10.58%\nEpoch 16/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.91it/s, loss=1.6197, acc=11.32%]\n\nEpoch 16/2000 Summary:\nTraining Loss: 1.6197, Accuracy: 11.32%\nEpoch 17/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.12it/s, loss=1.6100, acc=11.87%]\n\nEpoch 17/2000 Summary:\nTraining Loss: 1.6100, Accuracy: 11.87%\nEpoch 18/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=1.6665, acc=11.87%]\n\nEpoch 18/2000 Summary:\nTraining Loss: 1.6665, Accuracy: 11.87%\nEpoch 19/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=1.6010, acc=13.73%]\n\nEpoch 19/2000 Summary:\nTraining Loss: 1.6010, Accuracy: 13.73%\nEpoch 20/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=1.6445, acc=12.24%]\n\nEpoch 20/2000 Summary:\nTraining Loss: 1.6445, Accuracy: 12.24%\nEpoch 21/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.13it/s, loss=1.5903, acc=12.24%]\n\nEpoch 21/2000 Summary:\nTraining Loss: 1.5903, Accuracy: 12.24%\nEpoch 22/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.38it/s, loss=1.6256, acc=14.47%]\n\nEpoch 22/2000 Summary:\nTraining Loss: 1.6256, Accuracy: 14.47%\nEpoch 23/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=1.6168, acc=15.03%]\n\nEpoch 23/2000 Summary:\nTraining Loss: 1.6168, Accuracy: 15.03%\nEpoch 24/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.27it/s, loss=1.5308, acc=19.67%]\n\nEpoch 24/2000 Summary:\nTraining Loss: 1.5308, Accuracy: 19.67%\nEpoch 25/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.64it/s, loss=1.5147, acc=18.18%]\n\nEpoch 25/2000 Summary:\nTraining Loss: 1.5147, Accuracy: 18.18%\nEpoch 26/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.88it/s, loss=1.4896, acc=22.63%]\n\nEpoch 26/2000 Summary:\nTraining Loss: 1.4896, Accuracy: 22.63%\nEpoch 27/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.28it/s, loss=1.4677, acc=25.42%]\n\nEpoch 27/2000 Summary:\nTraining Loss: 1.4677, Accuracy: 25.42%\nEpoch 28/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.49it/s, loss=1.5179, acc=23.56%]\n\nEpoch 28/2000 Summary:\nTraining Loss: 1.5179, Accuracy: 23.56%\nEpoch 29/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.72it/s, loss=1.4390, acc=26.72%]\n\nEpoch 29/2000 Summary:\nTraining Loss: 1.4390, Accuracy: 26.72%\nEpoch 30/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.76it/s, loss=1.4892, acc=28.20%]\n\nEpoch 30/2000 Summary:\nTraining Loss: 1.4892, Accuracy: 28.20%\nEpoch 31/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.27it/s, loss=1.4184, acc=29.31%]\n\nEpoch 31/2000 Summary:\nTraining Loss: 1.4184, Accuracy: 29.31%\nEpoch 32/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.23it/s, loss=1.4322, acc=30.80%]\n\nEpoch 32/2000 Summary:\nTraining Loss: 1.4322, Accuracy: 30.80%\nEpoch 33/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.52it/s, loss=1.4268, acc=32.10%]\n\nEpoch 33/2000 Summary:\nTraining Loss: 1.4268, Accuracy: 32.10%\nEpoch 34/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=1.4288, acc=32.65%]\n\nEpoch 34/2000 Summary:\nTraining Loss: 1.4288, Accuracy: 32.65%\nEpoch 35/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.25it/s, loss=1.3710, acc=35.44%]\n\nEpoch 35/2000 Summary:\nTraining Loss: 1.3710, Accuracy: 35.44%\nEpoch 36/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.30it/s, loss=1.3704, acc=32.47%]\n\nEpoch 36/2000 Summary:\nTraining Loss: 1.3704, Accuracy: 32.47%\nEpoch 37/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.75it/s, loss=1.3805, acc=37.85%]\n\nEpoch 37/2000 Summary:\nTraining Loss: 1.3805, Accuracy: 37.85%\nEpoch 38/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=1.3270, acc=37.11%]\n\nEpoch 38/2000 Summary:\nTraining Loss: 1.3270, Accuracy: 37.11%\nEpoch 39/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=1.3717, acc=37.11%]\n\nEpoch 39/2000 Summary:\nTraining Loss: 1.3717, Accuracy: 37.11%\nEpoch 40/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=1.3529, acc=40.63%]\n\nEpoch 40/2000 Summary:\nTraining Loss: 1.3529, Accuracy: 40.63%\nEpoch 41/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.24it/s, loss=1.2884, acc=40.63%]\n\nEpoch 41/2000 Summary:\nTraining Loss: 1.2884, Accuracy: 40.63%\nEpoch 42/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=1.3193, acc=41.56%]\n\nEpoch 42/2000 Summary:\nTraining Loss: 1.3193, Accuracy: 41.56%\nEpoch 43/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.23it/s, loss=1.3273, acc=42.30%]\n\nEpoch 43/2000 Summary:\nTraining Loss: 1.3273, Accuracy: 42.30%\nEpoch 44/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.45it/s, loss=1.2542, acc=45.83%]\n\nEpoch 44/2000 Summary:\nTraining Loss: 1.2542, Accuracy: 45.83%\nEpoch 45/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.70it/s, loss=1.2587, acc=45.08%]\n\nEpoch 45/2000 Summary:\nTraining Loss: 1.2587, Accuracy: 45.08%\nEpoch 46/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=1.2793, acc=45.08%]\n\nEpoch 46/2000 Summary:\nTraining Loss: 1.2793, Accuracy: 45.08%\nEpoch 47/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=1.2654, acc=47.12%]\n\nEpoch 47/2000 Summary:\nTraining Loss: 1.2654, Accuracy: 47.12%\nEpoch 48/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=1.1990, acc=53.06%]\n\nEpoch 48/2000 Summary:\nTraining Loss: 1.1990, Accuracy: 53.06%\nEpoch 49/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=1.2338, acc=51.58%]\n\nEpoch 49/2000 Summary:\nTraining Loss: 1.2338, Accuracy: 51.58%\nEpoch 50/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.13it/s, loss=1.2383, acc=51.21%]\n\nEpoch 50/2000 Summary:\nTraining Loss: 1.2383, Accuracy: 51.21%\nEpoch 51/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=1.1778, acc=53.43%]\n\nEpoch 51/2000 Summary:\nTraining Loss: 1.1778, Accuracy: 53.43%\nEpoch 52/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.99it/s, loss=1.1983, acc=54.36%]\n\nEpoch 52/2000 Summary:\nTraining Loss: 1.1983, Accuracy: 54.36%\nEpoch 53/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=1.1982, acc=53.06%]\n\nEpoch 53/2000 Summary:\nTraining Loss: 1.1982, Accuracy: 53.06%\nEpoch 54/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.20it/s, loss=1.1484, acc=52.88%]\n\nEpoch 54/2000 Summary:\nTraining Loss: 1.1484, Accuracy: 52.88%\nEpoch 55/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=1.1821, acc=56.22%]\n\nEpoch 55/2000 Summary:\nTraining Loss: 1.1821, Accuracy: 56.22%\nEpoch 56/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=1.1557, acc=57.88%]\n\nEpoch 56/2000 Summary:\nTraining Loss: 1.1557, Accuracy: 57.88%\nEpoch 57/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.47it/s, loss=1.1152, acc=59.37%]\n\nEpoch 57/2000 Summary:\nTraining Loss: 1.1152, Accuracy: 59.37%\nEpoch 58/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.01it/s, loss=1.1130, acc=62.34%]\n\nEpoch 58/2000 Summary:\nTraining Loss: 1.1130, Accuracy: 62.34%\nEpoch 59/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=1.1378, acc=58.63%]\n\nEpoch 59/2000 Summary:\nTraining Loss: 1.1378, Accuracy: 58.63%\nEpoch 60/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=1.1305, acc=59.55%]\n\nEpoch 60/2000 Summary:\nTraining Loss: 1.1305, Accuracy: 59.55%\nEpoch 61/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=1.1144, acc=61.04%]\n\nEpoch 61/2000 Summary:\nTraining Loss: 1.1144, Accuracy: 61.04%\nEpoch 62/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=1.0795, acc=60.85%]\n\nEpoch 62/2000 Summary:\nTraining Loss: 1.0795, Accuracy: 60.85%\nEpoch 63/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.37it/s, loss=1.0974, acc=61.60%]\n\nEpoch 63/2000 Summary:\nTraining Loss: 1.0974, Accuracy: 61.60%\nEpoch 64/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=1.0947, acc=62.52%]\n\nEpoch 64/2000 Summary:\nTraining Loss: 1.0947, Accuracy: 62.52%\nEpoch 65/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.80it/s, loss=1.0827, acc=63.82%]\n\nEpoch 65/2000 Summary:\nTraining Loss: 1.0827, Accuracy: 63.82%\nEpoch 66/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=1.0910, acc=63.64%]\n\nEpoch 66/2000 Summary:\nTraining Loss: 1.0910, Accuracy: 63.64%\nEpoch 67/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.95it/s, loss=1.0451, acc=63.45%]\n\nEpoch 67/2000 Summary:\nTraining Loss: 1.0451, Accuracy: 63.45%\nEpoch 68/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=1.0631, acc=64.19%]\n\nEpoch 68/2000 Summary:\nTraining Loss: 1.0631, Accuracy: 64.19%\nEpoch 69/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.62it/s, loss=1.0200, acc=65.49%]\n\nEpoch 69/2000 Summary:\nTraining Loss: 1.0200, Accuracy: 65.49%\nEpoch 70/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.44it/s, loss=1.0545, acc=63.45%]\n\nEpoch 70/2000 Summary:\nTraining Loss: 1.0545, Accuracy: 63.45%\nEpoch 71/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.16it/s, loss=1.0428, acc=68.83%]\n\nEpoch 71/2000 Summary:\nTraining Loss: 1.0428, Accuracy: 68.83%\nEpoch 72/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.99it/s, loss=1.0285, acc=70.13%]\n\nEpoch 72/2000 Summary:\nTraining Loss: 1.0285, Accuracy: 70.13%\nEpoch 73/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.29it/s, loss=1.0157, acc=68.46%]\n\nEpoch 73/2000 Summary:\nTraining Loss: 1.0157, Accuracy: 68.46%\nEpoch 74/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=1.0190, acc=67.53%]\n\nEpoch 74/2000 Summary:\nTraining Loss: 1.0190, Accuracy: 67.53%\nEpoch 75/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.79it/s, loss=1.0116, acc=67.53%]\n\nEpoch 75/2000 Summary:\nTraining Loss: 1.0116, Accuracy: 67.53%\nEpoch 76/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.83it/s, loss=0.9936, acc=70.69%]\n\nEpoch 76/2000 Summary:\nTraining Loss: 0.9936, Accuracy: 70.69%\nEpoch 77/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.30it/s, loss=0.9951, acc=72.17%]\n\nEpoch 77/2000 Summary:\nTraining Loss: 0.9951, Accuracy: 72.17%\nEpoch 78/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.31it/s, loss=0.9908, acc=67.16%]\n\nEpoch 78/2000 Summary:\nTraining Loss: 0.9908, Accuracy: 67.16%\nEpoch 79/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.9870, acc=70.13%]\n\nEpoch 79/2000 Summary:\nTraining Loss: 0.9870, Accuracy: 70.13%\nEpoch 80/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.9437, acc=70.87%]\n\nEpoch 80/2000 Summary:\nTraining Loss: 0.9437, Accuracy: 70.87%\nEpoch 81/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.67it/s, loss=0.9282, acc=72.73%]\n\nEpoch 81/2000 Summary:\nTraining Loss: 0.9282, Accuracy: 72.73%\nEpoch 82/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.31it/s, loss=0.9249, acc=71.61%]\n\nEpoch 82/2000 Summary:\nTraining Loss: 0.9249, Accuracy: 71.61%\nEpoch 83/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.50it/s, loss=0.9427, acc=74.03%]\n\nEpoch 83/2000 Summary:\nTraining Loss: 0.9427, Accuracy: 74.03%\nEpoch 84/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.9250, acc=76.44%]\n\nEpoch 84/2000 Summary:\nTraining Loss: 0.9250, Accuracy: 76.44%\nEpoch 85/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.37it/s, loss=0.9059, acc=76.62%]\n\nEpoch 85/2000 Summary:\nTraining Loss: 0.9059, Accuracy: 76.62%\nEpoch 86/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.19it/s, loss=0.9181, acc=75.88%]\n\nEpoch 86/2000 Summary:\nTraining Loss: 0.9181, Accuracy: 75.88%\nEpoch 87/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.24it/s, loss=0.9209, acc=76.25%]\n\nEpoch 87/2000 Summary:\nTraining Loss: 0.9209, Accuracy: 76.25%\nEpoch 88/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.9031, acc=77.74%]\n\nEpoch 88/2000 Summary:\nTraining Loss: 0.9031, Accuracy: 77.74%\nEpoch 89/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.8727, acc=78.11%]\n\nEpoch 89/2000 Summary:\nTraining Loss: 0.8727, Accuracy: 78.11%\nEpoch 90/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.8732, acc=76.81%]\n\nEpoch 90/2000 Summary:\nTraining Loss: 0.8732, Accuracy: 76.81%\nEpoch 91/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.13it/s, loss=0.8795, acc=78.29%]\n\nEpoch 91/2000 Summary:\nTraining Loss: 0.8795, Accuracy: 78.29%\nEpoch 92/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.61it/s, loss=0.8776, acc=76.81%]\n\nEpoch 92/2000 Summary:\nTraining Loss: 0.8776, Accuracy: 76.81%\nEpoch 93/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.72it/s, loss=0.9151, acc=75.88%]\n\nEpoch 93/2000 Summary:\nTraining Loss: 0.9151, Accuracy: 75.88%\nEpoch 94/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.8858, acc=78.66%]\n\nEpoch 94/2000 Summary:\nTraining Loss: 0.8858, Accuracy: 78.66%\nEpoch 95/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.35it/s, loss=0.8691, acc=79.22%]\n\nEpoch 95/2000 Summary:\nTraining Loss: 0.8691, Accuracy: 79.22%\nEpoch 96/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.24it/s, loss=0.8436, acc=81.26%]\n\nEpoch 96/2000 Summary:\nTraining Loss: 0.8436, Accuracy: 81.26%\nEpoch 97/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.8420, acc=81.82%]\n\nEpoch 97/2000 Summary:\nTraining Loss: 0.8420, Accuracy: 81.82%\nEpoch 98/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.8236, acc=82.00%]\n\nEpoch 98/2000 Summary:\nTraining Loss: 0.8236, Accuracy: 82.00%\nEpoch 99/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.20it/s, loss=0.8244, acc=78.66%]\n\nEpoch 99/2000 Summary:\nTraining Loss: 0.8244, Accuracy: 78.66%\nEpoch 100/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.24it/s, loss=0.8210, acc=81.26%]\n\nEpoch 100/2000 Summary:\nTraining Loss: 0.8210, Accuracy: 81.26%\nEpoch 101/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.62it/s, loss=0.8084, acc=82.00%]\n\nEpoch 101/2000 Summary:\nTraining Loss: 0.8084, Accuracy: 82.00%\nEpoch 102/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.44it/s, loss=0.8332, acc=81.82%]\n\nEpoch 102/2000 Summary:\nTraining Loss: 0.8332, Accuracy: 81.82%\nEpoch 103/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.8205, acc=83.67%]\n\nEpoch 103/2000 Summary:\nTraining Loss: 0.8205, Accuracy: 83.67%\nEpoch 104/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.7893, acc=82.93%]\n\nEpoch 104/2000 Summary:\nTraining Loss: 0.7893, Accuracy: 82.93%\nEpoch 105/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.97it/s, loss=0.8141, acc=83.49%]\n\nEpoch 105/2000 Summary:\nTraining Loss: 0.8141, Accuracy: 83.49%\nEpoch 106/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.01it/s, loss=0.8008, acc=83.12%]\n\nEpoch 106/2000 Summary:\nTraining Loss: 0.8008, Accuracy: 83.12%\nEpoch 107/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.24it/s, loss=0.8089, acc=84.04%]\n\nEpoch 107/2000 Summary:\nTraining Loss: 0.8089, Accuracy: 84.04%\nEpoch 108/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.7892, acc=82.19%]\n\nEpoch 108/2000 Summary:\nTraining Loss: 0.7892, Accuracy: 82.19%\nEpoch 109/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.7930, acc=84.42%]\n\nEpoch 109/2000 Summary:\nTraining Loss: 0.7930, Accuracy: 84.42%\nEpoch 110/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.43it/s, loss=0.7568, acc=85.90%]\n\nEpoch 110/2000 Summary:\nTraining Loss: 0.7568, Accuracy: 85.90%\nEpoch 111/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.7816, acc=87.01%]\n\nEpoch 111/2000 Summary:\nTraining Loss: 0.7816, Accuracy: 87.01%\nEpoch 112/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.22it/s, loss=0.7564, acc=85.53%]\n\nEpoch 112/2000 Summary:\nTraining Loss: 0.7564, Accuracy: 85.53%\nEpoch 113/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.49it/s, loss=0.7401, acc=87.01%]\n\nEpoch 113/2000 Summary:\nTraining Loss: 0.7401, Accuracy: 87.01%\nEpoch 114/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.69it/s, loss=0.7579, acc=87.76%]\n\nEpoch 114/2000 Summary:\nTraining Loss: 0.7579, Accuracy: 87.76%\nEpoch 115/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.06it/s, loss=0.7683, acc=85.71%]\n\nEpoch 115/2000 Summary:\nTraining Loss: 0.7683, Accuracy: 85.71%\nEpoch 116/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.7679, acc=87.20%]\n\nEpoch 116/2000 Summary:\nTraining Loss: 0.7679, Accuracy: 87.20%\nEpoch 117/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.31it/s, loss=0.7565, acc=87.01%]\n\nEpoch 117/2000 Summary:\nTraining Loss: 0.7565, Accuracy: 87.01%\nEpoch 118/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.7594, acc=86.27%]\n\nEpoch 118/2000 Summary:\nTraining Loss: 0.7594, Accuracy: 86.27%\nEpoch 119/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.7195, acc=88.68%]\n\nEpoch 119/2000 Summary:\nTraining Loss: 0.7195, Accuracy: 88.68%\nEpoch 120/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.71it/s, loss=0.7505, acc=87.57%]\n\nEpoch 120/2000 Summary:\nTraining Loss: 0.7505, Accuracy: 87.57%\nEpoch 121/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.06it/s, loss=0.7200, acc=86.83%]\n\nEpoch 121/2000 Summary:\nTraining Loss: 0.7200, Accuracy: 86.83%\nEpoch 122/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.47it/s, loss=0.7148, acc=87.20%]\n\nEpoch 122/2000 Summary:\nTraining Loss: 0.7148, Accuracy: 87.20%\nEpoch 123/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.7379, acc=88.68%]\n\nEpoch 123/2000 Summary:\nTraining Loss: 0.7379, Accuracy: 88.68%\nEpoch 124/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.64it/s, loss=0.7342, acc=88.50%]\n\nEpoch 124/2000 Summary:\nTraining Loss: 0.7342, Accuracy: 88.50%\nEpoch 125/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.7222, acc=88.50%]\n\nEpoch 125/2000 Summary:\nTraining Loss: 0.7222, Accuracy: 88.50%\nEpoch 126/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=0.7201, acc=89.98%]\n\nEpoch 126/2000 Summary:\nTraining Loss: 0.7201, Accuracy: 89.98%\nEpoch 127/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.7208, acc=90.35%]\n\nEpoch 127/2000 Summary:\nTraining Loss: 0.7208, Accuracy: 90.35%\nEpoch 128/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.27it/s, loss=0.6911, acc=90.35%]\n\nEpoch 128/2000 Summary:\nTraining Loss: 0.6911, Accuracy: 90.35%\nEpoch 129/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.78it/s, loss=0.7169, acc=90.17%]\n\nEpoch 129/2000 Summary:\nTraining Loss: 0.7169, Accuracy: 90.17%\nEpoch 130/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.40it/s, loss=0.6873, acc=89.05%]\n\nEpoch 130/2000 Summary:\nTraining Loss: 0.6873, Accuracy: 89.05%\nEpoch 131/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.7013, acc=90.91%]\n\nEpoch 131/2000 Summary:\nTraining Loss: 0.7013, Accuracy: 90.91%\nEpoch 132/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.6975, acc=91.09%]\n\nEpoch 132/2000 Summary:\nTraining Loss: 0.6975, Accuracy: 91.09%\nEpoch 133/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.45it/s, loss=0.6745, acc=90.17%]\n\nEpoch 133/2000 Summary:\nTraining Loss: 0.6745, Accuracy: 90.17%\nEpoch 134/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.6745, acc=89.80%]\n\nEpoch 134/2000 Summary:\nTraining Loss: 0.6745, Accuracy: 89.80%\nEpoch 135/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.37it/s, loss=0.6586, acc=92.58%]\n\nEpoch 135/2000 Summary:\nTraining Loss: 0.6586, Accuracy: 92.58%\nEpoch 136/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.43it/s, loss=0.6691, acc=91.84%]\n\nEpoch 136/2000 Summary:\nTraining Loss: 0.6691, Accuracy: 91.84%\nEpoch 137/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.6829, acc=91.65%]\n\nEpoch 137/2000 Summary:\nTraining Loss: 0.6829, Accuracy: 91.65%\nEpoch 138/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.6482, acc=92.39%]\n\nEpoch 138/2000 Summary:\nTraining Loss: 0.6482, Accuracy: 92.39%\nEpoch 139/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.6751, acc=90.91%]\n\nEpoch 139/2000 Summary:\nTraining Loss: 0.6751, Accuracy: 90.91%\nEpoch 140/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.01it/s, loss=0.6539, acc=91.65%]\n\nEpoch 140/2000 Summary:\nTraining Loss: 0.6539, Accuracy: 91.65%\nEpoch 141/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.85it/s, loss=0.6469, acc=93.14%]\n\nEpoch 141/2000 Summary:\nTraining Loss: 0.6469, Accuracy: 93.14%\nEpoch 142/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.08it/s, loss=0.6530, acc=91.65%]\n\nEpoch 142/2000 Summary:\nTraining Loss: 0.6530, Accuracy: 91.65%\nEpoch 143/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.28it/s, loss=0.6623, acc=91.09%]\n\nEpoch 143/2000 Summary:\nTraining Loss: 0.6623, Accuracy: 91.09%\nEpoch 144/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.04it/s, loss=0.6715, acc=92.76%]\n\nEpoch 144/2000 Summary:\nTraining Loss: 0.6715, Accuracy: 92.76%\nEpoch 145/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.79it/s, loss=0.6541, acc=92.58%]\n\nEpoch 145/2000 Summary:\nTraining Loss: 0.6541, Accuracy: 92.58%\nEpoch 146/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.45it/s, loss=0.6200, acc=93.32%]\n\nEpoch 146/2000 Summary:\nTraining Loss: 0.6200, Accuracy: 93.32%\nEpoch 147/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=0.6313, acc=93.14%]\n\nEpoch 147/2000 Summary:\nTraining Loss: 0.6313, Accuracy: 93.14%\nEpoch 148/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.24it/s, loss=0.6499, acc=93.14%]\n\nEpoch 148/2000 Summary:\nTraining Loss: 0.6499, Accuracy: 93.14%\nEpoch 149/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.07it/s, loss=0.6464, acc=92.95%]\n\nEpoch 149/2000 Summary:\nTraining Loss: 0.6464, Accuracy: 92.95%\nEpoch 150/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.6460, acc=93.69%]\n\nEpoch 150/2000 Summary:\nTraining Loss: 0.6460, Accuracy: 93.69%\nEpoch 151/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.64it/s, loss=0.6212, acc=93.51%]\n\nEpoch 151/2000 Summary:\nTraining Loss: 0.6212, Accuracy: 93.51%\nEpoch 152/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.79it/s, loss=0.6471, acc=93.88%]\n\nEpoch 152/2000 Summary:\nTraining Loss: 0.6471, Accuracy: 93.88%\nEpoch 153/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.03it/s, loss=0.6368, acc=92.95%]\n\nEpoch 153/2000 Summary:\nTraining Loss: 0.6368, Accuracy: 92.95%\nEpoch 154/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.6502, acc=91.65%]\n\nEpoch 154/2000 Summary:\nTraining Loss: 0.6502, Accuracy: 91.65%\nEpoch 155/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.6274, acc=92.95%]\n\nEpoch 155/2000 Summary:\nTraining Loss: 0.6274, Accuracy: 92.95%\nEpoch 156/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.73it/s, loss=0.6186, acc=93.14%]\n\nEpoch 156/2000 Summary:\nTraining Loss: 0.6186, Accuracy: 93.14%\nEpoch 157/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.6314, acc=93.69%]\n\nEpoch 157/2000 Summary:\nTraining Loss: 0.6314, Accuracy: 93.69%\nEpoch 158/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.6372, acc=93.32%]\n\nEpoch 158/2000 Summary:\nTraining Loss: 0.6372, Accuracy: 93.32%\nEpoch 159/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.10it/s, loss=0.6258, acc=94.25%]\n\nEpoch 159/2000 Summary:\nTraining Loss: 0.6258, Accuracy: 94.25%\nEpoch 160/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.6263, acc=94.43%]\n\nEpoch 160/2000 Summary:\nTraining Loss: 0.6263, Accuracy: 94.43%\nEpoch 161/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.30it/s, loss=0.6064, acc=93.88%]\n\nEpoch 161/2000 Summary:\nTraining Loss: 0.6064, Accuracy: 93.88%\nEpoch 162/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=0.6318, acc=93.32%]\n\nEpoch 162/2000 Summary:\nTraining Loss: 0.6318, Accuracy: 93.32%\nEpoch 163/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.84it/s, loss=0.6208, acc=94.62%]\n\nEpoch 163/2000 Summary:\nTraining Loss: 0.6208, Accuracy: 94.62%\nEpoch 164/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.6135, acc=94.06%]\n\nEpoch 164/2000 Summary:\nTraining Loss: 0.6135, Accuracy: 94.06%\nEpoch 165/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.6084, acc=94.99%]\n\nEpoch 165/2000 Summary:\nTraining Loss: 0.6084, Accuracy: 94.99%\nEpoch 166/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.18it/s, loss=0.5884, acc=95.36%]\n\nEpoch 166/2000 Summary:\nTraining Loss: 0.5884, Accuracy: 95.36%\nEpoch 167/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.6152, acc=94.81%]\n\nEpoch 167/2000 Summary:\nTraining Loss: 0.6152, Accuracy: 94.81%\nEpoch 168/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.5768, acc=96.29%]\n\nEpoch 168/2000 Summary:\nTraining Loss: 0.5768, Accuracy: 96.29%\nEpoch 169/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.11it/s, loss=0.6007, acc=95.55%]\n\nEpoch 169/2000 Summary:\nTraining Loss: 0.6007, Accuracy: 95.55%\nEpoch 170/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.28it/s, loss=0.5744, acc=96.29%]\n\nEpoch 170/2000 Summary:\nTraining Loss: 0.5744, Accuracy: 96.29%\nEpoch 171/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.55it/s, loss=0.5817, acc=95.92%]\n\nEpoch 171/2000 Summary:\nTraining Loss: 0.5817, Accuracy: 95.92%\nEpoch 172/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.6171, acc=93.88%]\n\nEpoch 172/2000 Summary:\nTraining Loss: 0.6171, Accuracy: 93.88%\nEpoch 173/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.5962, acc=95.36%]\n\nEpoch 173/2000 Summary:\nTraining Loss: 0.5962, Accuracy: 95.36%\nEpoch 174/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.16it/s, loss=0.5740, acc=95.92%]\n\nEpoch 174/2000 Summary:\nTraining Loss: 0.5740, Accuracy: 95.92%\nEpoch 175/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.5835, acc=97.22%]\n\nEpoch 175/2000 Summary:\nTraining Loss: 0.5835, Accuracy: 97.22%\nEpoch 176/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.5834, acc=96.66%]\n\nEpoch 176/2000 Summary:\nTraining Loss: 0.5834, Accuracy: 96.66%\nEpoch 177/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.5768, acc=95.55%]\n\nEpoch 177/2000 Summary:\nTraining Loss: 0.5768, Accuracy: 95.55%\nEpoch 178/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.70it/s, loss=0.5720, acc=96.29%]\n\nEpoch 178/2000 Summary:\nTraining Loss: 0.5720, Accuracy: 96.29%\nEpoch 179/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.36it/s, loss=0.5939, acc=96.29%]\n\nEpoch 179/2000 Summary:\nTraining Loss: 0.5939, Accuracy: 96.29%\nEpoch 180/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.44it/s, loss=0.5922, acc=95.73%]\n\nEpoch 180/2000 Summary:\nTraining Loss: 0.5922, Accuracy: 95.73%\nEpoch 181/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.11it/s, loss=0.5681, acc=96.29%]\n\nEpoch 181/2000 Summary:\nTraining Loss: 0.5681, Accuracy: 96.29%\nEpoch 182/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.73it/s, loss=0.5658, acc=96.85%]\n\nEpoch 182/2000 Summary:\nTraining Loss: 0.5658, Accuracy: 96.85%\nEpoch 183/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.5829, acc=96.66%]\n\nEpoch 183/2000 Summary:\nTraining Loss: 0.5829, Accuracy: 96.66%\nEpoch 184/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.31it/s, loss=0.5716, acc=97.59%]\n\nEpoch 184/2000 Summary:\nTraining Loss: 0.5716, Accuracy: 97.59%\nEpoch 185/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.80it/s, loss=0.5683, acc=95.92%]\n\nEpoch 185/2000 Summary:\nTraining Loss: 0.5683, Accuracy: 95.92%\nEpoch 186/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.5841, acc=94.99%]\n\nEpoch 186/2000 Summary:\nTraining Loss: 0.5841, Accuracy: 94.99%\nEpoch 187/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.5819, acc=96.10%]\n\nEpoch 187/2000 Summary:\nTraining Loss: 0.5819, Accuracy: 96.10%\nEpoch 188/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.74it/s, loss=0.5623, acc=97.03%]\n\nEpoch 188/2000 Summary:\nTraining Loss: 0.5623, Accuracy: 97.03%\nEpoch 189/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.5769, acc=96.66%]\n\nEpoch 189/2000 Summary:\nTraining Loss: 0.5769, Accuracy: 96.66%\nEpoch 190/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.80it/s, loss=0.5704, acc=97.22%]\n\nEpoch 190/2000 Summary:\nTraining Loss: 0.5704, Accuracy: 97.22%\nEpoch 191/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.16it/s, loss=0.5708, acc=98.52%]\n\nEpoch 191/2000 Summary:\nTraining Loss: 0.5708, Accuracy: 98.52%\nEpoch 192/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.52it/s, loss=0.5746, acc=96.85%]\n\nEpoch 192/2000 Summary:\nTraining Loss: 0.5746, Accuracy: 96.85%\nEpoch 193/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.5683, acc=96.66%]\n\nEpoch 193/2000 Summary:\nTraining Loss: 0.5683, Accuracy: 96.66%\nEpoch 194/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.18it/s, loss=0.5761, acc=95.36%]\n\nEpoch 194/2000 Summary:\nTraining Loss: 0.5761, Accuracy: 95.36%\nEpoch 195/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.45it/s, loss=0.5686, acc=98.14%]\n\nEpoch 195/2000 Summary:\nTraining Loss: 0.5686, Accuracy: 98.14%\nEpoch 196/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.53it/s, loss=0.5413, acc=98.14%]\n\nEpoch 196/2000 Summary:\nTraining Loss: 0.5413, Accuracy: 98.14%\nEpoch 197/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.5525, acc=98.89%]\n\nEpoch 197/2000 Summary:\nTraining Loss: 0.5525, Accuracy: 98.89%\nEpoch 198/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.03it/s, loss=0.5571, acc=97.96%]\n\nEpoch 198/2000 Summary:\nTraining Loss: 0.5571, Accuracy: 97.96%\nEpoch 199/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.22it/s, loss=0.5612, acc=96.66%]\n\nEpoch 199/2000 Summary:\nTraining Loss: 0.5612, Accuracy: 96.66%\nEpoch 200/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.61it/s, loss=0.5430, acc=97.22%]\n\nEpoch 200/2000 Summary:\nTraining Loss: 0.5430, Accuracy: 97.22%\nEpoch 201/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.5489, acc=98.52%]\n\nEpoch 201/2000 Summary:\nTraining Loss: 0.5489, Accuracy: 98.52%\nEpoch 202/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.5391, acc=97.22%]\n\nEpoch 202/2000 Summary:\nTraining Loss: 0.5391, Accuracy: 97.22%\nEpoch 203/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.5521, acc=97.77%]\n\nEpoch 203/2000 Summary:\nTraining Loss: 0.5521, Accuracy: 97.77%\nEpoch 204/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.95it/s, loss=0.5574, acc=97.96%]\n\nEpoch 204/2000 Summary:\nTraining Loss: 0.5574, Accuracy: 97.96%\nEpoch 205/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.18it/s, loss=0.5397, acc=96.85%]\n\nEpoch 205/2000 Summary:\nTraining Loss: 0.5397, Accuracy: 96.85%\nEpoch 206/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.5521, acc=97.96%]\n\nEpoch 206/2000 Summary:\nTraining Loss: 0.5521, Accuracy: 97.96%\nEpoch 207/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.48it/s, loss=0.5280, acc=97.96%]\n\nEpoch 207/2000 Summary:\nTraining Loss: 0.5280, Accuracy: 97.96%\nEpoch 208/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.61it/s, loss=0.5452, acc=98.33%]\n\nEpoch 208/2000 Summary:\nTraining Loss: 0.5452, Accuracy: 98.33%\nEpoch 209/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.54it/s, loss=0.5376, acc=98.70%]\n\nEpoch 209/2000 Summary:\nTraining Loss: 0.5376, Accuracy: 98.70%\nEpoch 210/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.5457, acc=97.59%]\n\nEpoch 210/2000 Summary:\nTraining Loss: 0.5457, Accuracy: 97.59%\nEpoch 211/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=0.5390, acc=97.59%]\n\nEpoch 211/2000 Summary:\nTraining Loss: 0.5390, Accuracy: 97.59%\nEpoch 212/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.5376, acc=97.96%]\n\nEpoch 212/2000 Summary:\nTraining Loss: 0.5376, Accuracy: 97.96%\nEpoch 213/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.83it/s, loss=0.5179, acc=98.14%]\n\nEpoch 213/2000 Summary:\nTraining Loss: 0.5179, Accuracy: 98.14%\nEpoch 214/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.62it/s, loss=0.5222, acc=98.33%]\n\nEpoch 214/2000 Summary:\nTraining Loss: 0.5222, Accuracy: 98.33%\nEpoch 215/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.5337, acc=98.89%]\n\nEpoch 215/2000 Summary:\nTraining Loss: 0.5337, Accuracy: 98.89%\nEpoch 216/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.20it/s, loss=0.5129, acc=99.44%]\n\nEpoch 216/2000 Summary:\nTraining Loss: 0.5129, Accuracy: 99.44%\nEpoch 217/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.5360, acc=99.26%]\n\nEpoch 217/2000 Summary:\nTraining Loss: 0.5360, Accuracy: 99.26%\nEpoch 218/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.78it/s, loss=0.5389, acc=98.70%]\n\nEpoch 218/2000 Summary:\nTraining Loss: 0.5389, Accuracy: 98.70%\nEpoch 219/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.5334, acc=98.33%]\n\nEpoch 219/2000 Summary:\nTraining Loss: 0.5334, Accuracy: 98.33%\nEpoch 220/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.5201, acc=97.59%]\n\nEpoch 220/2000 Summary:\nTraining Loss: 0.5201, Accuracy: 97.59%\nEpoch 221/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=0.5277, acc=98.89%]\n\nEpoch 221/2000 Summary:\nTraining Loss: 0.5277, Accuracy: 98.89%\nEpoch 222/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.25it/s, loss=0.5255, acc=99.26%]\n\nEpoch 222/2000 Summary:\nTraining Loss: 0.5255, Accuracy: 99.26%\nEpoch 223/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.56it/s, loss=0.5139, acc=97.96%]\n\nEpoch 223/2000 Summary:\nTraining Loss: 0.5139, Accuracy: 97.96%\nEpoch 224/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.34it/s, loss=0.5215, acc=99.44%]\n\nEpoch 224/2000 Summary:\nTraining Loss: 0.5215, Accuracy: 99.44%\nEpoch 225/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=0.5299, acc=98.52%]\n\nEpoch 225/2000 Summary:\nTraining Loss: 0.5299, Accuracy: 98.52%\nEpoch 226/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.16it/s, loss=0.5059, acc=99.63%] \n\nEpoch 226/2000 Summary:\nTraining Loss: 0.5059, Accuracy: 99.63%\nEpoch 227/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.59it/s, loss=0.5084, acc=98.52%]\n\nEpoch 227/2000 Summary:\nTraining Loss: 0.5084, Accuracy: 98.52%\nEpoch 228/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.46it/s, loss=0.5173, acc=99.07%]\n\nEpoch 228/2000 Summary:\nTraining Loss: 0.5173, Accuracy: 99.07%\nEpoch 229/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=0.5170, acc=98.33%]\n\nEpoch 229/2000 Summary:\nTraining Loss: 0.5170, Accuracy: 98.33%\nEpoch 230/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.5148, acc=98.52%]\n\nEpoch 230/2000 Summary:\nTraining Loss: 0.5148, Accuracy: 98.52%\nEpoch 231/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.5252, acc=99.07%]\n\nEpoch 231/2000 Summary:\nTraining Loss: 0.5252, Accuracy: 99.07%\nEpoch 232/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.06it/s, loss=0.5326, acc=98.33%]\n\nEpoch 232/2000 Summary:\nTraining Loss: 0.5326, Accuracy: 98.33%\nEpoch 233/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.5107, acc=98.89%]\n\nEpoch 233/2000 Summary:\nTraining Loss: 0.5107, Accuracy: 98.89%\nEpoch 234/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.29it/s, loss=0.5130, acc=98.52%]\n\nEpoch 234/2000 Summary:\nTraining Loss: 0.5130, Accuracy: 98.52%\nEpoch 235/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.56it/s, loss=0.5366, acc=99.26%] \n\nEpoch 235/2000 Summary:\nTraining Loss: 0.5366, Accuracy: 99.26%\nEpoch 236/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.5132, acc=99.44%] \n\nEpoch 236/2000 Summary:\nTraining Loss: 0.5132, Accuracy: 99.44%\nEpoch 237/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.5070, acc=98.52%]\n\nEpoch 237/2000 Summary:\nTraining Loss: 0.5070, Accuracy: 98.52%\nEpoch 238/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.23it/s, loss=0.5237, acc=98.70%]\n\nEpoch 238/2000 Summary:\nTraining Loss: 0.5237, Accuracy: 98.70%\nEpoch 239/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.78it/s, loss=0.5268, acc=99.07%]\n\nEpoch 239/2000 Summary:\nTraining Loss: 0.5268, Accuracy: 99.07%\nEpoch 240/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.5238, acc=98.89%]\n\nEpoch 240/2000 Summary:\nTraining Loss: 0.5238, Accuracy: 98.89%\nEpoch 241/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.98it/s, loss=0.5010, acc=99.63%]\n\nEpoch 241/2000 Summary:\nTraining Loss: 0.5010, Accuracy: 99.63%\nEpoch 242/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.16it/s, loss=0.5132, acc=99.26%]\n\nEpoch 242/2000 Summary:\nTraining Loss: 0.5132, Accuracy: 99.26%\nEpoch 243/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.5169, acc=99.63%]\n\nEpoch 243/2000 Summary:\nTraining Loss: 0.5169, Accuracy: 99.63%\nEpoch 244/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.40it/s, loss=0.4831, acc=99.44%] \n\nEpoch 244/2000 Summary:\nTraining Loss: 0.4831, Accuracy: 99.44%\nEpoch 245/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.66it/s, loss=0.4987, acc=98.70%]\n\nEpoch 245/2000 Summary:\nTraining Loss: 0.4987, Accuracy: 98.70%\nEpoch 246/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.37it/s, loss=0.5077, acc=99.81%] \n\nEpoch 246/2000 Summary:\nTraining Loss: 0.5077, Accuracy: 99.81%\nEpoch 247/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.34it/s, loss=0.4983, acc=98.89%]\n\nEpoch 247/2000 Summary:\nTraining Loss: 0.4983, Accuracy: 98.89%\nEpoch 248/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.63it/s, loss=0.4949, acc=99.44%]\n\nEpoch 248/2000 Summary:\nTraining Loss: 0.4949, Accuracy: 99.44%\nEpoch 249/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4924, acc=99.63%]\n\nEpoch 249/2000 Summary:\nTraining Loss: 0.4924, Accuracy: 99.63%\nEpoch 250/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.33it/s, loss=0.4921, acc=99.63%]\n\nEpoch 250/2000 Summary:\nTraining Loss: 0.4921, Accuracy: 99.63%\nEpoch 251/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.5070, acc=99.81%] \n\nEpoch 251/2000 Summary:\nTraining Loss: 0.5070, Accuracy: 99.81%\nEpoch 252/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.87it/s, loss=0.4974, acc=99.07%]\n\nEpoch 252/2000 Summary:\nTraining Loss: 0.4974, Accuracy: 99.07%\nEpoch 253/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.63it/s, loss=0.5139, acc=98.52%]\n\nEpoch 253/2000 Summary:\nTraining Loss: 0.5139, Accuracy: 98.52%\nEpoch 254/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.5128, acc=99.07%]\n\nEpoch 254/2000 Summary:\nTraining Loss: 0.5128, Accuracy: 99.07%\nEpoch 255/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.48it/s, loss=0.5050, acc=99.26%]\n\nEpoch 255/2000 Summary:\nTraining Loss: 0.5050, Accuracy: 99.26%\nEpoch 256/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.5001, acc=100.00%]\n\nEpoch 256/2000 Summary:\nTraining Loss: 0.5001, Accuracy: 100.00%\nEpoch 257/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.5029, acc=99.63%] \n\nEpoch 257/2000 Summary:\nTraining Loss: 0.5029, Accuracy: 99.63%\nEpoch 258/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.5110, acc=99.44%]\n\nEpoch 258/2000 Summary:\nTraining Loss: 0.5110, Accuracy: 99.44%\nEpoch 259/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.40it/s, loss=0.4893, acc=99.63%] \n\nEpoch 259/2000 Summary:\nTraining Loss: 0.4893, Accuracy: 99.63%\nEpoch 260/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.57it/s, loss=0.5069, acc=99.81%] \n\nEpoch 260/2000 Summary:\nTraining Loss: 0.5069, Accuracy: 99.81%\nEpoch 261/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4837, acc=99.81%] \n\nEpoch 261/2000 Summary:\nTraining Loss: 0.4837, Accuracy: 99.81%\nEpoch 262/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.18it/s, loss=0.4997, acc=99.81%] \n\nEpoch 262/2000 Summary:\nTraining Loss: 0.4997, Accuracy: 99.81%\nEpoch 263/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4969, acc=100.00%]\n\nEpoch 263/2000 Summary:\nTraining Loss: 0.4969, Accuracy: 100.00%\nEpoch 264/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.56it/s, loss=0.5059, acc=99.07%]\n\nEpoch 264/2000 Summary:\nTraining Loss: 0.5059, Accuracy: 99.07%\nEpoch 265/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.4995, acc=99.63%] \n\nEpoch 265/2000 Summary:\nTraining Loss: 0.4995, Accuracy: 99.63%\nEpoch 266/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.5007, acc=100.00%]\n\nEpoch 266/2000 Summary:\nTraining Loss: 0.5007, Accuracy: 100.00%\nEpoch 267/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.55it/s, loss=0.5040, acc=99.81%]\n\nEpoch 267/2000 Summary:\nTraining Loss: 0.5040, Accuracy: 99.81%\nEpoch 268/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4812, acc=100.00%]\n\nEpoch 268/2000 Summary:\nTraining Loss: 0.4812, Accuracy: 100.00%\nEpoch 269/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.67it/s, loss=0.4846, acc=99.44%] \n\nEpoch 269/2000 Summary:\nTraining Loss: 0.4846, Accuracy: 99.44%\nEpoch 270/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.4870, acc=99.07%]\n\nEpoch 270/2000 Summary:\nTraining Loss: 0.4870, Accuracy: 99.07%\nEpoch 271/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4938, acc=100.00%]\n\nEpoch 271/2000 Summary:\nTraining Loss: 0.4938, Accuracy: 100.00%\nEpoch 272/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4998, acc=99.44%] \n\nEpoch 272/2000 Summary:\nTraining Loss: 0.4998, Accuracy: 99.44%\nEpoch 273/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.5033, acc=99.26%]\n\nEpoch 273/2000 Summary:\nTraining Loss: 0.5033, Accuracy: 99.26%\nEpoch 274/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4974, acc=99.63%] \n\nEpoch 274/2000 Summary:\nTraining Loss: 0.4974, Accuracy: 99.63%\nEpoch 275/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4780, acc=100.00%]\n\nEpoch 275/2000 Summary:\nTraining Loss: 0.4780, Accuracy: 100.00%\nEpoch 276/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.43it/s, loss=0.4633, acc=100.00%]\n\nEpoch 276/2000 Summary:\nTraining Loss: 0.4633, Accuracy: 100.00%\nEpoch 277/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4933, acc=99.63%] \n\nEpoch 277/2000 Summary:\nTraining Loss: 0.4933, Accuracy: 99.63%\nEpoch 278/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.51it/s, loss=0.4947, acc=99.81%] \n\nEpoch 278/2000 Summary:\nTraining Loss: 0.4947, Accuracy: 99.81%\nEpoch 279/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.81it/s, loss=0.4799, acc=99.81%]\n\nEpoch 279/2000 Summary:\nTraining Loss: 0.4799, Accuracy: 99.81%\nEpoch 280/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4740, acc=99.81%] \n\nEpoch 280/2000 Summary:\nTraining Loss: 0.4740, Accuracy: 99.81%\nEpoch 281/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.28it/s, loss=0.4912, acc=99.81%] \n\nEpoch 281/2000 Summary:\nTraining Loss: 0.4912, Accuracy: 99.81%\nEpoch 282/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.42it/s, loss=0.4784, acc=99.81%]\n\nEpoch 282/2000 Summary:\nTraining Loss: 0.4784, Accuracy: 99.81%\nEpoch 283/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.50it/s, loss=0.4908, acc=100.00%]\n\nEpoch 283/2000 Summary:\nTraining Loss: 0.4908, Accuracy: 100.00%\nEpoch 284/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4927, acc=99.81%]\n\nEpoch 284/2000 Summary:\nTraining Loss: 0.4927, Accuracy: 99.81%\nEpoch 285/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.4953, acc=99.44%]\n\nEpoch 285/2000 Summary:\nTraining Loss: 0.4953, Accuracy: 99.44%\nEpoch 286/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4901, acc=99.81%] \n\nEpoch 286/2000 Summary:\nTraining Loss: 0.4901, Accuracy: 99.81%\nEpoch 287/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.5026, acc=99.26%]\n\nEpoch 287/2000 Summary:\nTraining Loss: 0.5026, Accuracy: 99.26%\nEpoch 288/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4929, acc=99.81%] \n\nEpoch 288/2000 Summary:\nTraining Loss: 0.4929, Accuracy: 99.81%\nEpoch 289/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.25it/s, loss=0.4933, acc=99.81%] \n\nEpoch 289/2000 Summary:\nTraining Loss: 0.4933, Accuracy: 99.81%\nEpoch 290/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4892, acc=99.63%] \n\nEpoch 290/2000 Summary:\nTraining Loss: 0.4892, Accuracy: 99.63%\nEpoch 291/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.72it/s, loss=0.4706, acc=100.00%]\n\nEpoch 291/2000 Summary:\nTraining Loss: 0.4706, Accuracy: 100.00%\nEpoch 292/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4860, acc=99.81%] \n\nEpoch 292/2000 Summary:\nTraining Loss: 0.4860, Accuracy: 99.81%\nEpoch 293/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4894, acc=99.81%] \n\nEpoch 293/2000 Summary:\nTraining Loss: 0.4894, Accuracy: 99.81%\nEpoch 294/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.45it/s, loss=0.4712, acc=100.00%]\n\nEpoch 294/2000 Summary:\nTraining Loss: 0.4712, Accuracy: 100.00%\nEpoch 295/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.13it/s, loss=0.4901, acc=99.63%] \n\nEpoch 295/2000 Summary:\nTraining Loss: 0.4901, Accuracy: 99.63%\nEpoch 296/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.4891, acc=99.63%] \n\nEpoch 296/2000 Summary:\nTraining Loss: 0.4891, Accuracy: 99.63%\nEpoch 297/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.39it/s, loss=0.4693, acc=100.00%]\n\nEpoch 297/2000 Summary:\nTraining Loss: 0.4693, Accuracy: 100.00%\nEpoch 298/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.48it/s, loss=0.4713, acc=99.63%]\n\nEpoch 298/2000 Summary:\nTraining Loss: 0.4713, Accuracy: 99.63%\nEpoch 299/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4873, acc=100.00%]\n\nEpoch 299/2000 Summary:\nTraining Loss: 0.4873, Accuracy: 100.00%\nEpoch 300/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4696, acc=99.81%]\n\nEpoch 300/2000 Summary:\nTraining Loss: 0.4696, Accuracy: 99.81%\nEpoch 301/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.79it/s, loss=0.4824, acc=100.00%]\n\nEpoch 301/2000 Summary:\nTraining Loss: 0.4824, Accuracy: 100.00%\nEpoch 302/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4826, acc=100.00%]\n\nEpoch 302/2000 Summary:\nTraining Loss: 0.4826, Accuracy: 100.00%\nEpoch 303/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4779, acc=99.07%]\n\nEpoch 303/2000 Summary:\nTraining Loss: 0.4779, Accuracy: 99.07%\nEpoch 304/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4848, acc=99.81%]\n\nEpoch 304/2000 Summary:\nTraining Loss: 0.4848, Accuracy: 99.81%\nEpoch 305/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.41it/s, loss=0.4682, acc=100.00%]\n\nEpoch 305/2000 Summary:\nTraining Loss: 0.4682, Accuracy: 100.00%\nEpoch 306/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.00it/s, loss=0.4869, acc=99.81%]\n\nEpoch 306/2000 Summary:\nTraining Loss: 0.4869, Accuracy: 99.81%\nEpoch 307/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.4734, acc=99.63%]\n\nEpoch 307/2000 Summary:\nTraining Loss: 0.4734, Accuracy: 99.63%\nEpoch 308/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.51it/s, loss=0.4707, acc=99.81%]\n\nEpoch 308/2000 Summary:\nTraining Loss: 0.4707, Accuracy: 99.81%\nEpoch 309/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4847, acc=99.63%] \n\nEpoch 309/2000 Summary:\nTraining Loss: 0.4847, Accuracy: 99.63%\nEpoch 310/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.03it/s, loss=0.4741, acc=99.44%]\n\nEpoch 310/2000 Summary:\nTraining Loss: 0.4741, Accuracy: 99.44%\nEpoch 311/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4886, acc=99.81%] \n\nEpoch 311/2000 Summary:\nTraining Loss: 0.4886, Accuracy: 99.81%\nEpoch 312/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 49.24it/s, loss=0.4896, acc=98.14%]\n\nEpoch 312/2000 Summary:\nTraining Loss: 0.4896, Accuracy: 98.14%\nEpoch 313/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4986, acc=99.07%]\n\nEpoch 313/2000 Summary:\nTraining Loss: 0.4986, Accuracy: 99.07%\nEpoch 314/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.66it/s, loss=0.4885, acc=99.81%] \n\nEpoch 314/2000 Summary:\nTraining Loss: 0.4885, Accuracy: 99.81%\nEpoch 315/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.24it/s, loss=0.4737, acc=99.44%]\n\nEpoch 315/2000 Summary:\nTraining Loss: 0.4737, Accuracy: 99.44%\nEpoch 316/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4671, acc=100.00%]\n\nEpoch 316/2000 Summary:\nTraining Loss: 0.4671, Accuracy: 100.00%\nEpoch 317/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4651, acc=100.00%]\n\nEpoch 317/2000 Summary:\nTraining Loss: 0.4651, Accuracy: 100.00%\nEpoch 318/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.4835, acc=100.00%]\n\nEpoch 318/2000 Summary:\nTraining Loss: 0.4835, Accuracy: 100.00%\nEpoch 319/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4842, acc=99.63%] \n\nEpoch 319/2000 Summary:\nTraining Loss: 0.4842, Accuracy: 99.63%\nEpoch 320/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.06it/s, loss=0.4678, acc=100.00%]\n\nEpoch 320/2000 Summary:\nTraining Loss: 0.4678, Accuracy: 100.00%\nEpoch 321/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.30it/s, loss=0.4827, acc=99.81%]\n\nEpoch 321/2000 Summary:\nTraining Loss: 0.4827, Accuracy: 99.81%\nEpoch 322/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.56it/s, loss=0.4659, acc=99.81%]\n\nEpoch 322/2000 Summary:\nTraining Loss: 0.4659, Accuracy: 99.81%\nEpoch 323/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4809, acc=100.00%]\n\nEpoch 323/2000 Summary:\nTraining Loss: 0.4809, Accuracy: 100.00%\nEpoch 324/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4824, acc=100.00%]\n\nEpoch 324/2000 Summary:\nTraining Loss: 0.4824, Accuracy: 100.00%\nEpoch 325/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4668, acc=100.00%]\n\nEpoch 325/2000 Summary:\nTraining Loss: 0.4668, Accuracy: 100.00%\nEpoch 326/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4804, acc=100.00%]\n\nEpoch 326/2000 Summary:\nTraining Loss: 0.4804, Accuracy: 100.00%\nEpoch 327/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4787, acc=99.81%] \n\nEpoch 327/2000 Summary:\nTraining Loss: 0.4787, Accuracy: 99.81%\nEpoch 328/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.66it/s, loss=0.4658, acc=100.00%]\n\nEpoch 328/2000 Summary:\nTraining Loss: 0.4658, Accuracy: 100.00%\nEpoch 329/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.4792, acc=100.00%]\n\nEpoch 329/2000 Summary:\nTraining Loss: 0.4792, Accuracy: 100.00%\nEpoch 330/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.01it/s, loss=0.4813, acc=99.63%] \n\nEpoch 330/2000 Summary:\nTraining Loss: 0.4813, Accuracy: 99.63%\nEpoch 331/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.4826, acc=99.81%]\n\nEpoch 331/2000 Summary:\nTraining Loss: 0.4826, Accuracy: 99.81%\nEpoch 332/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.39it/s, loss=0.4779, acc=100.00%]\n\nEpoch 332/2000 Summary:\nTraining Loss: 0.4779, Accuracy: 100.00%\nEpoch 333/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4762, acc=100.00%]\n\nEpoch 333/2000 Summary:\nTraining Loss: 0.4762, Accuracy: 100.00%\nEpoch 334/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.60it/s, loss=0.4649, acc=100.00%]\n\nEpoch 334/2000 Summary:\nTraining Loss: 0.4649, Accuracy: 100.00%\nEpoch 335/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.4616, acc=100.00%]\n\nEpoch 335/2000 Summary:\nTraining Loss: 0.4616, Accuracy: 100.00%\nEpoch 336/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.98it/s, loss=0.4784, acc=99.81%] \n\nEpoch 336/2000 Summary:\nTraining Loss: 0.4784, Accuracy: 99.81%\nEpoch 337/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.86it/s, loss=0.4811, acc=99.81%]\n\nEpoch 337/2000 Summary:\nTraining Loss: 0.4811, Accuracy: 99.81%\nEpoch 338/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4684, acc=100.00%]\n\nEpoch 338/2000 Summary:\nTraining Loss: 0.4684, Accuracy: 100.00%\nEpoch 339/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.61it/s, loss=0.4641, acc=100.00%]\n\nEpoch 339/2000 Summary:\nTraining Loss: 0.4641, Accuracy: 100.00%\nEpoch 340/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4750, acc=100.00%]\n\nEpoch 340/2000 Summary:\nTraining Loss: 0.4750, Accuracy: 100.00%\nEpoch 341/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.4669, acc=99.44%]\n\nEpoch 341/2000 Summary:\nTraining Loss: 0.4669, Accuracy: 99.44%\nEpoch 342/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.50it/s, loss=0.4670, acc=99.63%]\n\nEpoch 342/2000 Summary:\nTraining Loss: 0.4670, Accuracy: 99.63%\nEpoch 343/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.4766, acc=99.81%] \n\nEpoch 343/2000 Summary:\nTraining Loss: 0.4766, Accuracy: 99.81%\nEpoch 344/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.77it/s, loss=0.4772, acc=99.81%] \n\nEpoch 344/2000 Summary:\nTraining Loss: 0.4772, Accuracy: 99.81%\nEpoch 345/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.69it/s, loss=0.4754, acc=100.00%]\n\nEpoch 345/2000 Summary:\nTraining Loss: 0.4754, Accuracy: 100.00%\nEpoch 346/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.48it/s, loss=0.4646, acc=99.63%] \n\nEpoch 346/2000 Summary:\nTraining Loss: 0.4646, Accuracy: 99.63%\nEpoch 347/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4781, acc=99.81%] \n\nEpoch 347/2000 Summary:\nTraining Loss: 0.4781, Accuracy: 99.81%\nEpoch 348/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4788, acc=99.81%] \n\nEpoch 348/2000 Summary:\nTraining Loss: 0.4788, Accuracy: 99.81%\nEpoch 349/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.55it/s, loss=0.4794, acc=99.81%] \n\nEpoch 349/2000 Summary:\nTraining Loss: 0.4794, Accuracy: 99.81%\nEpoch 350/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.42it/s, loss=0.4790, acc=99.81%]\n\nEpoch 350/2000 Summary:\nTraining Loss: 0.4790, Accuracy: 99.81%\nEpoch 351/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=0.4778, acc=100.00%]\n\nEpoch 351/2000 Summary:\nTraining Loss: 0.4778, Accuracy: 100.00%\nEpoch 352/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.99it/s, loss=0.4644, acc=99.81%] \n\nEpoch 352/2000 Summary:\nTraining Loss: 0.4644, Accuracy: 99.81%\nEpoch 353/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.33it/s, loss=0.4802, acc=100.00%]\n\nEpoch 353/2000 Summary:\nTraining Loss: 0.4802, Accuracy: 100.00%\nEpoch 354/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4768, acc=100.00%]\n\nEpoch 354/2000 Summary:\nTraining Loss: 0.4768, Accuracy: 100.00%\nEpoch 355/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4629, acc=100.00%]\n\nEpoch 355/2000 Summary:\nTraining Loss: 0.4629, Accuracy: 100.00%\nEpoch 356/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4760, acc=99.63%] \n\nEpoch 356/2000 Summary:\nTraining Loss: 0.4760, Accuracy: 99.63%\nEpoch 357/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.4705, acc=99.44%]\n\nEpoch 357/2000 Summary:\nTraining Loss: 0.4705, Accuracy: 99.44%\nEpoch 358/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=0.4870, acc=99.44%]\n\nEpoch 358/2000 Summary:\nTraining Loss: 0.4870, Accuracy: 99.44%\nEpoch 359/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.31it/s, loss=0.4644, acc=99.81%]\n\nEpoch 359/2000 Summary:\nTraining Loss: 0.4644, Accuracy: 99.81%\nEpoch 360/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.98it/s, loss=0.4765, acc=100.00%]\n\nEpoch 360/2000 Summary:\nTraining Loss: 0.4765, Accuracy: 100.00%\nEpoch 361/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4755, acc=100.00%]\n\nEpoch 361/2000 Summary:\nTraining Loss: 0.4755, Accuracy: 100.00%\nEpoch 362/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=0.4613, acc=100.00%]\n\nEpoch 362/2000 Summary:\nTraining Loss: 0.4613, Accuracy: 100.00%\nEpoch 363/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4772, acc=100.00%]\n\nEpoch 363/2000 Summary:\nTraining Loss: 0.4772, Accuracy: 100.00%\nEpoch 364/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.4685, acc=99.44%] \n\nEpoch 364/2000 Summary:\nTraining Loss: 0.4685, Accuracy: 99.44%\nEpoch 365/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.54it/s, loss=0.4820, acc=99.81%]\n\nEpoch 365/2000 Summary:\nTraining Loss: 0.4820, Accuracy: 99.81%\nEpoch 366/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.03it/s, loss=0.4597, acc=100.00%]\n\nEpoch 366/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 367/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.12it/s, loss=0.4753, acc=100.00%]\n\nEpoch 367/2000 Summary:\nTraining Loss: 0.4753, Accuracy: 100.00%\nEpoch 368/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.57it/s, loss=0.4730, acc=100.00%]\n\nEpoch 368/2000 Summary:\nTraining Loss: 0.4730, Accuracy: 100.00%\nEpoch 369/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4751, acc=99.63%] \n\nEpoch 369/2000 Summary:\nTraining Loss: 0.4751, Accuracy: 99.63%\nEpoch 370/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.47it/s, loss=0.4627, acc=100.00%]\n\nEpoch 370/2000 Summary:\nTraining Loss: 0.4627, Accuracy: 100.00%\nEpoch 371/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4812, acc=99.81%]\n\nEpoch 371/2000 Summary:\nTraining Loss: 0.4812, Accuracy: 99.81%\nEpoch 372/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.05it/s, loss=0.4743, acc=100.00%]\n\nEpoch 372/2000 Summary:\nTraining Loss: 0.4743, Accuracy: 100.00%\nEpoch 373/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.21it/s, loss=0.4743, acc=100.00%]\n\nEpoch 373/2000 Summary:\nTraining Loss: 0.4743, Accuracy: 100.00%\nEpoch 374/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=0.4801, acc=99.81%] \n\nEpoch 374/2000 Summary:\nTraining Loss: 0.4801, Accuracy: 99.81%\nEpoch 375/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=0.4760, acc=100.00%]\n\nEpoch 375/2000 Summary:\nTraining Loss: 0.4760, Accuracy: 100.00%\nEpoch 376/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.85it/s, loss=0.4756, acc=100.00%]\n\nEpoch 376/2000 Summary:\nTraining Loss: 0.4756, Accuracy: 100.00%\nEpoch 377/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.91it/s, loss=0.4607, acc=99.81%] \n\nEpoch 377/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 99.81%\nEpoch 378/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4781, acc=100.00%]\n\nEpoch 378/2000 Summary:\nTraining Loss: 0.4781, Accuracy: 100.00%\nEpoch 379/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.00it/s, loss=0.4751, acc=100.00%]\n\nEpoch 379/2000 Summary:\nTraining Loss: 0.4751, Accuracy: 100.00%\nEpoch 380/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.79it/s, loss=0.4607, acc=100.00%]\n\nEpoch 380/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 381/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.72it/s, loss=0.4741, acc=100.00%]\n\nEpoch 381/2000 Summary:\nTraining Loss: 0.4741, Accuracy: 100.00%\nEpoch 382/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.4601, acc=100.00%]\n\nEpoch 382/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 383/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=0.4597, acc=100.00%]\n\nEpoch 383/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 384/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4719, acc=100.00%]\n\nEpoch 384/2000 Summary:\nTraining Loss: 0.4719, Accuracy: 100.00%\nEpoch 385/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.53it/s, loss=0.4548, acc=100.00%]\n\nEpoch 385/2000 Summary:\nTraining Loss: 0.4548, Accuracy: 100.00%\nEpoch 386/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4702, acc=100.00%]\n\nEpoch 386/2000 Summary:\nTraining Loss: 0.4702, Accuracy: 100.00%\nEpoch 387/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.95it/s, loss=0.4566, acc=100.00%]\n\nEpoch 387/2000 Summary:\nTraining Loss: 0.4566, Accuracy: 100.00%\nEpoch 388/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.90it/s, loss=0.4724, acc=99.81%] \n\nEpoch 388/2000 Summary:\nTraining Loss: 0.4724, Accuracy: 99.81%\nEpoch 389/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.39it/s, loss=0.4606, acc=99.81%]\n\nEpoch 389/2000 Summary:\nTraining Loss: 0.4606, Accuracy: 99.81%\nEpoch 390/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.4595, acc=100.00%]\n\nEpoch 390/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 391/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.36it/s, loss=0.4581, acc=100.00%]\n\nEpoch 391/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 392/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.43it/s, loss=0.4583, acc=99.81%]\n\nEpoch 392/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 99.81%\nEpoch 393/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 44.92it/s, loss=0.4735, acc=99.81%] \n\nEpoch 393/2000 Summary:\nTraining Loss: 0.4735, Accuracy: 99.81%\nEpoch 394/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=0.4752, acc=99.81%]\n\nEpoch 394/2000 Summary:\nTraining Loss: 0.4752, Accuracy: 99.81%\nEpoch 395/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.81it/s, loss=0.4650, acc=99.26%]\n\nEpoch 395/2000 Summary:\nTraining Loss: 0.4650, Accuracy: 99.26%\nEpoch 396/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.4749, acc=99.63%] \n\nEpoch 396/2000 Summary:\nTraining Loss: 0.4749, Accuracy: 99.63%\nEpoch 397/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4665, acc=99.26%] \n\nEpoch 397/2000 Summary:\nTraining Loss: 0.4665, Accuracy: 99.26%\nEpoch 398/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.11it/s, loss=0.4811, acc=99.26%]\n\nEpoch 398/2000 Summary:\nTraining Loss: 0.4811, Accuracy: 99.26%\nEpoch 399/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4763, acc=99.81%] \n\nEpoch 399/2000 Summary:\nTraining Loss: 0.4763, Accuracy: 99.81%\nEpoch 400/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.4628, acc=99.44%]\n\nEpoch 400/2000 Summary:\nTraining Loss: 0.4628, Accuracy: 99.44%\nEpoch 401/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.90it/s, loss=0.4850, acc=98.52%]\n\nEpoch 401/2000 Summary:\nTraining Loss: 0.4850, Accuracy: 98.52%\nEpoch 402/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4713, acc=99.44%]\n\nEpoch 402/2000 Summary:\nTraining Loss: 0.4713, Accuracy: 99.44%\nEpoch 403/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4591, acc=100.00%]\n\nEpoch 403/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 404/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.25it/s, loss=0.4571, acc=100.00%]\n\nEpoch 404/2000 Summary:\nTraining Loss: 0.4571, Accuracy: 100.00%\nEpoch 405/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.82it/s, loss=0.4561, acc=100.00%]\n\nEpoch 405/2000 Summary:\nTraining Loss: 0.4561, Accuracy: 100.00%\nEpoch 406/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.46it/s, loss=0.4580, acc=100.00%]\n\nEpoch 406/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 407/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.00it/s, loss=0.4695, acc=100.00%]\n\nEpoch 407/2000 Summary:\nTraining Loss: 0.4695, Accuracy: 100.00%\nEpoch 408/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4707, acc=100.00%]\n\nEpoch 408/2000 Summary:\nTraining Loss: 0.4707, Accuracy: 100.00%\nEpoch 409/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.61it/s, loss=0.4717, acc=99.81%] \n\nEpoch 409/2000 Summary:\nTraining Loss: 0.4717, Accuracy: 99.81%\nEpoch 410/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4706, acc=100.00%]\n\nEpoch 410/2000 Summary:\nTraining Loss: 0.4706, Accuracy: 100.00%\nEpoch 411/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.38it/s, loss=0.4706, acc=100.00%]\n\nEpoch 411/2000 Summary:\nTraining Loss: 0.4706, Accuracy: 100.00%\nEpoch 412/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.69it/s, loss=0.4553, acc=99.81%]\n\nEpoch 412/2000 Summary:\nTraining Loss: 0.4553, Accuracy: 99.81%\nEpoch 413/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4676, acc=100.00%]\n\nEpoch 413/2000 Summary:\nTraining Loss: 0.4676, Accuracy: 100.00%\nEpoch 414/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.22it/s, loss=0.4697, acc=100.00%]\n\nEpoch 414/2000 Summary:\nTraining Loss: 0.4697, Accuracy: 100.00%\nEpoch 415/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4681, acc=100.00%]\n\nEpoch 415/2000 Summary:\nTraining Loss: 0.4681, Accuracy: 100.00%\nEpoch 416/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.43it/s, loss=0.4544, acc=100.00%]\n\nEpoch 416/2000 Summary:\nTraining Loss: 0.4544, Accuracy: 100.00%\nEpoch 417/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=0.4671, acc=100.00%]\n\nEpoch 417/2000 Summary:\nTraining Loss: 0.4671, Accuracy: 100.00%\nEpoch 418/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.66it/s, loss=0.4547, acc=100.00%]\n\nEpoch 418/2000 Summary:\nTraining Loss: 0.4547, Accuracy: 100.00%\nEpoch 419/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.29it/s, loss=0.4529, acc=100.00%]\n\nEpoch 419/2000 Summary:\nTraining Loss: 0.4529, Accuracy: 100.00%\nEpoch 420/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4679, acc=100.00%]\n\nEpoch 420/2000 Summary:\nTraining Loss: 0.4679, Accuracy: 100.00%\nEpoch 421/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.53it/s, loss=0.4674, acc=100.00%]\n\nEpoch 421/2000 Summary:\nTraining Loss: 0.4674, Accuracy: 100.00%\nEpoch 422/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.25it/s, loss=0.4661, acc=100.00%]\n\nEpoch 422/2000 Summary:\nTraining Loss: 0.4661, Accuracy: 100.00%\nEpoch 423/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.55it/s, loss=0.4675, acc=100.00%]\n\nEpoch 423/2000 Summary:\nTraining Loss: 0.4675, Accuracy: 100.00%\nEpoch 424/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.4658, acc=100.00%]\n\nEpoch 424/2000 Summary:\nTraining Loss: 0.4658, Accuracy: 100.00%\nEpoch 425/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.08it/s, loss=0.4545, acc=100.00%]\n\nEpoch 425/2000 Summary:\nTraining Loss: 0.4545, Accuracy: 100.00%\nEpoch 426/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.80it/s, loss=0.4543, acc=100.00%]\n\nEpoch 426/2000 Summary:\nTraining Loss: 0.4543, Accuracy: 100.00%\nEpoch 427/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=0.4551, acc=100.00%]\n\nEpoch 427/2000 Summary:\nTraining Loss: 0.4551, Accuracy: 100.00%\nEpoch 428/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.46it/s, loss=0.4696, acc=100.00%]\n\nEpoch 428/2000 Summary:\nTraining Loss: 0.4696, Accuracy: 100.00%\nEpoch 429/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=0.4544, acc=100.00%]\n\nEpoch 429/2000 Summary:\nTraining Loss: 0.4544, Accuracy: 100.00%\nEpoch 430/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.28it/s, loss=0.4589, acc=100.00%]\n\nEpoch 430/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 431/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4675, acc=100.00%]\n\nEpoch 431/2000 Summary:\nTraining Loss: 0.4675, Accuracy: 100.00%\nEpoch 432/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4528, acc=100.00%]\n\nEpoch 432/2000 Summary:\nTraining Loss: 0.4528, Accuracy: 100.00%\nEpoch 433/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.42it/s, loss=0.4524, acc=100.00%]\n\nEpoch 433/2000 Summary:\nTraining Loss: 0.4524, Accuracy: 100.00%\nEpoch 434/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4684, acc=100.00%]\n\nEpoch 434/2000 Summary:\nTraining Loss: 0.4684, Accuracy: 100.00%\nEpoch 435/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.37it/s, loss=0.4544, acc=99.81%] \n\nEpoch 435/2000 Summary:\nTraining Loss: 0.4544, Accuracy: 99.81%\nEpoch 436/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.4671, acc=100.00%]\n\nEpoch 436/2000 Summary:\nTraining Loss: 0.4671, Accuracy: 100.00%\nEpoch 437/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4674, acc=100.00%]\n\nEpoch 437/2000 Summary:\nTraining Loss: 0.4674, Accuracy: 100.00%\nEpoch 438/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.73it/s, loss=0.4692, acc=100.00%]\n\nEpoch 438/2000 Summary:\nTraining Loss: 0.4692, Accuracy: 100.00%\nEpoch 439/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4582, acc=99.81%]\n\nEpoch 439/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 99.81%\nEpoch 440/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.48it/s, loss=0.4523, acc=100.00%]\n\nEpoch 440/2000 Summary:\nTraining Loss: 0.4523, Accuracy: 100.00%\nEpoch 441/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.56it/s, loss=0.4543, acc=100.00%]\n\nEpoch 441/2000 Summary:\nTraining Loss: 0.4543, Accuracy: 100.00%\nEpoch 442/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.4681, acc=100.00%]\n\nEpoch 442/2000 Summary:\nTraining Loss: 0.4681, Accuracy: 100.00%\nEpoch 443/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.51it/s, loss=0.4540, acc=100.00%]\n\nEpoch 443/2000 Summary:\nTraining Loss: 0.4540, Accuracy: 100.00%\nEpoch 444/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 49.01it/s, loss=0.4532, acc=100.00%]\n\nEpoch 444/2000 Summary:\nTraining Loss: 0.4532, Accuracy: 100.00%\nEpoch 445/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4708, acc=99.63%] \n\nEpoch 445/2000 Summary:\nTraining Loss: 0.4708, Accuracy: 99.63%\nEpoch 446/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.4668, acc=99.07%]\n\nEpoch 446/2000 Summary:\nTraining Loss: 0.4668, Accuracy: 99.07%\nEpoch 447/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.01it/s, loss=0.4901, acc=99.07%]\n\nEpoch 447/2000 Summary:\nTraining Loss: 0.4901, Accuracy: 99.07%\nEpoch 448/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.4775, acc=99.81%]\n\nEpoch 448/2000 Summary:\nTraining Loss: 0.4775, Accuracy: 99.81%\nEpoch 449/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.72it/s, loss=0.4708, acc=100.00%]\n\nEpoch 449/2000 Summary:\nTraining Loss: 0.4708, Accuracy: 100.00%\nEpoch 450/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.52it/s, loss=0.4703, acc=99.81%] \n\nEpoch 450/2000 Summary:\nTraining Loss: 0.4703, Accuracy: 99.81%\nEpoch 451/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.22it/s, loss=0.4715, acc=100.00%]\n\nEpoch 451/2000 Summary:\nTraining Loss: 0.4715, Accuracy: 100.00%\nEpoch 452/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4519, acc=100.00%]\n\nEpoch 452/2000 Summary:\nTraining Loss: 0.4519, Accuracy: 100.00%\nEpoch 453/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.80it/s, loss=0.4693, acc=100.00%]\n\nEpoch 453/2000 Summary:\nTraining Loss: 0.4693, Accuracy: 100.00%\nEpoch 454/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4705, acc=100.00%]\n\nEpoch 454/2000 Summary:\nTraining Loss: 0.4705, Accuracy: 100.00%\nEpoch 455/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.97it/s, loss=0.4684, acc=100.00%]\n\nEpoch 455/2000 Summary:\nTraining Loss: 0.4684, Accuracy: 100.00%\nEpoch 456/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.00it/s, loss=0.4668, acc=100.00%]\n\nEpoch 456/2000 Summary:\nTraining Loss: 0.4668, Accuracy: 100.00%\nEpoch 457/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4572, acc=99.63%] \n\nEpoch 457/2000 Summary:\nTraining Loss: 0.4572, Accuracy: 99.63%\nEpoch 458/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.4666, acc=100.00%]\n\nEpoch 458/2000 Summary:\nTraining Loss: 0.4666, Accuracy: 100.00%\nEpoch 459/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4668, acc=100.00%]\n\nEpoch 459/2000 Summary:\nTraining Loss: 0.4668, Accuracy: 100.00%\nEpoch 460/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.82it/s, loss=0.4658, acc=100.00%]\n\nEpoch 460/2000 Summary:\nTraining Loss: 0.4658, Accuracy: 100.00%\nEpoch 461/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.56it/s, loss=0.4522, acc=100.00%]\n\nEpoch 461/2000 Summary:\nTraining Loss: 0.4522, Accuracy: 100.00%\nEpoch 462/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4692, acc=100.00%]\n\nEpoch 462/2000 Summary:\nTraining Loss: 0.4692, Accuracy: 100.00%\nEpoch 463/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.02it/s, loss=0.4653, acc=100.00%]\n\nEpoch 463/2000 Summary:\nTraining Loss: 0.4653, Accuracy: 100.00%\nEpoch 464/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4509, acc=100.00%]\n\nEpoch 464/2000 Summary:\nTraining Loss: 0.4509, Accuracy: 100.00%\nEpoch 465/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.4663, acc=100.00%]\n\nEpoch 465/2000 Summary:\nTraining Loss: 0.4663, Accuracy: 100.00%\nEpoch 466/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4650, acc=100.00%]\n\nEpoch 466/2000 Summary:\nTraining Loss: 0.4650, Accuracy: 100.00%\nEpoch 467/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.65it/s, loss=0.4533, acc=100.00%]\n\nEpoch 467/2000 Summary:\nTraining Loss: 0.4533, Accuracy: 100.00%\nEpoch 468/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.55it/s, loss=0.4540, acc=100.00%]\n\nEpoch 468/2000 Summary:\nTraining Loss: 0.4540, Accuracy: 100.00%\nEpoch 469/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.20it/s, loss=0.4528, acc=100.00%]\n\nEpoch 469/2000 Summary:\nTraining Loss: 0.4528, Accuracy: 100.00%\nEpoch 470/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.98it/s, loss=0.4697, acc=100.00%]\n\nEpoch 470/2000 Summary:\nTraining Loss: 0.4697, Accuracy: 100.00%\nEpoch 471/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.18it/s, loss=0.4757, acc=99.63%] \n\nEpoch 471/2000 Summary:\nTraining Loss: 0.4757, Accuracy: 99.63%\nEpoch 472/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4814, acc=99.26%]\n\nEpoch 472/2000 Summary:\nTraining Loss: 0.4814, Accuracy: 99.26%\nEpoch 473/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4752, acc=99.63%]\n\nEpoch 473/2000 Summary:\nTraining Loss: 0.4752, Accuracy: 99.63%\nEpoch 474/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=0.4555, acc=100.00%]\n\nEpoch 474/2000 Summary:\nTraining Loss: 0.4555, Accuracy: 100.00%\nEpoch 475/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.45it/s, loss=0.4641, acc=99.07%] \n\nEpoch 475/2000 Summary:\nTraining Loss: 0.4641, Accuracy: 99.07%\nEpoch 476/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.4883, acc=98.89%]\n\nEpoch 476/2000 Summary:\nTraining Loss: 0.4883, Accuracy: 98.89%\nEpoch 477/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.12it/s, loss=0.4754, acc=99.81%] \n\nEpoch 477/2000 Summary:\nTraining Loss: 0.4754, Accuracy: 99.81%\nEpoch 478/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.4539, acc=99.26%]\n\nEpoch 478/2000 Summary:\nTraining Loss: 0.4539, Accuracy: 99.26%\nEpoch 479/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.03it/s, loss=0.4807, acc=99.44%]\n\nEpoch 479/2000 Summary:\nTraining Loss: 0.4807, Accuracy: 99.44%\nEpoch 480/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.07it/s, loss=0.4740, acc=99.63%]\n\nEpoch 480/2000 Summary:\nTraining Loss: 0.4740, Accuracy: 99.63%\nEpoch 481/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4718, acc=99.81%]\n\nEpoch 481/2000 Summary:\nTraining Loss: 0.4718, Accuracy: 99.81%\nEpoch 482/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.43it/s, loss=0.4535, acc=100.00%]\n\nEpoch 482/2000 Summary:\nTraining Loss: 0.4535, Accuracy: 100.00%\nEpoch 483/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4647, acc=100.00%]\n\nEpoch 483/2000 Summary:\nTraining Loss: 0.4647, Accuracy: 100.00%\nEpoch 484/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.69it/s, loss=0.4656, acc=100.00%]\n\nEpoch 484/2000 Summary:\nTraining Loss: 0.4656, Accuracy: 100.00%\nEpoch 485/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4650, acc=100.00%]\n\nEpoch 485/2000 Summary:\nTraining Loss: 0.4650, Accuracy: 100.00%\nEpoch 486/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4653, acc=100.00%]\n\nEpoch 486/2000 Summary:\nTraining Loss: 0.4653, Accuracy: 100.00%\nEpoch 487/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4648, acc=100.00%]\n\nEpoch 487/2000 Summary:\nTraining Loss: 0.4648, Accuracy: 100.00%\nEpoch 488/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.4658, acc=100.00%]\n\nEpoch 488/2000 Summary:\nTraining Loss: 0.4658, Accuracy: 100.00%\nEpoch 489/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.4556, acc=99.81%] \n\nEpoch 489/2000 Summary:\nTraining Loss: 0.4556, Accuracy: 99.81%\nEpoch 490/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.91it/s, loss=0.4534, acc=99.81%]\n\nEpoch 490/2000 Summary:\nTraining Loss: 0.4534, Accuracy: 99.81%\nEpoch 491/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4656, acc=100.00%]\n\nEpoch 491/2000 Summary:\nTraining Loss: 0.4656, Accuracy: 100.00%\nEpoch 492/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.60it/s, loss=0.4684, acc=99.81%]\n\nEpoch 492/2000 Summary:\nTraining Loss: 0.4684, Accuracy: 99.81%\nEpoch 493/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4656, acc=100.00%]\n\nEpoch 493/2000 Summary:\nTraining Loss: 0.4656, Accuracy: 100.00%\nEpoch 494/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4639, acc=100.00%]\n\nEpoch 494/2000 Summary:\nTraining Loss: 0.4639, Accuracy: 100.00%\nEpoch 495/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4649, acc=100.00%]\n\nEpoch 495/2000 Summary:\nTraining Loss: 0.4649, Accuracy: 100.00%\nEpoch 496/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4647, acc=100.00%]\n\nEpoch 496/2000 Summary:\nTraining Loss: 0.4647, Accuracy: 100.00%\nEpoch 497/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.52it/s, loss=0.4530, acc=100.00%]\n\nEpoch 497/2000 Summary:\nTraining Loss: 0.4530, Accuracy: 100.00%\nEpoch 498/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.62it/s, loss=0.4645, acc=100.00%]\n\nEpoch 498/2000 Summary:\nTraining Loss: 0.4645, Accuracy: 100.00%\nEpoch 499/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.02it/s, loss=0.4645, acc=100.00%]\n\nEpoch 499/2000 Summary:\nTraining Loss: 0.4645, Accuracy: 100.00%\nEpoch 500/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.80it/s, loss=0.4628, acc=100.00%]\n\nEpoch 500/2000 Summary:\nTraining Loss: 0.4628, Accuracy: 100.00%\nEpoch 501/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.57it/s, loss=0.4488, acc=100.00%]\n\nEpoch 501/2000 Summary:\nTraining Loss: 0.4488, Accuracy: 100.00%\nEpoch 502/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4503, acc=100.00%]\n\nEpoch 502/2000 Summary:\nTraining Loss: 0.4503, Accuracy: 100.00%\nEpoch 503/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.31it/s, loss=0.4631, acc=100.00%]\n\nEpoch 503/2000 Summary:\nTraining Loss: 0.4631, Accuracy: 100.00%\nEpoch 504/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.41it/s, loss=0.4486, acc=100.00%]\n\nEpoch 504/2000 Summary:\nTraining Loss: 0.4486, Accuracy: 100.00%\nEpoch 505/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.09it/s, loss=0.4668, acc=100.00%]\n\nEpoch 505/2000 Summary:\nTraining Loss: 0.4668, Accuracy: 100.00%\nEpoch 506/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4513, acc=100.00%]\n\nEpoch 506/2000 Summary:\nTraining Loss: 0.4513, Accuracy: 100.00%\nEpoch 507/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.90it/s, loss=0.4504, acc=100.00%]\n\nEpoch 507/2000 Summary:\nTraining Loss: 0.4504, Accuracy: 100.00%\nEpoch 508/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.29it/s, loss=0.4527, acc=99.63%] \n\nEpoch 508/2000 Summary:\nTraining Loss: 0.4527, Accuracy: 99.63%\nEpoch 509/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4667, acc=100.00%]\n\nEpoch 509/2000 Summary:\nTraining Loss: 0.4667, Accuracy: 100.00%\nEpoch 510/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.36it/s, loss=0.4707, acc=99.63%] \n\nEpoch 510/2000 Summary:\nTraining Loss: 0.4707, Accuracy: 99.63%\nEpoch 511/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.29it/s, loss=0.4642, acc=100.00%]\n\nEpoch 511/2000 Summary:\nTraining Loss: 0.4642, Accuracy: 100.00%\nEpoch 512/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.70it/s, loss=0.4669, acc=100.00%]\n\nEpoch 512/2000 Summary:\nTraining Loss: 0.4669, Accuracy: 100.00%\nEpoch 513/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.4558, acc=99.63%] \n\nEpoch 513/2000 Summary:\nTraining Loss: 0.4558, Accuracy: 99.63%\nEpoch 514/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.55it/s, loss=0.4757, acc=99.63%]\n\nEpoch 514/2000 Summary:\nTraining Loss: 0.4757, Accuracy: 99.63%\nEpoch 515/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.28it/s, loss=0.4630, acc=99.44%]\n\nEpoch 515/2000 Summary:\nTraining Loss: 0.4630, Accuracy: 99.44%\nEpoch 516/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4686, acc=100.00%]\n\nEpoch 516/2000 Summary:\nTraining Loss: 0.4686, Accuracy: 100.00%\nEpoch 517/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4656, acc=100.00%]\n\nEpoch 517/2000 Summary:\nTraining Loss: 0.4656, Accuracy: 100.00%\nEpoch 518/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.54it/s, loss=0.4634, acc=100.00%]\n\nEpoch 518/2000 Summary:\nTraining Loss: 0.4634, Accuracy: 100.00%\nEpoch 519/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.46it/s, loss=0.4641, acc=100.00%]\n\nEpoch 519/2000 Summary:\nTraining Loss: 0.4641, Accuracy: 100.00%\nEpoch 520/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4492, acc=100.00%]\n\nEpoch 520/2000 Summary:\nTraining Loss: 0.4492, Accuracy: 100.00%\nEpoch 521/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4498, acc=100.00%]\n\nEpoch 521/2000 Summary:\nTraining Loss: 0.4498, Accuracy: 100.00%\nEpoch 522/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.06it/s, loss=0.4633, acc=100.00%]\n\nEpoch 522/2000 Summary:\nTraining Loss: 0.4633, Accuracy: 100.00%\nEpoch 523/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4499, acc=100.00%]\n\nEpoch 523/2000 Summary:\nTraining Loss: 0.4499, Accuracy: 100.00%\nEpoch 524/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.44it/s, loss=0.4640, acc=100.00%]\n\nEpoch 524/2000 Summary:\nTraining Loss: 0.4640, Accuracy: 100.00%\nEpoch 525/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4640, acc=100.00%]\n\nEpoch 525/2000 Summary:\nTraining Loss: 0.4640, Accuracy: 100.00%\nEpoch 526/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4637, acc=100.00%]\n\nEpoch 526/2000 Summary:\nTraining Loss: 0.4637, Accuracy: 100.00%\nEpoch 527/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4504, acc=100.00%]\n\nEpoch 527/2000 Summary:\nTraining Loss: 0.4504, Accuracy: 100.00%\nEpoch 528/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4625, acc=100.00%]\n\nEpoch 528/2000 Summary:\nTraining Loss: 0.4625, Accuracy: 100.00%\nEpoch 529/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.33it/s, loss=0.4498, acc=100.00%]\n\nEpoch 529/2000 Summary:\nTraining Loss: 0.4498, Accuracy: 100.00%\nEpoch 530/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.61it/s, loss=0.4628, acc=100.00%]\n\nEpoch 530/2000 Summary:\nTraining Loss: 0.4628, Accuracy: 100.00%\nEpoch 531/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.25it/s, loss=0.4489, acc=100.00%]\n\nEpoch 531/2000 Summary:\nTraining Loss: 0.4489, Accuracy: 100.00%\nEpoch 532/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.41it/s, loss=0.4494, acc=100.00%]\n\nEpoch 532/2000 Summary:\nTraining Loss: 0.4494, Accuracy: 100.00%\nEpoch 533/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.50it/s, loss=0.4630, acc=100.00%]\n\nEpoch 533/2000 Summary:\nTraining Loss: 0.4630, Accuracy: 100.00%\nEpoch 534/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4493, acc=100.00%]\n\nEpoch 534/2000 Summary:\nTraining Loss: 0.4493, Accuracy: 100.00%\nEpoch 535/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4683, acc=99.81%] \n\nEpoch 535/2000 Summary:\nTraining Loss: 0.4683, Accuracy: 99.81%\nEpoch 536/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4657, acc=100.00%]\n\nEpoch 536/2000 Summary:\nTraining Loss: 0.4657, Accuracy: 100.00%\nEpoch 537/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4693, acc=99.81%] \n\nEpoch 537/2000 Summary:\nTraining Loss: 0.4693, Accuracy: 99.81%\nEpoch 538/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.64it/s, loss=0.4645, acc=99.81%] \n\nEpoch 538/2000 Summary:\nTraining Loss: 0.4645, Accuracy: 99.81%\nEpoch 539/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4716, acc=99.81%]\n\nEpoch 539/2000 Summary:\nTraining Loss: 0.4716, Accuracy: 99.81%\nEpoch 540/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4702, acc=99.63%]\n\nEpoch 540/2000 Summary:\nTraining Loss: 0.4702, Accuracy: 99.63%\nEpoch 541/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.15it/s, loss=0.4914, acc=98.52%]\n\nEpoch 541/2000 Summary:\nTraining Loss: 0.4914, Accuracy: 98.52%\nEpoch 542/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.31it/s, loss=0.4981, acc=97.03%]\n\nEpoch 542/2000 Summary:\nTraining Loss: 0.4981, Accuracy: 97.03%\nEpoch 543/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.74it/s, loss=0.4833, acc=99.44%]\n\nEpoch 543/2000 Summary:\nTraining Loss: 0.4833, Accuracy: 99.44%\nEpoch 544/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.12it/s, loss=0.4625, acc=99.44%] \n\nEpoch 544/2000 Summary:\nTraining Loss: 0.4625, Accuracy: 99.44%\nEpoch 545/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=0.4726, acc=99.81%] \n\nEpoch 545/2000 Summary:\nTraining Loss: 0.4726, Accuracy: 99.81%\nEpoch 546/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4689, acc=99.63%]\n\nEpoch 546/2000 Summary:\nTraining Loss: 0.4689, Accuracy: 99.63%\nEpoch 547/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.63it/s, loss=0.4670, acc=100.00%]\n\nEpoch 547/2000 Summary:\nTraining Loss: 0.4670, Accuracy: 100.00%\nEpoch 548/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.4528, acc=100.00%]\n\nEpoch 548/2000 Summary:\nTraining Loss: 0.4528, Accuracy: 100.00%\nEpoch 549/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.12it/s, loss=0.4653, acc=100.00%]\n\nEpoch 549/2000 Summary:\nTraining Loss: 0.4653, Accuracy: 100.00%\nEpoch 550/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.76it/s, loss=0.4504, acc=100.00%]\n\nEpoch 550/2000 Summary:\nTraining Loss: 0.4504, Accuracy: 100.00%\nEpoch 551/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.00it/s, loss=0.4631, acc=100.00%]\n\nEpoch 551/2000 Summary:\nTraining Loss: 0.4631, Accuracy: 100.00%\nEpoch 552/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.11it/s, loss=0.4488, acc=100.00%]\n\nEpoch 552/2000 Summary:\nTraining Loss: 0.4488, Accuracy: 100.00%\nEpoch 553/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.4512, acc=99.81%] \n\nEpoch 553/2000 Summary:\nTraining Loss: 0.4512, Accuracy: 99.81%\nEpoch 554/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.4613, acc=100.00%]\n\nEpoch 554/2000 Summary:\nTraining Loss: 0.4613, Accuracy: 100.00%\nEpoch 555/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4493, acc=100.00%]\n\nEpoch 555/2000 Summary:\nTraining Loss: 0.4493, Accuracy: 100.00%\nEpoch 556/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.4481, acc=100.00%]\n\nEpoch 556/2000 Summary:\nTraining Loss: 0.4481, Accuracy: 100.00%\nEpoch 557/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4490, acc=100.00%]\n\nEpoch 557/2000 Summary:\nTraining Loss: 0.4490, Accuracy: 100.00%\nEpoch 558/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.40it/s, loss=0.4616, acc=100.00%]\n\nEpoch 558/2000 Summary:\nTraining Loss: 0.4616, Accuracy: 100.00%\nEpoch 559/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.4639, acc=100.00%]\n\nEpoch 559/2000 Summary:\nTraining Loss: 0.4639, Accuracy: 100.00%\nEpoch 560/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.37it/s, loss=0.4508, acc=100.00%]\n\nEpoch 560/2000 Summary:\nTraining Loss: 0.4508, Accuracy: 100.00%\nEpoch 561/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.89it/s, loss=0.4632, acc=100.00%]\n\nEpoch 561/2000 Summary:\nTraining Loss: 0.4632, Accuracy: 100.00%\nEpoch 562/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4630, acc=100.00%]\n\nEpoch 562/2000 Summary:\nTraining Loss: 0.4630, Accuracy: 100.00%\nEpoch 563/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.51it/s, loss=0.4633, acc=100.00%]\n\nEpoch 563/2000 Summary:\nTraining Loss: 0.4633, Accuracy: 100.00%\nEpoch 564/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.52it/s, loss=0.4630, acc=100.00%]\n\nEpoch 564/2000 Summary:\nTraining Loss: 0.4630, Accuracy: 100.00%\nEpoch 565/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.13it/s, loss=0.4646, acc=100.00%]\n\nEpoch 565/2000 Summary:\nTraining Loss: 0.4646, Accuracy: 100.00%\nEpoch 566/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.60it/s, loss=0.4645, acc=100.00%]\n\nEpoch 566/2000 Summary:\nTraining Loss: 0.4645, Accuracy: 100.00%\nEpoch 567/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.23it/s, loss=0.4631, acc=100.00%]\n\nEpoch 567/2000 Summary:\nTraining Loss: 0.4631, Accuracy: 100.00%\nEpoch 568/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=0.4638, acc=100.00%]\n\nEpoch 568/2000 Summary:\nTraining Loss: 0.4638, Accuracy: 100.00%\nEpoch 569/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.4625, acc=100.00%]\n\nEpoch 569/2000 Summary:\nTraining Loss: 0.4625, Accuracy: 100.00%\nEpoch 570/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4643, acc=100.00%]\n\nEpoch 570/2000 Summary:\nTraining Loss: 0.4643, Accuracy: 100.00%\nEpoch 571/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4631, acc=100.00%]\n\nEpoch 571/2000 Summary:\nTraining Loss: 0.4631, Accuracy: 100.00%\nEpoch 572/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4654, acc=99.81%] \n\nEpoch 572/2000 Summary:\nTraining Loss: 0.4654, Accuracy: 99.81%\nEpoch 573/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4616, acc=98.89%]\n\nEpoch 573/2000 Summary:\nTraining Loss: 0.4616, Accuracy: 98.89%\nEpoch 574/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.07it/s, loss=0.4717, acc=99.81%]\n\nEpoch 574/2000 Summary:\nTraining Loss: 0.4717, Accuracy: 99.81%\nEpoch 575/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4803, acc=99.07%]\n\nEpoch 575/2000 Summary:\nTraining Loss: 0.4803, Accuracy: 99.07%\nEpoch 576/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.16it/s, loss=0.4661, acc=100.00%]\n\nEpoch 576/2000 Summary:\nTraining Loss: 0.4661, Accuracy: 100.00%\nEpoch 577/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.4675, acc=100.00%]\n\nEpoch 577/2000 Summary:\nTraining Loss: 0.4675, Accuracy: 100.00%\nEpoch 578/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4695, acc=99.44%]\n\nEpoch 578/2000 Summary:\nTraining Loss: 0.4695, Accuracy: 99.44%\nEpoch 579/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.78it/s, loss=0.4697, acc=99.81%] \n\nEpoch 579/2000 Summary:\nTraining Loss: 0.4697, Accuracy: 99.81%\nEpoch 580/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.4962, acc=97.96%]\n\nEpoch 580/2000 Summary:\nTraining Loss: 0.4962, Accuracy: 97.96%\nEpoch 581/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.34it/s, loss=0.4725, acc=99.07%]\n\nEpoch 581/2000 Summary:\nTraining Loss: 0.4725, Accuracy: 99.07%\nEpoch 582/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.48it/s, loss=0.4555, acc=100.00%]\n\nEpoch 582/2000 Summary:\nTraining Loss: 0.4555, Accuracy: 100.00%\nEpoch 583/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.94it/s, loss=0.4682, acc=99.81%] \n\nEpoch 583/2000 Summary:\nTraining Loss: 0.4682, Accuracy: 99.81%\nEpoch 584/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.54it/s, loss=0.4657, acc=100.00%]\n\nEpoch 584/2000 Summary:\nTraining Loss: 0.4657, Accuracy: 100.00%\nEpoch 585/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.38it/s, loss=0.4533, acc=100.00%]\n\nEpoch 585/2000 Summary:\nTraining Loss: 0.4533, Accuracy: 100.00%\nEpoch 586/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=0.4655, acc=99.81%] \n\nEpoch 586/2000 Summary:\nTraining Loss: 0.4655, Accuracy: 99.81%\nEpoch 587/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4652, acc=100.00%]\n\nEpoch 587/2000 Summary:\nTraining Loss: 0.4652, Accuracy: 100.00%\nEpoch 588/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.4665, acc=100.00%]\n\nEpoch 588/2000 Summary:\nTraining Loss: 0.4665, Accuracy: 100.00%\nEpoch 589/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.28it/s, loss=0.4495, acc=100.00%]\n\nEpoch 589/2000 Summary:\nTraining Loss: 0.4495, Accuracy: 100.00%\nEpoch 590/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.37it/s, loss=0.4649, acc=100.00%]\n\nEpoch 590/2000 Summary:\nTraining Loss: 0.4649, Accuracy: 100.00%\nEpoch 591/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.99it/s, loss=0.4625, acc=100.00%]\n\nEpoch 591/2000 Summary:\nTraining Loss: 0.4625, Accuracy: 100.00%\nEpoch 592/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.24it/s, loss=0.4627, acc=100.00%]\n\nEpoch 592/2000 Summary:\nTraining Loss: 0.4627, Accuracy: 100.00%\nEpoch 593/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.50it/s, loss=0.4666, acc=99.81%] \n\nEpoch 593/2000 Summary:\nTraining Loss: 0.4666, Accuracy: 99.81%\nEpoch 594/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4630, acc=100.00%]\n\nEpoch 594/2000 Summary:\nTraining Loss: 0.4630, Accuracy: 100.00%\nEpoch 595/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.4479, acc=100.00%]\n\nEpoch 595/2000 Summary:\nTraining Loss: 0.4479, Accuracy: 100.00%\nEpoch 596/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.59it/s, loss=0.4495, acc=100.00%]\n\nEpoch 596/2000 Summary:\nTraining Loss: 0.4495, Accuracy: 100.00%\nEpoch 597/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.84it/s, loss=0.4628, acc=100.00%]\n\nEpoch 597/2000 Summary:\nTraining Loss: 0.4628, Accuracy: 100.00%\nEpoch 598/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=0.4611, acc=100.00%]\n\nEpoch 598/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 599/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.56it/s, loss=0.4530, acc=99.44%] \n\nEpoch 599/2000 Summary:\nTraining Loss: 0.4530, Accuracy: 99.44%\nEpoch 600/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.25it/s, loss=0.4876, acc=98.33%]\n\nEpoch 600/2000 Summary:\nTraining Loss: 0.4876, Accuracy: 98.33%\nEpoch 601/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4814, acc=98.33%]\n\nEpoch 601/2000 Summary:\nTraining Loss: 0.4814, Accuracy: 98.33%\nEpoch 602/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.75it/s, loss=0.4649, acc=99.44%]\n\nEpoch 602/2000 Summary:\nTraining Loss: 0.4649, Accuracy: 99.44%\nEpoch 603/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.31it/s, loss=0.4708, acc=99.81%] \n\nEpoch 603/2000 Summary:\nTraining Loss: 0.4708, Accuracy: 99.81%\nEpoch 604/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4697, acc=99.81%] \n\nEpoch 604/2000 Summary:\nTraining Loss: 0.4697, Accuracy: 99.81%\nEpoch 605/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4743, acc=99.44%] \n\nEpoch 605/2000 Summary:\nTraining Loss: 0.4743, Accuracy: 99.44%\nEpoch 606/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4771, acc=99.26%] \n\nEpoch 606/2000 Summary:\nTraining Loss: 0.4771, Accuracy: 99.26%\nEpoch 607/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.49it/s, loss=0.4685, acc=99.81%]\n\nEpoch 607/2000 Summary:\nTraining Loss: 0.4685, Accuracy: 99.81%\nEpoch 608/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.86it/s, loss=0.4663, acc=100.00%]\n\nEpoch 608/2000 Summary:\nTraining Loss: 0.4663, Accuracy: 100.00%\nEpoch 609/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.38it/s, loss=0.4657, acc=100.00%]\n\nEpoch 609/2000 Summary:\nTraining Loss: 0.4657, Accuracy: 100.00%\nEpoch 610/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4644, acc=100.00%]\n\nEpoch 610/2000 Summary:\nTraining Loss: 0.4644, Accuracy: 100.00%\nEpoch 611/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4629, acc=100.00%]\n\nEpoch 611/2000 Summary:\nTraining Loss: 0.4629, Accuracy: 100.00%\nEpoch 612/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.15it/s, loss=0.4633, acc=100.00%]\n\nEpoch 612/2000 Summary:\nTraining Loss: 0.4633, Accuracy: 100.00%\nEpoch 613/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.4627, acc=100.00%]\n\nEpoch 613/2000 Summary:\nTraining Loss: 0.4627, Accuracy: 100.00%\nEpoch 614/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.45it/s, loss=0.4626, acc=100.00%]\n\nEpoch 614/2000 Summary:\nTraining Loss: 0.4626, Accuracy: 100.00%\nEpoch 615/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.16it/s, loss=0.4620, acc=100.00%]\n\nEpoch 615/2000 Summary:\nTraining Loss: 0.4620, Accuracy: 100.00%\nEpoch 616/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.89it/s, loss=0.4629, acc=100.00%]\n\nEpoch 616/2000 Summary:\nTraining Loss: 0.4629, Accuracy: 100.00%\nEpoch 617/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.05it/s, loss=0.4619, acc=100.00%]\n\nEpoch 617/2000 Summary:\nTraining Loss: 0.4619, Accuracy: 100.00%\nEpoch 618/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.4475, acc=100.00%]\n\nEpoch 618/2000 Summary:\nTraining Loss: 0.4475, Accuracy: 100.00%\nEpoch 619/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.38it/s, loss=0.4353, acc=100.00%]\n\nEpoch 619/2000 Summary:\nTraining Loss: 0.4353, Accuracy: 100.00%\nEpoch 620/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.37it/s, loss=0.4630, acc=100.00%]\n\nEpoch 620/2000 Summary:\nTraining Loss: 0.4630, Accuracy: 100.00%\nEpoch 621/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4620, acc=100.00%]\n\nEpoch 621/2000 Summary:\nTraining Loss: 0.4620, Accuracy: 100.00%\nEpoch 622/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.33it/s, loss=0.4624, acc=100.00%]\n\nEpoch 622/2000 Summary:\nTraining Loss: 0.4624, Accuracy: 100.00%\nEpoch 623/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.29it/s, loss=0.4481, acc=100.00%]\n\nEpoch 623/2000 Summary:\nTraining Loss: 0.4481, Accuracy: 100.00%\nEpoch 624/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.82it/s, loss=0.4614, acc=100.00%]\n\nEpoch 624/2000 Summary:\nTraining Loss: 0.4614, Accuracy: 100.00%\nEpoch 625/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.4609, acc=100.00%]\n\nEpoch 625/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 100.00%\nEpoch 626/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4618, acc=100.00%]\n\nEpoch 626/2000 Summary:\nTraining Loss: 0.4618, Accuracy: 100.00%\nEpoch 627/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4479, acc=100.00%]\n\nEpoch 627/2000 Summary:\nTraining Loss: 0.4479, Accuracy: 100.00%\nEpoch 628/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.25it/s, loss=0.4606, acc=100.00%]\n\nEpoch 628/2000 Summary:\nTraining Loss: 0.4606, Accuracy: 100.00%\nEpoch 629/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4621, acc=100.00%]\n\nEpoch 629/2000 Summary:\nTraining Loss: 0.4621, Accuracy: 100.00%\nEpoch 630/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.66it/s, loss=0.4611, acc=100.00%]\n\nEpoch 630/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 631/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.48it/s, loss=0.4471, acc=100.00%]\n\nEpoch 631/2000 Summary:\nTraining Loss: 0.4471, Accuracy: 100.00%\nEpoch 632/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.68it/s, loss=0.4607, acc=100.00%]\n\nEpoch 632/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 633/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.82it/s, loss=0.4475, acc=100.00%]\n\nEpoch 633/2000 Summary:\nTraining Loss: 0.4475, Accuracy: 100.00%\nEpoch 634/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 49.02it/s, loss=0.4472, acc=100.00%]\n\nEpoch 634/2000 Summary:\nTraining Loss: 0.4472, Accuracy: 100.00%\nEpoch 635/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.95it/s, loss=0.4477, acc=100.00%]\n\nEpoch 635/2000 Summary:\nTraining Loss: 0.4477, Accuracy: 100.00%\nEpoch 636/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4486, acc=100.00%]\n\nEpoch 636/2000 Summary:\nTraining Loss: 0.4486, Accuracy: 100.00%\nEpoch 637/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.25it/s, loss=0.4620, acc=100.00%]\n\nEpoch 637/2000 Summary:\nTraining Loss: 0.4620, Accuracy: 100.00%\nEpoch 638/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.43it/s, loss=0.4485, acc=100.00%]\n\nEpoch 638/2000 Summary:\nTraining Loss: 0.4485, Accuracy: 100.00%\nEpoch 639/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.4619, acc=100.00%]\n\nEpoch 639/2000 Summary:\nTraining Loss: 0.4619, Accuracy: 100.00%\nEpoch 640/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.54it/s, loss=0.4624, acc=100.00%]\n\nEpoch 640/2000 Summary:\nTraining Loss: 0.4624, Accuracy: 100.00%\nEpoch 641/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.38it/s, loss=0.4606, acc=100.00%]\n\nEpoch 641/2000 Summary:\nTraining Loss: 0.4606, Accuracy: 100.00%\nEpoch 642/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.76it/s, loss=0.4478, acc=100.00%]\n\nEpoch 642/2000 Summary:\nTraining Loss: 0.4478, Accuracy: 100.00%\nEpoch 643/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4616, acc=100.00%]\n\nEpoch 643/2000 Summary:\nTraining Loss: 0.4616, Accuracy: 100.00%\nEpoch 644/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.12it/s, loss=0.4485, acc=100.00%]\n\nEpoch 644/2000 Summary:\nTraining Loss: 0.4485, Accuracy: 100.00%\nEpoch 645/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.95it/s, loss=0.4612, acc=100.00%]\n\nEpoch 645/2000 Summary:\nTraining Loss: 0.4612, Accuracy: 100.00%\nEpoch 646/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.77it/s, loss=0.4621, acc=100.00%]\n\nEpoch 646/2000 Summary:\nTraining Loss: 0.4621, Accuracy: 100.00%\nEpoch 647/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.12it/s, loss=0.4613, acc=100.00%]\n\nEpoch 647/2000 Summary:\nTraining Loss: 0.4613, Accuracy: 100.00%\nEpoch 648/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.50it/s, loss=0.4484, acc=100.00%]\n\nEpoch 648/2000 Summary:\nTraining Loss: 0.4484, Accuracy: 100.00%\nEpoch 649/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.91it/s, loss=0.4610, acc=100.00%]\n\nEpoch 649/2000 Summary:\nTraining Loss: 0.4610, Accuracy: 100.00%\nEpoch 650/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.09it/s, loss=0.4617, acc=100.00%]\n\nEpoch 650/2000 Summary:\nTraining Loss: 0.4617, Accuracy: 100.00%\nEpoch 651/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.06it/s, loss=0.4629, acc=100.00%]\n\nEpoch 651/2000 Summary:\nTraining Loss: 0.4629, Accuracy: 100.00%\nEpoch 652/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4611, acc=100.00%]\n\nEpoch 652/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 653/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.4464, acc=100.00%]\n\nEpoch 653/2000 Summary:\nTraining Loss: 0.4464, Accuracy: 100.00%\nEpoch 654/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4627, acc=100.00%]\n\nEpoch 654/2000 Summary:\nTraining Loss: 0.4627, Accuracy: 100.00%\nEpoch 655/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.99it/s, loss=0.4474, acc=100.00%]\n\nEpoch 655/2000 Summary:\nTraining Loss: 0.4474, Accuracy: 100.00%\nEpoch 656/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4626, acc=100.00%]\n\nEpoch 656/2000 Summary:\nTraining Loss: 0.4626, Accuracy: 100.00%\nEpoch 657/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4504, acc=100.00%]\n\nEpoch 657/2000 Summary:\nTraining Loss: 0.4504, Accuracy: 100.00%\nEpoch 658/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.29it/s, loss=0.4620, acc=99.44%] \n\nEpoch 658/2000 Summary:\nTraining Loss: 0.4620, Accuracy: 99.44%\nEpoch 659/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=0.4737, acc=98.33%]\n\nEpoch 659/2000 Summary:\nTraining Loss: 0.4737, Accuracy: 98.33%\nEpoch 660/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4977, acc=97.96%]\n\nEpoch 660/2000 Summary:\nTraining Loss: 0.4977, Accuracy: 97.96%\nEpoch 661/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.53it/s, loss=0.4844, acc=98.89%]\n\nEpoch 661/2000 Summary:\nTraining Loss: 0.4844, Accuracy: 98.89%\nEpoch 662/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.4540, acc=100.00%]\n\nEpoch 662/2000 Summary:\nTraining Loss: 0.4540, Accuracy: 100.00%\nEpoch 663/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4667, acc=99.81%]\n\nEpoch 663/2000 Summary:\nTraining Loss: 0.4667, Accuracy: 99.81%\nEpoch 664/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.43it/s, loss=0.4501, acc=100.00%]\n\nEpoch 664/2000 Summary:\nTraining Loss: 0.4501, Accuracy: 100.00%\nEpoch 665/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.67it/s, loss=0.4740, acc=99.26%] \n\nEpoch 665/2000 Summary:\nTraining Loss: 0.4740, Accuracy: 99.26%\nEpoch 666/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.39it/s, loss=0.4598, acc=99.44%]\n\nEpoch 666/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 99.44%\nEpoch 667/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4692, acc=99.81%]\n\nEpoch 667/2000 Summary:\nTraining Loss: 0.4692, Accuracy: 99.81%\nEpoch 668/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.28it/s, loss=0.4652, acc=100.00%]\n\nEpoch 668/2000 Summary:\nTraining Loss: 0.4652, Accuracy: 100.00%\nEpoch 669/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.23it/s, loss=0.4633, acc=100.00%]\n\nEpoch 669/2000 Summary:\nTraining Loss: 0.4633, Accuracy: 100.00%\nEpoch 670/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.4617, acc=100.00%]\n\nEpoch 670/2000 Summary:\nTraining Loss: 0.4617, Accuracy: 100.00%\nEpoch 671/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4636, acc=100.00%]\n\nEpoch 671/2000 Summary:\nTraining Loss: 0.4636, Accuracy: 100.00%\nEpoch 672/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.38it/s, loss=0.4541, acc=99.81%]\n\nEpoch 672/2000 Summary:\nTraining Loss: 0.4541, Accuracy: 99.81%\nEpoch 673/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4643, acc=100.00%]\n\nEpoch 673/2000 Summary:\nTraining Loss: 0.4643, Accuracy: 100.00%\nEpoch 674/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.22it/s, loss=0.4482, acc=100.00%]\n\nEpoch 674/2000 Summary:\nTraining Loss: 0.4482, Accuracy: 100.00%\nEpoch 675/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.4626, acc=100.00%]\n\nEpoch 675/2000 Summary:\nTraining Loss: 0.4626, Accuracy: 100.00%\nEpoch 676/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.4631, acc=100.00%]\n\nEpoch 676/2000 Summary:\nTraining Loss: 0.4631, Accuracy: 100.00%\nEpoch 677/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.4626, acc=100.00%]\n\nEpoch 677/2000 Summary:\nTraining Loss: 0.4626, Accuracy: 100.00%\nEpoch 678/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.82it/s, loss=0.4510, acc=99.63%]\n\nEpoch 678/2000 Summary:\nTraining Loss: 0.4510, Accuracy: 99.63%\nEpoch 679/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.84it/s, loss=0.4676, acc=99.63%]\n\nEpoch 679/2000 Summary:\nTraining Loss: 0.4676, Accuracy: 99.63%\nEpoch 680/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.49it/s, loss=0.4541, acc=99.63%]\n\nEpoch 680/2000 Summary:\nTraining Loss: 0.4541, Accuracy: 99.63%\nEpoch 681/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4679, acc=99.63%] \n\nEpoch 681/2000 Summary:\nTraining Loss: 0.4679, Accuracy: 99.63%\nEpoch 682/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.28it/s, loss=0.4637, acc=100.00%]\n\nEpoch 682/2000 Summary:\nTraining Loss: 0.4637, Accuracy: 100.00%\nEpoch 683/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.89it/s, loss=0.4482, acc=100.00%]\n\nEpoch 683/2000 Summary:\nTraining Loss: 0.4482, Accuracy: 100.00%\nEpoch 684/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.76it/s, loss=0.4622, acc=100.00%]\n\nEpoch 684/2000 Summary:\nTraining Loss: 0.4622, Accuracy: 100.00%\nEpoch 685/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4605, acc=100.00%]\n\nEpoch 685/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 100.00%\nEpoch 686/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4467, acc=100.00%]\n\nEpoch 686/2000 Summary:\nTraining Loss: 0.4467, Accuracy: 100.00%\nEpoch 687/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.24it/s, loss=0.4620, acc=100.00%]\n\nEpoch 687/2000 Summary:\nTraining Loss: 0.4620, Accuracy: 100.00%\nEpoch 688/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.25it/s, loss=0.4626, acc=100.00%]\n\nEpoch 688/2000 Summary:\nTraining Loss: 0.4626, Accuracy: 100.00%\nEpoch 689/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.57it/s, loss=0.4479, acc=100.00%]\n\nEpoch 689/2000 Summary:\nTraining Loss: 0.4479, Accuracy: 100.00%\nEpoch 690/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.4470, acc=100.00%]\n\nEpoch 690/2000 Summary:\nTraining Loss: 0.4470, Accuracy: 100.00%\nEpoch 691/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4612, acc=100.00%]\n\nEpoch 691/2000 Summary:\nTraining Loss: 0.4612, Accuracy: 100.00%\nEpoch 692/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4632, acc=100.00%]\n\nEpoch 692/2000 Summary:\nTraining Loss: 0.4632, Accuracy: 100.00%\nEpoch 693/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.79it/s, loss=0.4622, acc=100.00%]\n\nEpoch 693/2000 Summary:\nTraining Loss: 0.4622, Accuracy: 100.00%\nEpoch 694/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.75it/s, loss=0.4628, acc=100.00%]\n\nEpoch 694/2000 Summary:\nTraining Loss: 0.4628, Accuracy: 100.00%\nEpoch 695/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4684, acc=99.63%]\n\nEpoch 695/2000 Summary:\nTraining Loss: 0.4684, Accuracy: 99.63%\nEpoch 696/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.23it/s, loss=0.4665, acc=100.00%]\n\nEpoch 696/2000 Summary:\nTraining Loss: 0.4665, Accuracy: 100.00%\nEpoch 697/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.18it/s, loss=0.4742, acc=99.26%]\n\nEpoch 697/2000 Summary:\nTraining Loss: 0.4742, Accuracy: 99.26%\nEpoch 698/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.30it/s, loss=0.4734, acc=99.44%]\n\nEpoch 698/2000 Summary:\nTraining Loss: 0.4734, Accuracy: 99.44%\nEpoch 699/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4813, acc=99.07%]\n\nEpoch 699/2000 Summary:\nTraining Loss: 0.4813, Accuracy: 99.07%\nEpoch 700/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.98it/s, loss=0.4585, acc=99.63%]\n\nEpoch 700/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 99.63%\nEpoch 701/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4699, acc=99.81%]\n\nEpoch 701/2000 Summary:\nTraining Loss: 0.4699, Accuracy: 99.81%\nEpoch 702/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.4628, acc=100.00%]\n\nEpoch 702/2000 Summary:\nTraining Loss: 0.4628, Accuracy: 100.00%\nEpoch 703/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4472, acc=100.00%]\n\nEpoch 703/2000 Summary:\nTraining Loss: 0.4472, Accuracy: 100.00%\nEpoch 704/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4604, acc=100.00%]\n\nEpoch 704/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 705/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=0.4485, acc=100.00%]\n\nEpoch 705/2000 Summary:\nTraining Loss: 0.4485, Accuracy: 100.00%\nEpoch 706/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4471, acc=100.00%]\n\nEpoch 706/2000 Summary:\nTraining Loss: 0.4471, Accuracy: 100.00%\nEpoch 707/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.38it/s, loss=0.4652, acc=99.63%]\n\nEpoch 707/2000 Summary:\nTraining Loss: 0.4652, Accuracy: 99.63%\nEpoch 708/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4653, acc=99.81%] \n\nEpoch 708/2000 Summary:\nTraining Loss: 0.4653, Accuracy: 99.81%\nEpoch 709/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4662, acc=99.81%]\n\nEpoch 709/2000 Summary:\nTraining Loss: 0.4662, Accuracy: 99.81%\nEpoch 710/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4506, acc=100.00%]\n\nEpoch 710/2000 Summary:\nTraining Loss: 0.4506, Accuracy: 100.00%\nEpoch 711/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.36it/s, loss=0.4661, acc=99.81%]\n\nEpoch 711/2000 Summary:\nTraining Loss: 0.4661, Accuracy: 99.81%\nEpoch 712/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4607, acc=100.00%]\n\nEpoch 712/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 713/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.4501, acc=99.81%] \n\nEpoch 713/2000 Summary:\nTraining Loss: 0.4501, Accuracy: 99.81%\nEpoch 714/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4694, acc=99.44%] \n\nEpoch 714/2000 Summary:\nTraining Loss: 0.4694, Accuracy: 99.44%\nEpoch 715/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.22it/s, loss=0.4652, acc=99.81%]\n\nEpoch 715/2000 Summary:\nTraining Loss: 0.4652, Accuracy: 99.81%\nEpoch 716/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.27it/s, loss=0.4618, acc=100.00%]\n\nEpoch 716/2000 Summary:\nTraining Loss: 0.4618, Accuracy: 100.00%\nEpoch 717/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4618, acc=100.00%]\n\nEpoch 717/2000 Summary:\nTraining Loss: 0.4618, Accuracy: 100.00%\nEpoch 718/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.45it/s, loss=0.4484, acc=100.00%]\n\nEpoch 718/2000 Summary:\nTraining Loss: 0.4484, Accuracy: 100.00%\nEpoch 719/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.79it/s, loss=0.4618, acc=100.00%]\n\nEpoch 719/2000 Summary:\nTraining Loss: 0.4618, Accuracy: 100.00%\nEpoch 720/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.13it/s, loss=0.4478, acc=100.00%]\n\nEpoch 720/2000 Summary:\nTraining Loss: 0.4478, Accuracy: 100.00%\nEpoch 721/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4621, acc=100.00%]\n\nEpoch 721/2000 Summary:\nTraining Loss: 0.4621, Accuracy: 100.00%\nEpoch 722/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4606, acc=100.00%]\n\nEpoch 722/2000 Summary:\nTraining Loss: 0.4606, Accuracy: 100.00%\nEpoch 723/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4550, acc=99.44%]\n\nEpoch 723/2000 Summary:\nTraining Loss: 0.4550, Accuracy: 99.44%\nEpoch 724/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.81it/s, loss=0.4729, acc=99.63%]\n\nEpoch 724/2000 Summary:\nTraining Loss: 0.4729, Accuracy: 99.63%\nEpoch 725/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4631, acc=100.00%]\n\nEpoch 725/2000 Summary:\nTraining Loss: 0.4631, Accuracy: 100.00%\nEpoch 726/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.18it/s, loss=0.4474, acc=100.00%]\n\nEpoch 726/2000 Summary:\nTraining Loss: 0.4474, Accuracy: 100.00%\nEpoch 727/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4614, acc=100.00%]\n\nEpoch 727/2000 Summary:\nTraining Loss: 0.4614, Accuracy: 100.00%\nEpoch 728/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.76it/s, loss=0.4597, acc=100.00%]\n\nEpoch 728/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 729/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4612, acc=100.00%]\n\nEpoch 729/2000 Summary:\nTraining Loss: 0.4612, Accuracy: 100.00%\nEpoch 730/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.55it/s, loss=0.4607, acc=100.00%]\n\nEpoch 730/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 731/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4653, acc=99.81%] \n\nEpoch 731/2000 Summary:\nTraining Loss: 0.4653, Accuracy: 99.81%\nEpoch 732/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.42it/s, loss=0.4541, acc=99.81%]\n\nEpoch 732/2000 Summary:\nTraining Loss: 0.4541, Accuracy: 99.81%\nEpoch 733/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4623, acc=100.00%]\n\nEpoch 733/2000 Summary:\nTraining Loss: 0.4623, Accuracy: 100.00%\nEpoch 734/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4613, acc=100.00%]\n\nEpoch 734/2000 Summary:\nTraining Loss: 0.4613, Accuracy: 100.00%\nEpoch 735/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4608, acc=100.00%]\n\nEpoch 735/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 736/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.22it/s, loss=0.4615, acc=100.00%]\n\nEpoch 736/2000 Summary:\nTraining Loss: 0.4615, Accuracy: 100.00%\nEpoch 737/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4470, acc=100.00%]\n\nEpoch 737/2000 Summary:\nTraining Loss: 0.4470, Accuracy: 100.00%\nEpoch 738/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4597, acc=100.00%]\n\nEpoch 738/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 739/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4621, acc=100.00%]\n\nEpoch 739/2000 Summary:\nTraining Loss: 0.4621, Accuracy: 100.00%\nEpoch 740/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.23it/s, loss=0.4607, acc=100.00%]\n\nEpoch 740/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 741/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.19it/s, loss=0.4603, acc=100.00%]\n\nEpoch 741/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 742/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.37it/s, loss=0.4608, acc=100.00%]\n\nEpoch 742/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 743/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.72it/s, loss=0.4463, acc=100.00%]\n\nEpoch 743/2000 Summary:\nTraining Loss: 0.4463, Accuracy: 100.00%\nEpoch 744/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4611, acc=100.00%]\n\nEpoch 744/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 745/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.69it/s, loss=0.4511, acc=99.63%]\n\nEpoch 745/2000 Summary:\nTraining Loss: 0.4511, Accuracy: 99.63%\nEpoch 746/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.4767, acc=99.26%]\n\nEpoch 746/2000 Summary:\nTraining Loss: 0.4767, Accuracy: 99.26%\nEpoch 747/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=0.4579, acc=99.44%]\n\nEpoch 747/2000 Summary:\nTraining Loss: 0.4579, Accuracy: 99.44%\nEpoch 748/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.10it/s, loss=0.4758, acc=99.63%] \n\nEpoch 748/2000 Summary:\nTraining Loss: 0.4758, Accuracy: 99.63%\nEpoch 749/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.59it/s, loss=0.4818, acc=98.70%]\n\nEpoch 749/2000 Summary:\nTraining Loss: 0.4818, Accuracy: 98.70%\nEpoch 750/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.97it/s, loss=0.4723, acc=99.07%] \n\nEpoch 750/2000 Summary:\nTraining Loss: 0.4723, Accuracy: 99.07%\nEpoch 751/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.20it/s, loss=0.4752, acc=99.44%]\n\nEpoch 751/2000 Summary:\nTraining Loss: 0.4752, Accuracy: 99.44%\nEpoch 752/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=0.4638, acc=99.26%]\n\nEpoch 752/2000 Summary:\nTraining Loss: 0.4638, Accuracy: 99.26%\nEpoch 753/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4699, acc=99.63%]\n\nEpoch 753/2000 Summary:\nTraining Loss: 0.4699, Accuracy: 99.63%\nEpoch 754/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4637, acc=100.00%]\n\nEpoch 754/2000 Summary:\nTraining Loss: 0.4637, Accuracy: 100.00%\nEpoch 755/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.80it/s, loss=0.4618, acc=100.00%]\n\nEpoch 755/2000 Summary:\nTraining Loss: 0.4618, Accuracy: 100.00%\nEpoch 756/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.62it/s, loss=0.4611, acc=100.00%]\n\nEpoch 756/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 757/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.80it/s, loss=0.4611, acc=100.00%]\n\nEpoch 757/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 758/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=0.4602, acc=100.00%]\n\nEpoch 758/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 759/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.87it/s, loss=0.4608, acc=100.00%]\n\nEpoch 759/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 760/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.80it/s, loss=0.4612, acc=100.00%]\n\nEpoch 760/2000 Summary:\nTraining Loss: 0.4612, Accuracy: 100.00%\nEpoch 761/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4614, acc=100.00%]\n\nEpoch 761/2000 Summary:\nTraining Loss: 0.4614, Accuracy: 100.00%\nEpoch 762/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4481, acc=99.81%]\n\nEpoch 762/2000 Summary:\nTraining Loss: 0.4481, Accuracy: 99.81%\nEpoch 763/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.55it/s, loss=0.4608, acc=100.00%]\n\nEpoch 763/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 764/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4473, acc=100.00%]\n\nEpoch 764/2000 Summary:\nTraining Loss: 0.4473, Accuracy: 100.00%\nEpoch 765/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.99it/s, loss=0.4608, acc=100.00%]\n\nEpoch 765/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 766/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=0.4611, acc=100.00%]\n\nEpoch 766/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 767/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4605, acc=100.00%]\n\nEpoch 767/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 100.00%\nEpoch 768/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.4463, acc=100.00%]\n\nEpoch 768/2000 Summary:\nTraining Loss: 0.4463, Accuracy: 100.00%\nEpoch 769/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.4608, acc=100.00%]\n\nEpoch 769/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 770/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.02it/s, loss=0.4627, acc=100.00%]\n\nEpoch 770/2000 Summary:\nTraining Loss: 0.4627, Accuracy: 100.00%\nEpoch 771/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4671, acc=99.63%]\n\nEpoch 771/2000 Summary:\nTraining Loss: 0.4671, Accuracy: 99.63%\nEpoch 772/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4624, acc=100.00%]\n\nEpoch 772/2000 Summary:\nTraining Loss: 0.4624, Accuracy: 100.00%\nEpoch 773/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4618, acc=100.00%]\n\nEpoch 773/2000 Summary:\nTraining Loss: 0.4618, Accuracy: 100.00%\nEpoch 774/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.41it/s, loss=0.4478, acc=100.00%]\n\nEpoch 774/2000 Summary:\nTraining Loss: 0.4478, Accuracy: 100.00%\nEpoch 775/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4600, acc=100.00%]\n\nEpoch 775/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 776/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.43it/s, loss=0.4611, acc=100.00%]\n\nEpoch 776/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 777/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.70it/s, loss=0.4597, acc=100.00%]\n\nEpoch 777/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 778/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.21it/s, loss=0.4608, acc=100.00%]\n\nEpoch 778/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 779/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4469, acc=100.00%]\n\nEpoch 779/2000 Summary:\nTraining Loss: 0.4469, Accuracy: 100.00%\nEpoch 780/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.4609, acc=100.00%]\n\nEpoch 780/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 100.00%\nEpoch 781/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4602, acc=100.00%]\n\nEpoch 781/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 782/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.50it/s, loss=0.4464, acc=100.00%]\n\nEpoch 782/2000 Summary:\nTraining Loss: 0.4464, Accuracy: 100.00%\nEpoch 783/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.54it/s, loss=0.4598, acc=100.00%]\n\nEpoch 783/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 784/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.91it/s, loss=0.4601, acc=100.00%]\n\nEpoch 784/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 785/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.43it/s, loss=0.4461, acc=100.00%]\n\nEpoch 785/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 786/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.08it/s, loss=0.4608, acc=100.00%]\n\nEpoch 786/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 787/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.60it/s, loss=0.4601, acc=100.00%]\n\nEpoch 787/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 788/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.57it/s, loss=0.4599, acc=100.00%]\n\nEpoch 788/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 789/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.44it/s, loss=0.4468, acc=100.00%]\n\nEpoch 789/2000 Summary:\nTraining Loss: 0.4468, Accuracy: 100.00%\nEpoch 790/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4605, acc=100.00%]\n\nEpoch 790/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 100.00%\nEpoch 791/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4466, acc=100.00%]\n\nEpoch 791/2000 Summary:\nTraining Loss: 0.4466, Accuracy: 100.00%\nEpoch 792/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.46it/s, loss=0.4468, acc=100.00%]\n\nEpoch 792/2000 Summary:\nTraining Loss: 0.4468, Accuracy: 100.00%\nEpoch 793/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.4610, acc=100.00%]\n\nEpoch 793/2000 Summary:\nTraining Loss: 0.4610, Accuracy: 100.00%\nEpoch 794/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.61it/s, loss=0.4604, acc=100.00%]\n\nEpoch 794/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 795/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.16it/s, loss=0.4484, acc=100.00%]\n\nEpoch 795/2000 Summary:\nTraining Loss: 0.4484, Accuracy: 100.00%\nEpoch 796/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4605, acc=100.00%]\n\nEpoch 796/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 100.00%\nEpoch 797/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4609, acc=100.00%]\n\nEpoch 797/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 100.00%\nEpoch 798/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4461, acc=100.00%]\n\nEpoch 798/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 799/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.80it/s, loss=0.4461, acc=100.00%]\n\nEpoch 799/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 800/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.29it/s, loss=0.4467, acc=100.00%]\n\nEpoch 800/2000 Summary:\nTraining Loss: 0.4467, Accuracy: 100.00%\nEpoch 801/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.4607, acc=100.00%]\n\nEpoch 801/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 802/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.40it/s, loss=0.4600, acc=100.00%]\n\nEpoch 802/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 803/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.4597, acc=100.00%]\n\nEpoch 803/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 804/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.03it/s, loss=0.4591, acc=100.00%]\n\nEpoch 804/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 805/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.72it/s, loss=0.4603, acc=100.00%]\n\nEpoch 805/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 806/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.99it/s, loss=0.4592, acc=100.00%]\n\nEpoch 806/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 807/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=0.4591, acc=100.00%]\n\nEpoch 807/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 808/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.87it/s, loss=0.4592, acc=100.00%]\n\nEpoch 808/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 809/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.13it/s, loss=0.4609, acc=100.00%]\n\nEpoch 809/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 100.00%\nEpoch 810/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.22it/s, loss=0.4467, acc=100.00%]\n\nEpoch 810/2000 Summary:\nTraining Loss: 0.4467, Accuracy: 100.00%\nEpoch 811/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4589, acc=100.00%]\n\nEpoch 811/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 812/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.38it/s, loss=0.4604, acc=100.00%]\n\nEpoch 812/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 813/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.44it/s, loss=0.4467, acc=100.00%]\n\nEpoch 813/2000 Summary:\nTraining Loss: 0.4467, Accuracy: 100.00%\nEpoch 814/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4591, acc=100.00%]\n\nEpoch 814/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 815/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.18it/s, loss=0.4469, acc=100.00%]\n\nEpoch 815/2000 Summary:\nTraining Loss: 0.4469, Accuracy: 100.00%\nEpoch 816/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.4462, acc=100.00%]\n\nEpoch 816/2000 Summary:\nTraining Loss: 0.4462, Accuracy: 100.00%\nEpoch 817/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.03it/s, loss=0.4948, acc=97.96%] \n\nEpoch 817/2000 Summary:\nTraining Loss: 0.4948, Accuracy: 97.96%\nEpoch 818/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.95it/s, loss=0.4784, acc=99.26%] \n\nEpoch 818/2000 Summary:\nTraining Loss: 0.4784, Accuracy: 99.26%\nEpoch 819/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.02it/s, loss=0.4722, acc=99.26%]\n\nEpoch 819/2000 Summary:\nTraining Loss: 0.4722, Accuracy: 99.26%\nEpoch 820/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.94it/s, loss=0.4522, acc=99.81%] \n\nEpoch 820/2000 Summary:\nTraining Loss: 0.4522, Accuracy: 99.81%\nEpoch 821/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.22it/s, loss=0.4619, acc=100.00%]\n\nEpoch 821/2000 Summary:\nTraining Loss: 0.4619, Accuracy: 100.00%\nEpoch 822/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4472, acc=100.00%]\n\nEpoch 822/2000 Summary:\nTraining Loss: 0.4472, Accuracy: 100.00%\nEpoch 823/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.4607, acc=100.00%]\n\nEpoch 823/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 824/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.49it/s, loss=0.4466, acc=100.00%]\n\nEpoch 824/2000 Summary:\nTraining Loss: 0.4466, Accuracy: 100.00%\nEpoch 825/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4726, acc=99.26%] \n\nEpoch 825/2000 Summary:\nTraining Loss: 0.4726, Accuracy: 99.26%\nEpoch 826/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.75it/s, loss=0.4670, acc=99.81%] \n\nEpoch 826/2000 Summary:\nTraining Loss: 0.4670, Accuracy: 99.81%\nEpoch 827/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.78it/s, loss=0.4629, acc=100.00%]\n\nEpoch 827/2000 Summary:\nTraining Loss: 0.4629, Accuracy: 100.00%\nEpoch 828/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4605, acc=100.00%]\n\nEpoch 828/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 100.00%\nEpoch 829/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4611, acc=100.00%]\n\nEpoch 829/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 830/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.12it/s, loss=0.4469, acc=100.00%]\n\nEpoch 830/2000 Summary:\nTraining Loss: 0.4469, Accuracy: 100.00%\nEpoch 831/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4602, acc=100.00%]\n\nEpoch 831/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 832/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.31it/s, loss=0.4513, acc=99.63%]\n\nEpoch 832/2000 Summary:\nTraining Loss: 0.4513, Accuracy: 99.63%\nEpoch 833/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.74it/s, loss=0.4471, acc=100.00%]\n\nEpoch 833/2000 Summary:\nTraining Loss: 0.4471, Accuracy: 100.00%\nEpoch 834/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4736, acc=99.26%] \n\nEpoch 834/2000 Summary:\nTraining Loss: 0.4736, Accuracy: 99.26%\nEpoch 835/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.47it/s, loss=0.4566, acc=99.44%] \n\nEpoch 835/2000 Summary:\nTraining Loss: 0.4566, Accuracy: 99.44%\nEpoch 836/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.74it/s, loss=0.4853, acc=98.33%]\n\nEpoch 836/2000 Summary:\nTraining Loss: 0.4853, Accuracy: 98.33%\nEpoch 837/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.20it/s, loss=0.4810, acc=99.07%]\n\nEpoch 837/2000 Summary:\nTraining Loss: 0.4810, Accuracy: 99.07%\nEpoch 838/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.28it/s, loss=0.4496, acc=99.81%] \n\nEpoch 838/2000 Summary:\nTraining Loss: 0.4496, Accuracy: 99.81%\nEpoch 839/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.74it/s, loss=0.4618, acc=100.00%]\n\nEpoch 839/2000 Summary:\nTraining Loss: 0.4618, Accuracy: 100.00%\nEpoch 840/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4465, acc=100.00%]\n\nEpoch 840/2000 Summary:\nTraining Loss: 0.4465, Accuracy: 100.00%\nEpoch 841/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4613, acc=100.00%]\n\nEpoch 841/2000 Summary:\nTraining Loss: 0.4613, Accuracy: 100.00%\nEpoch 842/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4460, acc=100.00%]\n\nEpoch 842/2000 Summary:\nTraining Loss: 0.4460, Accuracy: 100.00%\nEpoch 843/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.52it/s, loss=0.4470, acc=100.00%]\n\nEpoch 843/2000 Summary:\nTraining Loss: 0.4470, Accuracy: 100.00%\nEpoch 844/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4463, acc=100.00%]\n\nEpoch 844/2000 Summary:\nTraining Loss: 0.4463, Accuracy: 100.00%\nEpoch 845/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4600, acc=100.00%]\n\nEpoch 845/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 846/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.4463, acc=100.00%]\n\nEpoch 846/2000 Summary:\nTraining Loss: 0.4463, Accuracy: 100.00%\nEpoch 847/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.59it/s, loss=0.4747, acc=100.00%]\n\nEpoch 847/2000 Summary:\nTraining Loss: 0.4747, Accuracy: 100.00%\nEpoch 848/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.52it/s, loss=0.4597, acc=100.00%]\n\nEpoch 848/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 849/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.22it/s, loss=0.4601, acc=100.00%]\n\nEpoch 849/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 850/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.38it/s, loss=0.4597, acc=100.00%]\n\nEpoch 850/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 851/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.50it/s, loss=0.4457, acc=100.00%]\n\nEpoch 851/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 852/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4602, acc=100.00%]\n\nEpoch 852/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 853/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.71it/s, loss=0.4461, acc=100.00%]\n\nEpoch 853/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 854/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.58it/s, loss=0.4626, acc=99.81%]\n\nEpoch 854/2000 Summary:\nTraining Loss: 0.4626, Accuracy: 99.81%\nEpoch 855/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.4661, acc=99.81%]\n\nEpoch 855/2000 Summary:\nTraining Loss: 0.4661, Accuracy: 99.81%\nEpoch 856/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4605, acc=100.00%]\n\nEpoch 856/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 100.00%\nEpoch 857/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.19it/s, loss=0.4609, acc=100.00%]\n\nEpoch 857/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 100.00%\nEpoch 858/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4468, acc=100.00%]\n\nEpoch 858/2000 Summary:\nTraining Loss: 0.4468, Accuracy: 100.00%\nEpoch 859/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 49.00it/s, loss=0.4469, acc=100.00%]\n\nEpoch 859/2000 Summary:\nTraining Loss: 0.4469, Accuracy: 100.00%\nEpoch 860/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.25it/s, loss=0.4456, acc=100.00%]\n\nEpoch 860/2000 Summary:\nTraining Loss: 0.4456, Accuracy: 100.00%\nEpoch 861/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.01it/s, loss=0.4605, acc=100.00%]\n\nEpoch 861/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 100.00%\nEpoch 862/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4611, acc=100.00%]\n\nEpoch 862/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 863/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4633, acc=100.00%]\n\nEpoch 863/2000 Summary:\nTraining Loss: 0.4633, Accuracy: 100.00%\nEpoch 864/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.25it/s, loss=0.4528, acc=99.81%]\n\nEpoch 864/2000 Summary:\nTraining Loss: 0.4528, Accuracy: 99.81%\nEpoch 865/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.51it/s, loss=0.4632, acc=99.81%] \n\nEpoch 865/2000 Summary:\nTraining Loss: 0.4632, Accuracy: 99.81%\nEpoch 866/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=0.4688, acc=99.81%] \n\nEpoch 866/2000 Summary:\nTraining Loss: 0.4688, Accuracy: 99.81%\nEpoch 867/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.56it/s, loss=0.4539, acc=99.63%] \n\nEpoch 867/2000 Summary:\nTraining Loss: 0.4539, Accuracy: 99.63%\nEpoch 868/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.78it/s, loss=0.4510, acc=100.00%]\n\nEpoch 868/2000 Summary:\nTraining Loss: 0.4510, Accuracy: 100.00%\nEpoch 869/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.24it/s, loss=0.4476, acc=100.00%]\n\nEpoch 869/2000 Summary:\nTraining Loss: 0.4476, Accuracy: 100.00%\nEpoch 870/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4601, acc=100.00%]\n\nEpoch 870/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 871/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4462, acc=100.00%]\n\nEpoch 871/2000 Summary:\nTraining Loss: 0.4462, Accuracy: 100.00%\nEpoch 872/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4470, acc=100.00%]\n\nEpoch 872/2000 Summary:\nTraining Loss: 0.4470, Accuracy: 100.00%\nEpoch 873/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4607, acc=100.00%]\n\nEpoch 873/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 874/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=0.4465, acc=100.00%]\n\nEpoch 874/2000 Summary:\nTraining Loss: 0.4465, Accuracy: 100.00%\nEpoch 875/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=0.4668, acc=99.63%] \n\nEpoch 875/2000 Summary:\nTraining Loss: 0.4668, Accuracy: 99.63%\nEpoch 876/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.30it/s, loss=0.4544, acc=99.44%]\n\nEpoch 876/2000 Summary:\nTraining Loss: 0.4544, Accuracy: 99.44%\nEpoch 877/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.52it/s, loss=0.4709, acc=99.44%]\n\nEpoch 877/2000 Summary:\nTraining Loss: 0.4709, Accuracy: 99.44%\nEpoch 878/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4480, acc=100.00%]\n\nEpoch 878/2000 Summary:\nTraining Loss: 0.4480, Accuracy: 100.00%\nEpoch 879/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4479, acc=100.00%]\n\nEpoch 879/2000 Summary:\nTraining Loss: 0.4479, Accuracy: 100.00%\nEpoch 880/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.14it/s, loss=0.4607, acc=100.00%]\n\nEpoch 880/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 881/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.21it/s, loss=0.4629, acc=99.81%] \n\nEpoch 881/2000 Summary:\nTraining Loss: 0.4629, Accuracy: 99.81%\nEpoch 882/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4670, acc=99.63%]\n\nEpoch 882/2000 Summary:\nTraining Loss: 0.4670, Accuracy: 99.63%\nEpoch 883/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.51it/s, loss=0.4492, acc=100.00%]\n\nEpoch 883/2000 Summary:\nTraining Loss: 0.4492, Accuracy: 100.00%\nEpoch 884/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.98it/s, loss=0.4611, acc=100.00%]\n\nEpoch 884/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 885/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4603, acc=100.00%]\n\nEpoch 885/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 886/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.4455, acc=100.00%]\n\nEpoch 886/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 887/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.59it/s, loss=0.4459, acc=100.00%]\n\nEpoch 887/2000 Summary:\nTraining Loss: 0.4459, Accuracy: 100.00%\nEpoch 888/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4588, acc=100.00%]\n\nEpoch 888/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 889/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.36it/s, loss=0.4610, acc=100.00%]\n\nEpoch 889/2000 Summary:\nTraining Loss: 0.4610, Accuracy: 100.00%\nEpoch 890/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4595, acc=100.00%]\n\nEpoch 890/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 891/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4589, acc=100.00%]\n\nEpoch 891/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 892/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4491, acc=99.81%]\n\nEpoch 892/2000 Summary:\nTraining Loss: 0.4491, Accuracy: 99.81%\nEpoch 893/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.80it/s, loss=0.4479, acc=100.00%]\n\nEpoch 893/2000 Summary:\nTraining Loss: 0.4479, Accuracy: 100.00%\nEpoch 894/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.78it/s, loss=0.4555, acc=99.26%]\n\nEpoch 894/2000 Summary:\nTraining Loss: 0.4555, Accuracy: 99.26%\nEpoch 895/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4632, acc=100.00%]\n\nEpoch 895/2000 Summary:\nTraining Loss: 0.4632, Accuracy: 100.00%\nEpoch 896/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4474, acc=100.00%]\n\nEpoch 896/2000 Summary:\nTraining Loss: 0.4474, Accuracy: 100.00%\nEpoch 897/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.05it/s, loss=0.4602, acc=100.00%]\n\nEpoch 897/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 898/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4597, acc=100.00%]\n\nEpoch 898/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 899/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=0.4470, acc=100.00%]\n\nEpoch 899/2000 Summary:\nTraining Loss: 0.4470, Accuracy: 100.00%\nEpoch 900/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4608, acc=100.00%]\n\nEpoch 900/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 901/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.12it/s, loss=0.4455, acc=100.00%]\n\nEpoch 901/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 902/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4607, acc=100.00%]\n\nEpoch 902/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 903/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.82it/s, loss=0.4598, acc=100.00%]\n\nEpoch 903/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 904/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4607, acc=100.00%]\n\nEpoch 904/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 905/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.35it/s, loss=0.4470, acc=100.00%]\n\nEpoch 905/2000 Summary:\nTraining Loss: 0.4470, Accuracy: 100.00%\nEpoch 906/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.22it/s, loss=0.4457, acc=100.00%]\n\nEpoch 906/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 907/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.49it/s, loss=0.4603, acc=100.00%]\n\nEpoch 907/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 908/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.01it/s, loss=0.4461, acc=100.00%]\n\nEpoch 908/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 909/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4588, acc=100.00%]\n\nEpoch 909/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 910/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.45it/s, loss=0.4603, acc=100.00%]\n\nEpoch 910/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 911/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4604, acc=100.00%]\n\nEpoch 911/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 912/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.86it/s, loss=0.4459, acc=100.00%]\n\nEpoch 912/2000 Summary:\nTraining Loss: 0.4459, Accuracy: 100.00%\nEpoch 913/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.05it/s, loss=0.4462, acc=100.00%]\n\nEpoch 913/2000 Summary:\nTraining Loss: 0.4462, Accuracy: 100.00%\nEpoch 914/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4602, acc=100.00%]\n\nEpoch 914/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 915/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.40it/s, loss=0.4603, acc=100.00%]\n\nEpoch 915/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 916/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.06it/s, loss=0.4461, acc=100.00%]\n\nEpoch 916/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 917/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.05it/s, loss=0.4605, acc=100.00%]\n\nEpoch 917/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 100.00%\nEpoch 918/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.69it/s, loss=0.4606, acc=100.00%]\n\nEpoch 918/2000 Summary:\nTraining Loss: 0.4606, Accuracy: 100.00%\nEpoch 919/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.36it/s, loss=0.4456, acc=100.00%]\n\nEpoch 919/2000 Summary:\nTraining Loss: 0.4456, Accuracy: 100.00%\nEpoch 920/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.75it/s, loss=0.4599, acc=100.00%]\n\nEpoch 920/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 921/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.03it/s, loss=0.4460, acc=100.00%]\n\nEpoch 921/2000 Summary:\nTraining Loss: 0.4460, Accuracy: 100.00%\nEpoch 922/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.4457, acc=100.00%]\n\nEpoch 922/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 923/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.30it/s, loss=0.4604, acc=100.00%]\n\nEpoch 923/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 924/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.54it/s, loss=0.4602, acc=100.00%]\n\nEpoch 924/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 925/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4595, acc=100.00%]\n\nEpoch 925/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 926/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.4585, acc=100.00%]\n\nEpoch 926/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 927/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4603, acc=100.00%]\n\nEpoch 927/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 928/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4604, acc=100.00%]\n\nEpoch 928/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 929/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4592, acc=100.00%]\n\nEpoch 929/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 930/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.76it/s, loss=0.4591, acc=100.00%]\n\nEpoch 930/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 931/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.42it/s, loss=0.4588, acc=100.00%]\n\nEpoch 931/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 932/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4452, acc=100.00%]\n\nEpoch 932/2000 Summary:\nTraining Loss: 0.4452, Accuracy: 100.00%\nEpoch 933/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.4593, acc=100.00%]\n\nEpoch 933/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 934/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.23it/s, loss=0.4599, acc=100.00%]\n\nEpoch 934/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 935/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4462, acc=100.00%]\n\nEpoch 935/2000 Summary:\nTraining Loss: 0.4462, Accuracy: 100.00%\nEpoch 936/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.40it/s, loss=0.4453, acc=100.00%]\n\nEpoch 936/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 937/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.4457, acc=100.00%]\n\nEpoch 937/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 938/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.68it/s, loss=0.4600, acc=100.00%]\n\nEpoch 938/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 939/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.52it/s, loss=0.4640, acc=99.63%]\n\nEpoch 939/2000 Summary:\nTraining Loss: 0.4640, Accuracy: 99.63%\nEpoch 940/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.4571, acc=99.44%] \n\nEpoch 940/2000 Summary:\nTraining Loss: 0.4571, Accuracy: 99.44%\nEpoch 941/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4760, acc=99.07%] \n\nEpoch 941/2000 Summary:\nTraining Loss: 0.4760, Accuracy: 99.07%\nEpoch 942/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4767, acc=98.52%]\n\nEpoch 942/2000 Summary:\nTraining Loss: 0.4767, Accuracy: 98.52%\nEpoch 943/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4769, acc=99.44%]\n\nEpoch 943/2000 Summary:\nTraining Loss: 0.4769, Accuracy: 99.44%\nEpoch 944/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.99it/s, loss=0.4679, acc=99.81%] \n\nEpoch 944/2000 Summary:\nTraining Loss: 0.4679, Accuracy: 99.81%\nEpoch 945/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.86it/s, loss=0.4645, acc=99.81%] \n\nEpoch 945/2000 Summary:\nTraining Loss: 0.4645, Accuracy: 99.81%\nEpoch 946/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4633, acc=100.00%]\n\nEpoch 946/2000 Summary:\nTraining Loss: 0.4633, Accuracy: 100.00%\nEpoch 947/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.67it/s, loss=0.4477, acc=100.00%]\n\nEpoch 947/2000 Summary:\nTraining Loss: 0.4477, Accuracy: 100.00%\nEpoch 948/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4597, acc=100.00%]\n\nEpoch 948/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 949/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.4457, acc=100.00%]\n\nEpoch 949/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 950/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.4608, acc=100.00%]\n\nEpoch 950/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 951/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.66it/s, loss=0.4457, acc=100.00%]\n\nEpoch 951/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 952/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.01it/s, loss=0.4599, acc=100.00%]\n\nEpoch 952/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 953/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.03it/s, loss=0.4593, acc=100.00%]\n\nEpoch 953/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 954/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.40it/s, loss=0.4459, acc=100.00%]\n\nEpoch 954/2000 Summary:\nTraining Loss: 0.4459, Accuracy: 100.00%\nEpoch 955/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.24it/s, loss=0.4591, acc=100.00%]\n\nEpoch 955/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 956/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4599, acc=100.00%]\n\nEpoch 956/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 957/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4462, acc=100.00%]\n\nEpoch 957/2000 Summary:\nTraining Loss: 0.4462, Accuracy: 100.00%\nEpoch 958/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4460, acc=100.00%]\n\nEpoch 958/2000 Summary:\nTraining Loss: 0.4460, Accuracy: 100.00%\nEpoch 959/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.27it/s, loss=0.4591, acc=100.00%]\n\nEpoch 959/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 960/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4482, acc=99.81%]\n\nEpoch 960/2000 Summary:\nTraining Loss: 0.4482, Accuracy: 99.81%\nEpoch 961/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.4667, acc=99.44%]\n\nEpoch 961/2000 Summary:\nTraining Loss: 0.4667, Accuracy: 99.44%\nEpoch 962/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4637, acc=99.63%] \n\nEpoch 962/2000 Summary:\nTraining Loss: 0.4637, Accuracy: 99.63%\nEpoch 963/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.4740, acc=99.26%]\n\nEpoch 963/2000 Summary:\nTraining Loss: 0.4740, Accuracy: 99.26%\nEpoch 964/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4657, acc=99.63%]\n\nEpoch 964/2000 Summary:\nTraining Loss: 0.4657, Accuracy: 99.63%\nEpoch 965/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.92it/s, loss=0.4464, acc=100.00%]\n\nEpoch 965/2000 Summary:\nTraining Loss: 0.4464, Accuracy: 100.00%\nEpoch 966/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.88it/s, loss=0.4602, acc=100.00%]\n\nEpoch 966/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 967/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.16it/s, loss=0.4532, acc=99.44%]\n\nEpoch 967/2000 Summary:\nTraining Loss: 0.4532, Accuracy: 99.44%\nEpoch 968/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.4620, acc=100.00%]\n\nEpoch 968/2000 Summary:\nTraining Loss: 0.4620, Accuracy: 100.00%\nEpoch 969/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4615, acc=100.00%]\n\nEpoch 969/2000 Summary:\nTraining Loss: 0.4615, Accuracy: 100.00%\nEpoch 970/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4653, acc=99.81%] \n\nEpoch 970/2000 Summary:\nTraining Loss: 0.4653, Accuracy: 99.81%\nEpoch 971/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.39it/s, loss=0.4648, acc=98.70%]\n\nEpoch 971/2000 Summary:\nTraining Loss: 0.4648, Accuracy: 98.70%\nEpoch 972/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.18it/s, loss=0.4582, acc=99.63%] \n\nEpoch 972/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 99.63%\nEpoch 973/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.15it/s, loss=0.4621, acc=100.00%]\n\nEpoch 973/2000 Summary:\nTraining Loss: 0.4621, Accuracy: 100.00%\nEpoch 974/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.80it/s, loss=0.4465, acc=100.00%]\n\nEpoch 974/2000 Summary:\nTraining Loss: 0.4465, Accuracy: 100.00%\nEpoch 975/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.98it/s, loss=0.4457, acc=100.00%]\n\nEpoch 975/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 976/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.4464, acc=100.00%]\n\nEpoch 976/2000 Summary:\nTraining Loss: 0.4464, Accuracy: 100.00%\nEpoch 977/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4596, acc=100.00%]\n\nEpoch 977/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 978/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4610, acc=100.00%]\n\nEpoch 978/2000 Summary:\nTraining Loss: 0.4610, Accuracy: 100.00%\nEpoch 979/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.50it/s, loss=0.4481, acc=99.81%]\n\nEpoch 979/2000 Summary:\nTraining Loss: 0.4481, Accuracy: 99.81%\nEpoch 980/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.20it/s, loss=0.4696, acc=99.44%]\n\nEpoch 980/2000 Summary:\nTraining Loss: 0.4696, Accuracy: 99.44%\nEpoch 981/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4613, acc=100.00%]\n\nEpoch 981/2000 Summary:\nTraining Loss: 0.4613, Accuracy: 100.00%\nEpoch 982/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.45it/s, loss=0.4465, acc=100.00%]\n\nEpoch 982/2000 Summary:\nTraining Loss: 0.4465, Accuracy: 100.00%\nEpoch 983/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4594, acc=100.00%]\n\nEpoch 983/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 984/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.82it/s, loss=0.4600, acc=100.00%]\n\nEpoch 984/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 985/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.38it/s, loss=0.4461, acc=100.00%]\n\nEpoch 985/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 986/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4598, acc=100.00%]\n\nEpoch 986/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 987/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.16it/s, loss=0.4601, acc=100.00%]\n\nEpoch 987/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 988/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4465, acc=100.00%]\n\nEpoch 988/2000 Summary:\nTraining Loss: 0.4465, Accuracy: 100.00%\nEpoch 989/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4609, acc=100.00%]\n\nEpoch 989/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 100.00%\nEpoch 990/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4462, acc=100.00%]\n\nEpoch 990/2000 Summary:\nTraining Loss: 0.4462, Accuracy: 100.00%\nEpoch 991/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.4592, acc=100.00%]\n\nEpoch 991/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 992/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4447, acc=100.00%]\n\nEpoch 992/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 993/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.28it/s, loss=0.4593, acc=100.00%]\n\nEpoch 993/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 994/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.58it/s, loss=0.4603, acc=100.00%]\n\nEpoch 994/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 995/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.95it/s, loss=0.4530, acc=99.63%]\n\nEpoch 995/2000 Summary:\nTraining Loss: 0.4530, Accuracy: 99.63%\nEpoch 996/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.31it/s, loss=0.4603, acc=99.26%]\n\nEpoch 996/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 99.26%\nEpoch 997/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.36it/s, loss=0.4470, acc=100.00%]\n\nEpoch 997/2000 Summary:\nTraining Loss: 0.4470, Accuracy: 100.00%\nEpoch 998/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4597, acc=100.00%]\n\nEpoch 998/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 999/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.04it/s, loss=0.4622, acc=100.00%]\n\nEpoch 999/2000 Summary:\nTraining Loss: 0.4622, Accuracy: 100.00%\nEpoch 1000/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.18it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1000/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1001/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.45it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1001/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1002/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.03it/s, loss=0.4470, acc=100.00%]\n\nEpoch 1002/2000 Summary:\nTraining Loss: 0.4470, Accuracy: 100.00%\nEpoch 1003/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4473, acc=100.00%]\n\nEpoch 1003/2000 Summary:\nTraining Loss: 0.4473, Accuracy: 100.00%\nEpoch 1004/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4599, acc=100.00%]\n\nEpoch 1004/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 1005/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4621, acc=99.81%] \n\nEpoch 1005/2000 Summary:\nTraining Loss: 0.4621, Accuracy: 99.81%\nEpoch 1006/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.82it/s, loss=0.4711, acc=99.26%]\n\nEpoch 1006/2000 Summary:\nTraining Loss: 0.4711, Accuracy: 99.26%\nEpoch 1007/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.45it/s, loss=0.4529, acc=99.63%] \n\nEpoch 1007/2000 Summary:\nTraining Loss: 0.4529, Accuracy: 99.63%\nEpoch 1008/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.00it/s, loss=0.4713, acc=99.44%]\n\nEpoch 1008/2000 Summary:\nTraining Loss: 0.4713, Accuracy: 99.44%\nEpoch 1009/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.21it/s, loss=0.4700, acc=99.81%] \n\nEpoch 1009/2000 Summary:\nTraining Loss: 0.4700, Accuracy: 99.81%\nEpoch 1010/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.30it/s, loss=0.4618, acc=100.00%]\n\nEpoch 1010/2000 Summary:\nTraining Loss: 0.4618, Accuracy: 100.00%\nEpoch 1011/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.4629, acc=99.81%]\n\nEpoch 1011/2000 Summary:\nTraining Loss: 0.4629, Accuracy: 99.81%\nEpoch 1012/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4517, acc=99.44%] \n\nEpoch 1012/2000 Summary:\nTraining Loss: 0.4517, Accuracy: 99.44%\nEpoch 1013/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.18it/s, loss=0.4698, acc=99.44%]\n\nEpoch 1013/2000 Summary:\nTraining Loss: 0.4698, Accuracy: 99.44%\nEpoch 1014/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.35it/s, loss=0.4685, acc=99.81%] \n\nEpoch 1014/2000 Summary:\nTraining Loss: 0.4685, Accuracy: 99.81%\nEpoch 1015/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.78it/s, loss=0.4629, acc=100.00%]\n\nEpoch 1015/2000 Summary:\nTraining Loss: 0.4629, Accuracy: 100.00%\nEpoch 1016/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.24it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1016/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1017/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=0.4607, acc=99.81%] \n\nEpoch 1017/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 99.81%\nEpoch 1018/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4629, acc=99.81%]\n\nEpoch 1018/2000 Summary:\nTraining Loss: 0.4629, Accuracy: 99.81%\nEpoch 1019/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=0.4611, acc=100.00%]\n\nEpoch 1019/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 100.00%\nEpoch 1020/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.45it/s, loss=0.4599, acc=100.00%]\n\nEpoch 1020/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 1021/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.82it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1021/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1022/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.01it/s, loss=0.4460, acc=100.00%]\n\nEpoch 1022/2000 Summary:\nTraining Loss: 0.4460, Accuracy: 100.00%\nEpoch 1023/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.94it/s, loss=0.4604, acc=100.00%]\n\nEpoch 1023/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 1024/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1024/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1025/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.21it/s, loss=0.4604, acc=100.00%]\n\nEpoch 1025/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 1026/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4462, acc=100.00%]\n\nEpoch 1026/2000 Summary:\nTraining Loss: 0.4462, Accuracy: 100.00%\nEpoch 1027/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4466, acc=100.00%]\n\nEpoch 1027/2000 Summary:\nTraining Loss: 0.4466, Accuracy: 100.00%\nEpoch 1028/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4455, acc=100.00%]\n\nEpoch 1028/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 1029/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.95it/s, loss=0.4631, acc=99.81%] \n\nEpoch 1029/2000 Summary:\nTraining Loss: 0.4631, Accuracy: 99.81%\nEpoch 1030/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.06it/s, loss=0.4619, acc=100.00%]\n\nEpoch 1030/2000 Summary:\nTraining Loss: 0.4619, Accuracy: 100.00%\nEpoch 1031/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.98it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1031/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1032/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.37it/s, loss=0.4459, acc=100.00%]\n\nEpoch 1032/2000 Summary:\nTraining Loss: 0.4459, Accuracy: 100.00%\nEpoch 1033/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.01it/s, loss=0.4447, acc=100.00%]\n\nEpoch 1033/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 1034/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.29it/s, loss=0.4455, acc=100.00%]\n\nEpoch 1034/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 1035/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.07it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1035/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1036/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.18it/s, loss=0.4452, acc=100.00%]\n\nEpoch 1036/2000 Summary:\nTraining Loss: 0.4452, Accuracy: 100.00%\nEpoch 1037/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.54it/s, loss=0.4467, acc=100.00%]\n\nEpoch 1037/2000 Summary:\nTraining Loss: 0.4467, Accuracy: 100.00%\nEpoch 1038/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.20it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1038/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1039/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1039/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1040/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=0.4604, acc=100.00%]\n\nEpoch 1040/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 1041/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1041/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1042/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.74it/s, loss=0.4452, acc=100.00%]\n\nEpoch 1042/2000 Summary:\nTraining Loss: 0.4452, Accuracy: 100.00%\nEpoch 1043/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1043/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1044/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1044/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1045/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1045/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1046/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4457, acc=100.00%]\n\nEpoch 1046/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 1047/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.07it/s, loss=0.4607, acc=100.00%]\n\nEpoch 1047/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 1048/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.19it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1048/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1049/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.00it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1049/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1050/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.74it/s, loss=0.4604, acc=100.00%]\n\nEpoch 1050/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 1051/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.69it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1051/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1052/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.24it/s, loss=0.4476, acc=99.81%] \n\nEpoch 1052/2000 Summary:\nTraining Loss: 0.4476, Accuracy: 99.81%\nEpoch 1053/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.65it/s, loss=0.4626, acc=98.70%]\n\nEpoch 1053/2000 Summary:\nTraining Loss: 0.4626, Accuracy: 98.70%\nEpoch 1054/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4580, acc=99.44%] \n\nEpoch 1054/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 99.44%\nEpoch 1055/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.76it/s, loss=0.4544, acc=99.44%]\n\nEpoch 1055/2000 Summary:\nTraining Loss: 0.4544, Accuracy: 99.44%\nEpoch 1056/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4628, acc=99.26%]\n\nEpoch 1056/2000 Summary:\nTraining Loss: 0.4628, Accuracy: 99.26%\nEpoch 1057/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.4645, acc=99.81%] \n\nEpoch 1057/2000 Summary:\nTraining Loss: 0.4645, Accuracy: 99.81%\nEpoch 1058/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.92it/s, loss=0.4608, acc=100.00%]\n\nEpoch 1058/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 1059/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1059/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1060/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.25it/s, loss=0.4609, acc=99.81%] \n\nEpoch 1060/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 99.81%\nEpoch 1061/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.4633, acc=99.81%]\n\nEpoch 1061/2000 Summary:\nTraining Loss: 0.4633, Accuracy: 99.81%\nEpoch 1062/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.4469, acc=100.00%]\n\nEpoch 1062/2000 Summary:\nTraining Loss: 0.4469, Accuracy: 100.00%\nEpoch 1063/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.22it/s, loss=0.4606, acc=100.00%]\n\nEpoch 1063/2000 Summary:\nTraining Loss: 0.4606, Accuracy: 100.00%\nEpoch 1064/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4461, acc=100.00%]\n\nEpoch 1064/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 1065/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1065/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1066/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.88it/s, loss=0.4600, acc=100.00%]\n\nEpoch 1066/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 1067/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.78it/s, loss=0.4463, acc=100.00%]\n\nEpoch 1067/2000 Summary:\nTraining Loss: 0.4463, Accuracy: 100.00%\nEpoch 1068/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1068/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1069/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.46it/s, loss=0.4448, acc=100.00%]\n\nEpoch 1069/2000 Summary:\nTraining Loss: 0.4448, Accuracy: 100.00%\nEpoch 1070/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.4493, acc=99.63%]\n\nEpoch 1070/2000 Summary:\nTraining Loss: 0.4493, Accuracy: 99.63%\nEpoch 1071/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1071/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1072/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.23it/s, loss=0.4614, acc=100.00%]\n\nEpoch 1072/2000 Summary:\nTraining Loss: 0.4614, Accuracy: 100.00%\nEpoch 1073/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.4456, acc=100.00%]\n\nEpoch 1073/2000 Summary:\nTraining Loss: 0.4456, Accuracy: 100.00%\nEpoch 1074/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.76it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1074/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1075/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.02it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1075/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1076/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4458, acc=100.00%]\n\nEpoch 1076/2000 Summary:\nTraining Loss: 0.4458, Accuracy: 100.00%\nEpoch 1077/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4602, acc=100.00%]\n\nEpoch 1077/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 1078/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.79it/s, loss=0.4457, acc=100.00%]\n\nEpoch 1078/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 1079/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1079/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1080/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4450, acc=100.00%]\n\nEpoch 1080/2000 Summary:\nTraining Loss: 0.4450, Accuracy: 100.00%\nEpoch 1081/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1081/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1082/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1082/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1083/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4458, acc=100.00%]\n\nEpoch 1083/2000 Summary:\nTraining Loss: 0.4458, Accuracy: 100.00%\nEpoch 1084/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1084/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1085/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1085/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1086/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4505, acc=99.81%] \n\nEpoch 1086/2000 Summary:\nTraining Loss: 0.4505, Accuracy: 99.81%\nEpoch 1087/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4680, acc=99.63%]\n\nEpoch 1087/2000 Summary:\nTraining Loss: 0.4680, Accuracy: 99.63%\nEpoch 1088/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.47it/s, loss=0.4588, acc=99.44%] \n\nEpoch 1088/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 99.44%\nEpoch 1089/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.07it/s, loss=0.4686, acc=99.44%]\n\nEpoch 1089/2000 Summary:\nTraining Loss: 0.4686, Accuracy: 99.44%\nEpoch 1090/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.4602, acc=100.00%]\n\nEpoch 1090/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 1091/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.46it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1091/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1092/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.24it/s, loss=0.4607, acc=100.00%]\n\nEpoch 1092/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 1093/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1093/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1094/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.71it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1094/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1095/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.45it/s, loss=0.4460, acc=100.00%]\n\nEpoch 1095/2000 Summary:\nTraining Loss: 0.4460, Accuracy: 100.00%\nEpoch 1096/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.70it/s, loss=0.4605, acc=100.00%]\n\nEpoch 1096/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 100.00%\nEpoch 1097/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.55it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1097/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1098/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4600, acc=100.00%]\n\nEpoch 1098/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 1099/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.4464, acc=100.00%]\n\nEpoch 1099/2000 Summary:\nTraining Loss: 0.4464, Accuracy: 100.00%\nEpoch 1100/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.95it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1100/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1101/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.98it/s, loss=0.4456, acc=100.00%]\n\nEpoch 1101/2000 Summary:\nTraining Loss: 0.4456, Accuracy: 100.00%\nEpoch 1102/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1102/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1103/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4463, acc=100.00%]\n\nEpoch 1103/2000 Summary:\nTraining Loss: 0.4463, Accuracy: 100.00%\nEpoch 1104/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.66it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1104/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1105/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.4452, acc=100.00%]\n\nEpoch 1105/2000 Summary:\nTraining Loss: 0.4452, Accuracy: 100.00%\nEpoch 1106/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.4452, acc=100.00%]\n\nEpoch 1106/2000 Summary:\nTraining Loss: 0.4452, Accuracy: 100.00%\nEpoch 1107/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1107/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1108/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.69it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1108/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1109/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.84it/s, loss=0.4599, acc=100.00%]\n\nEpoch 1109/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 1110/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4614, acc=100.00%]\n\nEpoch 1110/2000 Summary:\nTraining Loss: 0.4614, Accuracy: 100.00%\nEpoch 1111/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.20it/s, loss=0.4450, acc=100.00%]\n\nEpoch 1111/2000 Summary:\nTraining Loss: 0.4450, Accuracy: 100.00%\nEpoch 1112/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1112/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1113/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4600, acc=100.00%]\n\nEpoch 1113/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 1114/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1114/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1115/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.03it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1115/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1116/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.90it/s, loss=0.4631, acc=99.81%] \n\nEpoch 1116/2000 Summary:\nTraining Loss: 0.4631, Accuracy: 99.81%\nEpoch 1117/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4605, acc=99.81%] \n\nEpoch 1117/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 99.81%\nEpoch 1118/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4622, acc=99.81%] \n\nEpoch 1118/2000 Summary:\nTraining Loss: 0.4622, Accuracy: 99.81%\nEpoch 1119/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4645, acc=99.63%]\n\nEpoch 1119/2000 Summary:\nTraining Loss: 0.4645, Accuracy: 99.63%\nEpoch 1120/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4619, acc=100.00%]\n\nEpoch 1120/2000 Summary:\nTraining Loss: 0.4619, Accuracy: 100.00%\nEpoch 1121/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4605, acc=100.00%]\n\nEpoch 1121/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 100.00%\nEpoch 1122/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4463, acc=100.00%]\n\nEpoch 1122/2000 Summary:\nTraining Loss: 0.4463, Accuracy: 100.00%\nEpoch 1123/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.30it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1123/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1124/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1124/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1125/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1125/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1126/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.63it/s, loss=0.4455, acc=100.00%]\n\nEpoch 1126/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 1127/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.24it/s, loss=0.4461, acc=100.00%]\n\nEpoch 1127/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 1128/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4450, acc=100.00%]\n\nEpoch 1128/2000 Summary:\nTraining Loss: 0.4450, Accuracy: 100.00%\nEpoch 1129/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.13it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1129/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1130/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.31it/s, loss=0.4599, acc=100.00%]\n\nEpoch 1130/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 1131/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.40it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1131/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1132/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.98it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1132/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1133/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.22it/s, loss=0.4596, acc=99.81%] \n\nEpoch 1133/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 99.81%\nEpoch 1134/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.42it/s, loss=0.4546, acc=99.63%] \n\nEpoch 1134/2000 Summary:\nTraining Loss: 0.4546, Accuracy: 99.63%\nEpoch 1135/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.10it/s, loss=0.4609, acc=100.00%]\n\nEpoch 1135/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 100.00%\nEpoch 1136/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.30it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1136/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1137/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.60it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1137/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1138/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1138/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1139/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.4452, acc=100.00%]\n\nEpoch 1139/2000 Summary:\nTraining Loss: 0.4452, Accuracy: 100.00%\nEpoch 1140/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.4609, acc=100.00%]\n\nEpoch 1140/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 100.00%\nEpoch 1141/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1141/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1142/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1142/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1143/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1143/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1144/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.67it/s, loss=0.4451, acc=100.00%]\n\nEpoch 1144/2000 Summary:\nTraining Loss: 0.4451, Accuracy: 100.00%\nEpoch 1145/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1145/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1146/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.16it/s, loss=0.4455, acc=100.00%]\n\nEpoch 1146/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 1147/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.4448, acc=100.00%]\n\nEpoch 1147/2000 Summary:\nTraining Loss: 0.4448, Accuracy: 100.00%\nEpoch 1148/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4448, acc=100.00%]\n\nEpoch 1148/2000 Summary:\nTraining Loss: 0.4448, Accuracy: 100.00%\nEpoch 1149/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.82it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1149/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1150/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4468, acc=100.00%]\n\nEpoch 1150/2000 Summary:\nTraining Loss: 0.4468, Accuracy: 100.00%\nEpoch 1151/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.40it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1151/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1152/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.98it/s, loss=0.4735, acc=100.00%]\n\nEpoch 1152/2000 Summary:\nTraining Loss: 0.4735, Accuracy: 100.00%\nEpoch 1153/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4604, acc=100.00%]\n\nEpoch 1153/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 1154/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1154/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1155/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4458, acc=100.00%]\n\nEpoch 1155/2000 Summary:\nTraining Loss: 0.4458, Accuracy: 100.00%\nEpoch 1156/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4448, acc=100.00%]\n\nEpoch 1156/2000 Summary:\nTraining Loss: 0.4448, Accuracy: 100.00%\nEpoch 1157/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1157/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1158/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4457, acc=100.00%]\n\nEpoch 1158/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 1159/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1159/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1160/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1160/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1161/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4610, acc=100.00%]\n\nEpoch 1161/2000 Summary:\nTraining Loss: 0.4610, Accuracy: 100.00%\nEpoch 1162/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.04it/s, loss=0.4851, acc=97.96%] \n\nEpoch 1162/2000 Summary:\nTraining Loss: 0.4851, Accuracy: 97.96%\nEpoch 1163/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.5100, acc=97.59%]\n\nEpoch 1163/2000 Summary:\nTraining Loss: 0.5100, Accuracy: 97.59%\nEpoch 1164/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.23it/s, loss=0.4645, acc=99.44%]\n\nEpoch 1164/2000 Summary:\nTraining Loss: 0.4645, Accuracy: 99.44%\nEpoch 1165/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.70it/s, loss=0.4550, acc=99.81%]\n\nEpoch 1165/2000 Summary:\nTraining Loss: 0.4550, Accuracy: 99.81%\nEpoch 1166/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.98it/s, loss=0.4614, acc=100.00%]\n\nEpoch 1166/2000 Summary:\nTraining Loss: 0.4614, Accuracy: 100.00%\nEpoch 1167/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.4608, acc=100.00%]\n\nEpoch 1167/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 1168/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.30it/s, loss=0.4608, acc=100.00%]\n\nEpoch 1168/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 1169/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.40it/s, loss=0.4466, acc=100.00%]\n\nEpoch 1169/2000 Summary:\nTraining Loss: 0.4466, Accuracy: 100.00%\nEpoch 1170/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4541, acc=99.44%]\n\nEpoch 1170/2000 Summary:\nTraining Loss: 0.4541, Accuracy: 99.44%\nEpoch 1171/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4529, acc=99.44%] \n\nEpoch 1171/2000 Summary:\nTraining Loss: 0.4529, Accuracy: 99.44%\nEpoch 1172/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.46it/s, loss=0.4554, acc=99.44%]\n\nEpoch 1172/2000 Summary:\nTraining Loss: 0.4554, Accuracy: 99.44%\nEpoch 1173/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.37it/s, loss=0.4700, acc=99.44%]\n\nEpoch 1173/2000 Summary:\nTraining Loss: 0.4700, Accuracy: 99.44%\nEpoch 1174/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4612, acc=100.00%]\n\nEpoch 1174/2000 Summary:\nTraining Loss: 0.4612, Accuracy: 100.00%\nEpoch 1175/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4455, acc=99.81%] \n\nEpoch 1175/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 99.81%\nEpoch 1176/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4603, acc=100.00%]\n\nEpoch 1176/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 1177/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.4496, acc=99.63%]\n\nEpoch 1177/2000 Summary:\nTraining Loss: 0.4496, Accuracy: 99.63%\nEpoch 1178/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.4455, acc=100.00%]\n\nEpoch 1178/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 1179/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.95it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1179/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1180/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.65it/s, loss=0.4600, acc=100.00%]\n\nEpoch 1180/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 1181/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4452, acc=100.00%]\n\nEpoch 1181/2000 Summary:\nTraining Loss: 0.4452, Accuracy: 100.00%\nEpoch 1182/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.39it/s, loss=0.4450, acc=100.00%]\n\nEpoch 1182/2000 Summary:\nTraining Loss: 0.4450, Accuracy: 100.00%\nEpoch 1183/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1183/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1184/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.79it/s, loss=0.4456, acc=100.00%]\n\nEpoch 1184/2000 Summary:\nTraining Loss: 0.4456, Accuracy: 100.00%\nEpoch 1185/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.72it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1185/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1186/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1186/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1187/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1187/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1188/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.45it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1188/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1189/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.66it/s, loss=0.4454, acc=100.00%]\n\nEpoch 1189/2000 Summary:\nTraining Loss: 0.4454, Accuracy: 100.00%\nEpoch 1190/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1190/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1191/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.52it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1191/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1192/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.21it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1192/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1193/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1193/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1194/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.05it/s, loss=0.4455, acc=100.00%]\n\nEpoch 1194/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 1195/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.11it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1195/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1196/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.97it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1196/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1197/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.13it/s, loss=0.4604, acc=100.00%]\n\nEpoch 1197/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 1198/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.93it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1198/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1199/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.58it/s, loss=0.4612, acc=100.00%]\n\nEpoch 1199/2000 Summary:\nTraining Loss: 0.4612, Accuracy: 100.00%\nEpoch 1200/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1200/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1201/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1201/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1202/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.38it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1202/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1203/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1203/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1204/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.08it/s, loss=0.4461, acc=100.00%]\n\nEpoch 1204/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 1205/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4606, acc=100.00%]\n\nEpoch 1205/2000 Summary:\nTraining Loss: 0.4606, Accuracy: 100.00%\nEpoch 1206/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.28it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1206/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1207/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1207/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1208/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.38it/s, loss=0.4451, acc=100.00%]\n\nEpoch 1208/2000 Summary:\nTraining Loss: 0.4451, Accuracy: 100.00%\nEpoch 1209/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.57it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1209/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1210/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.4457, acc=100.00%]\n\nEpoch 1210/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 1211/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1211/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1212/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.34it/s, loss=0.4449, acc=100.00%]\n\nEpoch 1212/2000 Summary:\nTraining Loss: 0.4449, Accuracy: 100.00%\nEpoch 1213/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.75it/s, loss=0.4447, acc=100.00%]\n\nEpoch 1213/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 1214/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.43it/s, loss=0.4456, acc=100.00%]\n\nEpoch 1214/2000 Summary:\nTraining Loss: 0.4456, Accuracy: 100.00%\nEpoch 1215/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.27it/s, loss=0.4450, acc=100.00%]\n\nEpoch 1215/2000 Summary:\nTraining Loss: 0.4450, Accuracy: 100.00%\nEpoch 1216/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.03it/s, loss=0.4455, acc=100.00%]\n\nEpoch 1216/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 1217/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1217/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1218/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.45it/s, loss=0.4460, acc=100.00%]\n\nEpoch 1218/2000 Summary:\nTraining Loss: 0.4460, Accuracy: 100.00%\nEpoch 1219/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.13it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1219/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1220/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1220/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1221/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.52it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1221/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1222/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.64it/s, loss=0.4458, acc=100.00%]\n\nEpoch 1222/2000 Summary:\nTraining Loss: 0.4458, Accuracy: 100.00%\nEpoch 1223/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.75it/s, loss=0.4450, acc=100.00%]\n\nEpoch 1223/2000 Summary:\nTraining Loss: 0.4450, Accuracy: 100.00%\nEpoch 1224/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=0.4451, acc=100.00%]\n\nEpoch 1224/2000 Summary:\nTraining Loss: 0.4451, Accuracy: 100.00%\nEpoch 1225/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1225/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1226/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.20it/s, loss=0.4458, acc=100.00%]\n\nEpoch 1226/2000 Summary:\nTraining Loss: 0.4458, Accuracy: 100.00%\nEpoch 1227/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.04it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1227/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1228/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1228/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1229/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4636, acc=98.70%]\n\nEpoch 1229/2000 Summary:\nTraining Loss: 0.4636, Accuracy: 98.70%\nEpoch 1230/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.06it/s, loss=0.4786, acc=98.89%]\n\nEpoch 1230/2000 Summary:\nTraining Loss: 0.4786, Accuracy: 98.89%\nEpoch 1231/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4635, acc=100.00%]\n\nEpoch 1231/2000 Summary:\nTraining Loss: 0.4635, Accuracy: 100.00%\nEpoch 1232/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.44it/s, loss=0.4527, acc=99.63%] \n\nEpoch 1232/2000 Summary:\nTraining Loss: 0.4527, Accuracy: 99.63%\nEpoch 1233/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4621, acc=100.00%]\n\nEpoch 1233/2000 Summary:\nTraining Loss: 0.4621, Accuracy: 100.00%\nEpoch 1234/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4512, acc=99.63%] \n\nEpoch 1234/2000 Summary:\nTraining Loss: 0.4512, Accuracy: 99.63%\nEpoch 1235/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.63it/s, loss=0.4541, acc=99.63%] \n\nEpoch 1235/2000 Summary:\nTraining Loss: 0.4541, Accuracy: 99.63%\nEpoch 1236/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.4470, acc=100.00%]\n\nEpoch 1236/2000 Summary:\nTraining Loss: 0.4470, Accuracy: 100.00%\nEpoch 1237/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1237/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1238/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.57it/s, loss=0.4604, acc=100.00%]\n\nEpoch 1238/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 1239/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.44it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1239/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1240/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4454, acc=100.00%]\n\nEpoch 1240/2000 Summary:\nTraining Loss: 0.4454, Accuracy: 100.00%\nEpoch 1241/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.4457, acc=100.00%]\n\nEpoch 1241/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 1242/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4496, acc=99.63%] \n\nEpoch 1242/2000 Summary:\nTraining Loss: 0.4496, Accuracy: 99.63%\nEpoch 1243/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.99it/s, loss=0.4627, acc=99.81%] \n\nEpoch 1243/2000 Summary:\nTraining Loss: 0.4627, Accuracy: 99.81%\nEpoch 1244/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.4482, acc=99.63%] \n\nEpoch 1244/2000 Summary:\nTraining Loss: 0.4482, Accuracy: 99.63%\nEpoch 1245/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4689, acc=99.44%]\n\nEpoch 1245/2000 Summary:\nTraining Loss: 0.4689, Accuracy: 99.44%\nEpoch 1246/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.41it/s, loss=0.4668, acc=99.81%] \n\nEpoch 1246/2000 Summary:\nTraining Loss: 0.4668, Accuracy: 99.81%\nEpoch 1247/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4501, acc=99.81%] \n\nEpoch 1247/2000 Summary:\nTraining Loss: 0.4501, Accuracy: 99.81%\nEpoch 1248/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.32it/s, loss=0.4678, acc=99.44%]\n\nEpoch 1248/2000 Summary:\nTraining Loss: 0.4678, Accuracy: 99.44%\nEpoch 1249/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.43it/s, loss=0.4752, acc=99.07%]\n\nEpoch 1249/2000 Summary:\nTraining Loss: 0.4752, Accuracy: 99.07%\nEpoch 1250/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.82it/s, loss=0.4696, acc=99.81%]\n\nEpoch 1250/2000 Summary:\nTraining Loss: 0.4696, Accuracy: 99.81%\nEpoch 1251/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4628, acc=100.00%]\n\nEpoch 1251/2000 Summary:\nTraining Loss: 0.4628, Accuracy: 100.00%\nEpoch 1252/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.06it/s, loss=0.4482, acc=99.81%]\n\nEpoch 1252/2000 Summary:\nTraining Loss: 0.4482, Accuracy: 99.81%\nEpoch 1253/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4466, acc=100.00%]\n\nEpoch 1253/2000 Summary:\nTraining Loss: 0.4466, Accuracy: 100.00%\nEpoch 1254/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.4457, acc=99.81%] \n\nEpoch 1254/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 99.81%\nEpoch 1255/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1255/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1256/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.86it/s, loss=0.4602, acc=100.00%]\n\nEpoch 1256/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 1257/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.4602, acc=100.00%]\n\nEpoch 1257/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 1258/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4504, acc=99.81%]\n\nEpoch 1258/2000 Summary:\nTraining Loss: 0.4504, Accuracy: 99.81%\nEpoch 1259/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.51it/s, loss=0.4520, acc=99.63%]\n\nEpoch 1259/2000 Summary:\nTraining Loss: 0.4520, Accuracy: 99.63%\nEpoch 1260/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4606, acc=100.00%]\n\nEpoch 1260/2000 Summary:\nTraining Loss: 0.4606, Accuracy: 100.00%\nEpoch 1261/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4458, acc=100.00%]\n\nEpoch 1261/2000 Summary:\nTraining Loss: 0.4458, Accuracy: 100.00%\nEpoch 1262/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4462, acc=100.00%]\n\nEpoch 1262/2000 Summary:\nTraining Loss: 0.4462, Accuracy: 100.00%\nEpoch 1263/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.23it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1263/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1264/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.52it/s, loss=0.4619, acc=99.81%]\n\nEpoch 1264/2000 Summary:\nTraining Loss: 0.4619, Accuracy: 99.81%\nEpoch 1265/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1265/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1266/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.10it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1266/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1267/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1267/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1268/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.97it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1268/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1269/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1269/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1270/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4473, acc=99.81%] \n\nEpoch 1270/2000 Summary:\nTraining Loss: 0.4473, Accuracy: 99.81%\nEpoch 1271/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.28it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1271/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1272/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1272/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1273/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.68it/s, loss=0.4677, acc=99.26%] \n\nEpoch 1273/2000 Summary:\nTraining Loss: 0.4677, Accuracy: 99.26%\nEpoch 1274/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.44it/s, loss=0.4693, acc=99.63%] \n\nEpoch 1274/2000 Summary:\nTraining Loss: 0.4693, Accuracy: 99.63%\nEpoch 1275/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4603, acc=100.00%]\n\nEpoch 1275/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 1276/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4458, acc=100.00%]\n\nEpoch 1276/2000 Summary:\nTraining Loss: 0.4458, Accuracy: 100.00%\nEpoch 1277/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1277/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1278/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.01it/s, loss=0.4462, acc=100.00%]\n\nEpoch 1278/2000 Summary:\nTraining Loss: 0.4462, Accuracy: 100.00%\nEpoch 1279/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.40it/s, loss=0.4451, acc=100.00%]\n\nEpoch 1279/2000 Summary:\nTraining Loss: 0.4451, Accuracy: 100.00%\nEpoch 1280/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1280/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1281/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1281/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1282/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1282/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1283/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.69it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1283/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1284/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1284/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1285/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1285/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1286/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1286/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1287/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1287/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1288/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.13it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1288/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1289/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.4443, acc=100.00%]\n\nEpoch 1289/2000 Summary:\nTraining Loss: 0.4443, Accuracy: 100.00%\nEpoch 1290/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1290/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1291/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1291/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1292/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.99it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1292/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1293/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.37it/s, loss=0.4455, acc=100.00%]\n\nEpoch 1293/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 1294/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.20it/s, loss=0.4457, acc=100.00%]\n\nEpoch 1294/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 1295/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1295/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1296/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1296/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1297/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4457, acc=100.00%]\n\nEpoch 1297/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 1298/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.61it/s, loss=0.4460, acc=100.00%]\n\nEpoch 1298/2000 Summary:\nTraining Loss: 0.4460, Accuracy: 100.00%\nEpoch 1299/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.72it/s, loss=0.4460, acc=100.00%]\n\nEpoch 1299/2000 Summary:\nTraining Loss: 0.4460, Accuracy: 100.00%\nEpoch 1300/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1300/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1301/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1301/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1302/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4435, acc=100.00%]\n\nEpoch 1302/2000 Summary:\nTraining Loss: 0.4435, Accuracy: 100.00%\nEpoch 1303/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.51it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1303/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1304/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1304/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1305/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.42it/s, loss=0.4449, acc=100.00%]\n\nEpoch 1305/2000 Summary:\nTraining Loss: 0.4449, Accuracy: 100.00%\nEpoch 1306/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.35it/s, loss=0.4457, acc=100.00%]\n\nEpoch 1306/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 1307/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.01it/s, loss=0.4600, acc=100.00%]\n\nEpoch 1307/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 1308/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.03it/s, loss=0.4678, acc=98.52%]\n\nEpoch 1308/2000 Summary:\nTraining Loss: 0.4678, Accuracy: 98.52%\nEpoch 1309/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.66it/s, loss=0.4639, acc=100.00%]\n\nEpoch 1309/2000 Summary:\nTraining Loss: 0.4639, Accuracy: 100.00%\nEpoch 1310/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.30it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1310/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1311/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.92it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1311/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1312/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1312/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1313/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.33it/s, loss=0.4475, acc=100.00%]\n\nEpoch 1313/2000 Summary:\nTraining Loss: 0.4475, Accuracy: 100.00%\nEpoch 1314/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.30it/s, loss=0.4659, acc=99.63%] \n\nEpoch 1314/2000 Summary:\nTraining Loss: 0.4659, Accuracy: 99.63%\nEpoch 1315/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.40it/s, loss=0.4572, acc=99.26%]\n\nEpoch 1315/2000 Summary:\nTraining Loss: 0.4572, Accuracy: 99.26%\nEpoch 1316/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.70it/s, loss=0.4539, acc=99.44%]\n\nEpoch 1316/2000 Summary:\nTraining Loss: 0.4539, Accuracy: 99.44%\nEpoch 1317/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.34it/s, loss=0.4476, acc=99.81%]\n\nEpoch 1317/2000 Summary:\nTraining Loss: 0.4476, Accuracy: 99.81%\nEpoch 1318/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.82it/s, loss=0.4628, acc=99.81%] \n\nEpoch 1318/2000 Summary:\nTraining Loss: 0.4628, Accuracy: 99.81%\nEpoch 1319/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.16it/s, loss=0.4623, acc=99.81%]\n\nEpoch 1319/2000 Summary:\nTraining Loss: 0.4623, Accuracy: 99.81%\nEpoch 1320/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4501, acc=99.81%]\n\nEpoch 1320/2000 Summary:\nTraining Loss: 0.4501, Accuracy: 99.81%\nEpoch 1321/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4500, acc=99.63%]\n\nEpoch 1321/2000 Summary:\nTraining Loss: 0.4500, Accuracy: 99.63%\nEpoch 1322/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.03it/s, loss=0.4518, acc=99.81%]\n\nEpoch 1322/2000 Summary:\nTraining Loss: 0.4518, Accuracy: 99.81%\nEpoch 1323/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.29it/s, loss=0.4500, acc=99.81%] \n\nEpoch 1323/2000 Summary:\nTraining Loss: 0.4500, Accuracy: 99.81%\nEpoch 1324/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4489, acc=99.81%] \n\nEpoch 1324/2000 Summary:\nTraining Loss: 0.4489, Accuracy: 99.81%\nEpoch 1325/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4745, acc=99.07%]\n\nEpoch 1325/2000 Summary:\nTraining Loss: 0.4745, Accuracy: 99.07%\nEpoch 1326/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.35it/s, loss=0.4530, acc=99.44%]\n\nEpoch 1326/2000 Summary:\nTraining Loss: 0.4530, Accuracy: 99.44%\nEpoch 1327/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.72it/s, loss=0.4595, acc=99.26%]\n\nEpoch 1327/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 99.26%\nEpoch 1328/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4609, acc=100.00%]\n\nEpoch 1328/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 100.00%\nEpoch 1329/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1329/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1330/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1330/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1331/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1331/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1332/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1332/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1333/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.50it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1333/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1334/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.4459, acc=100.00%]\n\nEpoch 1334/2000 Summary:\nTraining Loss: 0.4459, Accuracy: 100.00%\nEpoch 1335/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.83it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1335/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1336/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.10it/s, loss=0.4602, acc=99.81%] \n\nEpoch 1336/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 99.81%\nEpoch 1337/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.05it/s, loss=0.4624, acc=99.63%] \n\nEpoch 1337/2000 Summary:\nTraining Loss: 0.4624, Accuracy: 99.63%\nEpoch 1338/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.84it/s, loss=0.4732, acc=99.26%]\n\nEpoch 1338/2000 Summary:\nTraining Loss: 0.4732, Accuracy: 99.26%\nEpoch 1339/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.4461, acc=100.00%]\n\nEpoch 1339/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 1340/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.74it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1340/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1341/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.60it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1341/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1342/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4607, acc=100.00%]\n\nEpoch 1342/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 1343/2000 [Train]: 100%|██████████| 34/34 [00:01<00:00, 30.77it/s, loss=0.4452, acc=100.00%]\n\nEpoch 1343/2000 Summary:\nTraining Loss: 0.4452, Accuracy: 100.00%\nEpoch 1344/2000 [Train]: 100%|██████████| 34/34 [00:01<00:00, 27.58it/s, loss=0.4741, acc=100.00%]\n\nEpoch 1344/2000 Summary:\nTraining Loss: 0.4741, Accuracy: 100.00%\nEpoch 1345/2000 [Train]: 100%|██████████| 34/34 [00:01<00:00, 33.32it/s, loss=0.4907, acc=100.00%]\n\nEpoch 1345/2000 Summary:\nTraining Loss: 0.4907, Accuracy: 100.00%\nEpoch 1346/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 39.48it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1346/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1347/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 38.68it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1347/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1348/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.80it/s, loss=0.4448, acc=100.00%]\n\nEpoch 1348/2000 Summary:\nTraining Loss: 0.4448, Accuracy: 100.00%\nEpoch 1349/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1349/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1350/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 35.09it/s, loss=0.5073, acc=100.00%]\n\nEpoch 1350/2000 Summary:\nTraining Loss: 0.5073, Accuracy: 100.00%\nEpoch 1351/2000 [Train]: 100%|██████████| 34/34 [00:01<00:00, 31.35it/s, loss=0.5064, acc=100.00%]\n\nEpoch 1351/2000 Summary:\nTraining Loss: 0.5064, Accuracy: 100.00%\nEpoch 1352/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 37.91it/s, loss=0.4902, acc=100.00%]\n\nEpoch 1352/2000 Summary:\nTraining Loss: 0.4902, Accuracy: 100.00%\nEpoch 1353/2000 [Train]: 100%|██████████| 34/34 [00:01<00:00, 33.57it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1353/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1354/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 39.08it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1354/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1355/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 34.46it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1355/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1356/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.30it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1356/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1357/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1357/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1358/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.87it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1358/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1359/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1359/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1360/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.86it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1360/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1361/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=0.4449, acc=100.00%]\n\nEpoch 1361/2000 Summary:\nTraining Loss: 0.4449, Accuracy: 100.00%\nEpoch 1362/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.93it/s, loss=0.4447, acc=100.00%]\n\nEpoch 1362/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 1363/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.80it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1363/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1364/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.10it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1364/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1365/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1365/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1366/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4445, acc=100.00%]\n\nEpoch 1366/2000 Summary:\nTraining Loss: 0.4445, Accuracy: 100.00%\nEpoch 1367/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4445, acc=100.00%]\n\nEpoch 1367/2000 Summary:\nTraining Loss: 0.4445, Accuracy: 100.00%\nEpoch 1368/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.25it/s, loss=0.4579, acc=100.00%]\n\nEpoch 1368/2000 Summary:\nTraining Loss: 0.4579, Accuracy: 100.00%\nEpoch 1369/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1369/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1370/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.43it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1370/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1371/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1371/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1372/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1372/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1373/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.88it/s, loss=0.4448, acc=100.00%]\n\nEpoch 1373/2000 Summary:\nTraining Loss: 0.4448, Accuracy: 100.00%\nEpoch 1374/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.91it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1374/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1375/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.30it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1375/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1376/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1376/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1377/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.64it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1377/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1378/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4600, acc=100.00%]\n\nEpoch 1378/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 1379/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.69it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1379/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1380/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1380/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1381/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1381/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1382/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1382/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1383/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.86it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1383/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1384/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1384/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1385/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.89it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1385/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1386/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1386/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1387/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.80it/s, loss=0.4602, acc=100.00%]\n\nEpoch 1387/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 1388/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1388/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1389/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1389/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1390/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1390/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1391/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4458, acc=100.00%]\n\nEpoch 1391/2000 Summary:\nTraining Loss: 0.4458, Accuracy: 100.00%\nEpoch 1392/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1392/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1393/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1393/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1394/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1394/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1395/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.61it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1395/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1396/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1396/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1397/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1397/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1398/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4574, acc=100.00%]\n\nEpoch 1398/2000 Summary:\nTraining Loss: 0.4574, Accuracy: 100.00%\nEpoch 1399/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.50it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1399/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1400/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1400/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1401/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1401/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1402/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.77it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1402/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1403/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.51it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1403/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1404/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1404/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1405/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.60it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1405/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1406/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.22it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1406/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1407/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4791, acc=99.07%] \n\nEpoch 1407/2000 Summary:\nTraining Loss: 0.4791, Accuracy: 99.07%\nEpoch 1408/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.25it/s, loss=0.4631, acc=99.07%]\n\nEpoch 1408/2000 Summary:\nTraining Loss: 0.4631, Accuracy: 99.07%\nEpoch 1409/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.78it/s, loss=0.4709, acc=99.44%]\n\nEpoch 1409/2000 Summary:\nTraining Loss: 0.4709, Accuracy: 99.44%\nEpoch 1410/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.57it/s, loss=0.4675, acc=98.52%]\n\nEpoch 1410/2000 Summary:\nTraining Loss: 0.4675, Accuracy: 98.52%\nEpoch 1411/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4741, acc=99.07%]\n\nEpoch 1411/2000 Summary:\nTraining Loss: 0.4741, Accuracy: 99.07%\nEpoch 1412/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.4602, acc=98.89%]\n\nEpoch 1412/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 98.89%\nEpoch 1413/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.06it/s, loss=0.4735, acc=99.07%]\n\nEpoch 1413/2000 Summary:\nTraining Loss: 0.4735, Accuracy: 99.07%\nEpoch 1414/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=0.4716, acc=99.26%]\n\nEpoch 1414/2000 Summary:\nTraining Loss: 0.4716, Accuracy: 99.26%\nEpoch 1415/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.92it/s, loss=0.4635, acc=99.81%] \n\nEpoch 1415/2000 Summary:\nTraining Loss: 0.4635, Accuracy: 99.81%\nEpoch 1416/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4617, acc=99.81%]\n\nEpoch 1416/2000 Summary:\nTraining Loss: 0.4617, Accuracy: 99.81%\nEpoch 1417/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=0.4607, acc=100.00%]\n\nEpoch 1417/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 100.00%\nEpoch 1418/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4576, acc=100.00%]\n\nEpoch 1418/2000 Summary:\nTraining Loss: 0.4576, Accuracy: 100.00%\nEpoch 1419/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.44it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1419/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1420/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.75it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1420/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1421/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.37it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1421/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1422/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.69it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1422/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1423/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1423/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1424/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1424/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1425/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1425/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1426/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.91it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1426/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1427/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.25it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1427/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1428/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.22it/s, loss=0.4599, acc=100.00%]\n\nEpoch 1428/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 1429/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.33it/s, loss=0.4450, acc=100.00%]\n\nEpoch 1429/2000 Summary:\nTraining Loss: 0.4450, Accuracy: 100.00%\nEpoch 1430/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1430/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1431/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.55it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1431/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1432/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1432/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1433/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1433/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1434/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.37it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1434/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1435/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.50it/s, loss=0.4602, acc=100.00%]\n\nEpoch 1435/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 1436/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1436/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1437/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1437/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1438/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1438/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1439/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4571, acc=100.00%]\n\nEpoch 1439/2000 Summary:\nTraining Loss: 0.4571, Accuracy: 100.00%\nEpoch 1440/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1440/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1441/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4603, acc=100.00%]\n\nEpoch 1441/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 1442/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.75it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1442/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1443/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1443/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1444/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4578, acc=100.00%]\n\nEpoch 1444/2000 Summary:\nTraining Loss: 0.4578, Accuracy: 100.00%\nEpoch 1445/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.82it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1445/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1446/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1446/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1447/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.28it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1447/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1448/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1448/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1449/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1449/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1450/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.69it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1450/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1451/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.08it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1451/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1452/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1452/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1453/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.91it/s, loss=0.4578, acc=100.00%]\n\nEpoch 1453/2000 Summary:\nTraining Loss: 0.4578, Accuracy: 100.00%\nEpoch 1454/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1454/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1455/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.74it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1455/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1456/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.27it/s, loss=0.4605, acc=99.81%] \n\nEpoch 1456/2000 Summary:\nTraining Loss: 0.4605, Accuracy: 99.81%\nEpoch 1457/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1457/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1458/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.76it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1458/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1459/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.97it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1459/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1460/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.31it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1460/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1461/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.98it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1461/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1462/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.27it/s, loss=0.4600, acc=100.00%]\n\nEpoch 1462/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 1463/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.04it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1463/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1464/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.21it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1464/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1465/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.50it/s, loss=0.4449, acc=100.00%]\n\nEpoch 1465/2000 Summary:\nTraining Loss: 0.4449, Accuracy: 100.00%\nEpoch 1466/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1466/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1467/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1467/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1468/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.87it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1468/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1469/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1469/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1470/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.75it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1470/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1471/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1471/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1472/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1472/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1473/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.40it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1473/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1474/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1474/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1475/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.92it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1475/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1476/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.52it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1476/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1477/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.87it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1477/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1478/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.57it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1478/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1479/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.16it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1479/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1480/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1480/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1481/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.97it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1481/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1482/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.55it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1482/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1483/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4603, acc=100.00%]\n\nEpoch 1483/2000 Summary:\nTraining Loss: 0.4603, Accuracy: 100.00%\nEpoch 1484/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4457, acc=100.00%]\n\nEpoch 1484/2000 Summary:\nTraining Loss: 0.4457, Accuracy: 100.00%\nEpoch 1485/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.85it/s, loss=0.4458, acc=100.00%]\n\nEpoch 1485/2000 Summary:\nTraining Loss: 0.4458, Accuracy: 100.00%\nEpoch 1486/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.4451, acc=100.00%]\n\nEpoch 1486/2000 Summary:\nTraining Loss: 0.4451, Accuracy: 100.00%\nEpoch 1487/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.40it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1487/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1488/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4575, acc=100.00%]\n\nEpoch 1488/2000 Summary:\nTraining Loss: 0.4575, Accuracy: 100.00%\nEpoch 1489/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1489/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1490/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1490/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1491/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.70it/s, loss=0.4579, acc=100.00%]\n\nEpoch 1491/2000 Summary:\nTraining Loss: 0.4579, Accuracy: 100.00%\nEpoch 1492/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4578, acc=100.00%]\n\nEpoch 1492/2000 Summary:\nTraining Loss: 0.4578, Accuracy: 100.00%\nEpoch 1493/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.11it/s, loss=0.4455, acc=100.00%]\n\nEpoch 1493/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 1494/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1494/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1495/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1495/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1496/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.38it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1496/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1497/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.97it/s, loss=0.4576, acc=100.00%]\n\nEpoch 1497/2000 Summary:\nTraining Loss: 0.4576, Accuracy: 100.00%\nEpoch 1498/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.43it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1498/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1499/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.63it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1499/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1500/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.4570, acc=100.00%]\n\nEpoch 1500/2000 Summary:\nTraining Loss: 0.4570, Accuracy: 100.00%\nEpoch 1501/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.63it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1501/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1502/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1502/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1503/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.22it/s, loss=0.4576, acc=100.00%]\n\nEpoch 1503/2000 Summary:\nTraining Loss: 0.4576, Accuracy: 100.00%\nEpoch 1504/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.11it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1504/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1505/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4450, acc=100.00%]\n\nEpoch 1505/2000 Summary:\nTraining Loss: 0.4450, Accuracy: 100.00%\nEpoch 1506/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.97it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1506/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1507/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.4578, acc=100.00%]\n\nEpoch 1507/2000 Summary:\nTraining Loss: 0.4578, Accuracy: 100.00%\nEpoch 1508/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.55it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1508/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1509/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.13it/s, loss=0.4446, acc=100.00%]\n\nEpoch 1509/2000 Summary:\nTraining Loss: 0.4446, Accuracy: 100.00%\nEpoch 1510/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.74it/s, loss=0.4447, acc=100.00%]\n\nEpoch 1510/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 1511/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.99it/s, loss=0.4450, acc=100.00%]\n\nEpoch 1511/2000 Summary:\nTraining Loss: 0.4450, Accuracy: 100.00%\nEpoch 1512/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.13it/s, loss=0.4447, acc=100.00%]\n\nEpoch 1512/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 1513/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.29it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1513/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1514/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1514/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1515/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.92it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1515/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1516/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1516/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1517/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.51it/s, loss=0.4438, acc=100.00%]\n\nEpoch 1517/2000 Summary:\nTraining Loss: 0.4438, Accuracy: 100.00%\nEpoch 1518/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4450, acc=100.00%]\n\nEpoch 1518/2000 Summary:\nTraining Loss: 0.4450, Accuracy: 100.00%\nEpoch 1519/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1519/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1520/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.96it/s, loss=0.4569, acc=100.00%]\n\nEpoch 1520/2000 Summary:\nTraining Loss: 0.4569, Accuracy: 100.00%\nEpoch 1521/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.02it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1521/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1522/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.05it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1522/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1523/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.19it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1523/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1524/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1524/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1525/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1525/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1526/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4438, acc=100.00%]\n\nEpoch 1526/2000 Summary:\nTraining Loss: 0.4438, Accuracy: 100.00%\nEpoch 1527/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1527/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1528/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.91it/s, loss=0.4599, acc=100.00%]\n\nEpoch 1528/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 1529/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1529/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1530/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.54it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1530/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1531/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1531/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1532/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.23it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1532/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1533/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.73it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1533/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1534/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1534/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1535/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.03it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1535/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1536/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1536/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1537/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1537/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1538/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=0.4741, acc=99.26%] \n\nEpoch 1538/2000 Summary:\nTraining Loss: 0.4741, Accuracy: 99.26%\nEpoch 1539/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.5119, acc=97.22%]\n\nEpoch 1539/2000 Summary:\nTraining Loss: 0.5119, Accuracy: 97.22%\nEpoch 1540/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4844, acc=98.70%]\n\nEpoch 1540/2000 Summary:\nTraining Loss: 0.4844, Accuracy: 98.70%\nEpoch 1541/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.31it/s, loss=0.4711, acc=99.44%] \n\nEpoch 1541/2000 Summary:\nTraining Loss: 0.4711, Accuracy: 99.44%\nEpoch 1542/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.4654, acc=99.81%] \n\nEpoch 1542/2000 Summary:\nTraining Loss: 0.4654, Accuracy: 99.81%\nEpoch 1543/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.37it/s, loss=0.4613, acc=100.00%]\n\nEpoch 1543/2000 Summary:\nTraining Loss: 0.4613, Accuracy: 100.00%\nEpoch 1544/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1544/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1545/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.49it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1545/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1546/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1546/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1547/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=0.4443, acc=100.00%]\n\nEpoch 1547/2000 Summary:\nTraining Loss: 0.4443, Accuracy: 100.00%\nEpoch 1548/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.63it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1548/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1549/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.21it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1549/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1550/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1550/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1551/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.43it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1551/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1552/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1552/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1553/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.4610, acc=100.00%]\n\nEpoch 1553/2000 Summary:\nTraining Loss: 0.4610, Accuracy: 100.00%\nEpoch 1554/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.79it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1554/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1555/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1555/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1556/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.94it/s, loss=0.4577, acc=100.00%]\n\nEpoch 1556/2000 Summary:\nTraining Loss: 0.4577, Accuracy: 100.00%\nEpoch 1557/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.65it/s, loss=0.4578, acc=100.00%]\n\nEpoch 1557/2000 Summary:\nTraining Loss: 0.4578, Accuracy: 100.00%\nEpoch 1558/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.28it/s, loss=0.4458, acc=100.00%]\n\nEpoch 1558/2000 Summary:\nTraining Loss: 0.4458, Accuracy: 100.00%\nEpoch 1559/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1559/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1560/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4446, acc=100.00%]\n\nEpoch 1560/2000 Summary:\nTraining Loss: 0.4446, Accuracy: 100.00%\nEpoch 1561/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.39it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1561/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1562/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.15it/s, loss=0.4599, acc=100.00%]\n\nEpoch 1562/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 1563/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.66it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1563/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1564/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.13it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1564/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1565/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.81it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1565/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1566/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.30it/s, loss=0.4599, acc=100.00%]\n\nEpoch 1566/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 1567/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.99it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1567/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1568/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1568/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1569/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1569/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1570/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1570/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1571/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.54it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1571/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1572/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.33it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1572/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1573/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.78it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1573/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1574/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.61it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1574/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1575/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1575/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1576/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.31it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1576/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1577/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4571, acc=100.00%]\n\nEpoch 1577/2000 Summary:\nTraining Loss: 0.4571, Accuracy: 100.00%\nEpoch 1578/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4447, acc=100.00%]\n\nEpoch 1578/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 1579/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1579/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1580/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.10it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1580/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1581/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.33it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1581/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1582/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1582/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1583/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.05it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1583/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1584/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1584/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1585/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1585/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1586/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4444, acc=100.00%]\n\nEpoch 1586/2000 Summary:\nTraining Loss: 0.4444, Accuracy: 100.00%\nEpoch 1587/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.19it/s, loss=0.4306, acc=100.00%]\n\nEpoch 1587/2000 Summary:\nTraining Loss: 0.4306, Accuracy: 100.00%\nEpoch 1588/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.28it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1588/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1589/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.55it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1589/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1590/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.38it/s, loss=0.4434, acc=100.00%]\n\nEpoch 1590/2000 Summary:\nTraining Loss: 0.4434, Accuracy: 100.00%\nEpoch 1591/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.66it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1591/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1592/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.63it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1592/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1593/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1593/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1594/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4596, acc=99.81%] \n\nEpoch 1594/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 99.81%\nEpoch 1595/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.81it/s, loss=0.4510, acc=99.63%]\n\nEpoch 1595/2000 Summary:\nTraining Loss: 0.4510, Accuracy: 99.63%\nEpoch 1596/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4653, acc=99.07%]\n\nEpoch 1596/2000 Summary:\nTraining Loss: 0.4653, Accuracy: 99.07%\nEpoch 1597/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.4646, acc=99.63%] \n\nEpoch 1597/2000 Summary:\nTraining Loss: 0.4646, Accuracy: 99.63%\nEpoch 1598/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.31it/s, loss=0.4701, acc=99.63%]\n\nEpoch 1598/2000 Summary:\nTraining Loss: 0.4701, Accuracy: 99.63%\nEpoch 1599/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.78it/s, loss=0.4531, acc=99.63%] \n\nEpoch 1599/2000 Summary:\nTraining Loss: 0.4531, Accuracy: 99.63%\nEpoch 1600/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.05it/s, loss=0.4646, acc=99.81%]\n\nEpoch 1600/2000 Summary:\nTraining Loss: 0.4646, Accuracy: 99.81%\nEpoch 1601/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1601/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1602/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.45it/s, loss=0.4461, acc=100.00%]\n\nEpoch 1602/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 1603/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.04it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1603/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1604/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.71it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1604/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1605/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.47it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1605/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1606/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.84it/s, loss=0.4577, acc=100.00%]\n\nEpoch 1606/2000 Summary:\nTraining Loss: 0.4577, Accuracy: 100.00%\nEpoch 1607/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.51it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1607/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1608/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1608/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1609/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.4461, acc=100.00%]\n\nEpoch 1609/2000 Summary:\nTraining Loss: 0.4461, Accuracy: 100.00%\nEpoch 1610/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.06it/s, loss=0.4604, acc=100.00%]\n\nEpoch 1610/2000 Summary:\nTraining Loss: 0.4604, Accuracy: 100.00%\nEpoch 1611/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.12it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1611/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1612/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.97it/s, loss=0.4500, acc=99.44%]\n\nEpoch 1612/2000 Summary:\nTraining Loss: 0.4500, Accuracy: 99.44%\nEpoch 1613/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.62it/s, loss=0.4634, acc=99.63%]\n\nEpoch 1613/2000 Summary:\nTraining Loss: 0.4634, Accuracy: 99.63%\nEpoch 1614/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4451, acc=100.00%]\n\nEpoch 1614/2000 Summary:\nTraining Loss: 0.4451, Accuracy: 100.00%\nEpoch 1615/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.13it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1615/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1616/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1616/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1617/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.54it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1617/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1618/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.13it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1618/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1619/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.12it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1619/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1620/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.06it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1620/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1621/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.85it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1621/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1622/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4729, acc=99.26%]\n\nEpoch 1622/2000 Summary:\nTraining Loss: 0.4729, Accuracy: 99.26%\nEpoch 1623/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4665, acc=99.63%] \n\nEpoch 1623/2000 Summary:\nTraining Loss: 0.4665, Accuracy: 99.63%\nEpoch 1624/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.45it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1624/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1625/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.52it/s, loss=0.4599, acc=100.00%]\n\nEpoch 1625/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 1626/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4609, acc=99.81%] \n\nEpoch 1626/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 99.81%\nEpoch 1627/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1627/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1628/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.78it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1628/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1629/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.48it/s, loss=0.4465, acc=100.00%]\n\nEpoch 1629/2000 Summary:\nTraining Loss: 0.4465, Accuracy: 100.00%\nEpoch 1630/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.75it/s, loss=0.4642, acc=99.81%]\n\nEpoch 1630/2000 Summary:\nTraining Loss: 0.4642, Accuracy: 99.81%\nEpoch 1631/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1631/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1632/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4611, acc=99.81%] \n\nEpoch 1632/2000 Summary:\nTraining Loss: 0.4611, Accuracy: 99.81%\nEpoch 1633/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4500, acc=99.44%]\n\nEpoch 1633/2000 Summary:\nTraining Loss: 0.4500, Accuracy: 99.44%\nEpoch 1634/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.37it/s, loss=0.4844, acc=98.14%]\n\nEpoch 1634/2000 Summary:\nTraining Loss: 0.4844, Accuracy: 98.14%\nEpoch 1635/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.05it/s, loss=0.4715, acc=99.44%]\n\nEpoch 1635/2000 Summary:\nTraining Loss: 0.4715, Accuracy: 99.44%\nEpoch 1636/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.93it/s, loss=0.4696, acc=99.26%]\n\nEpoch 1636/2000 Summary:\nTraining Loss: 0.4696, Accuracy: 99.26%\nEpoch 1637/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4618, acc=99.81%] \n\nEpoch 1637/2000 Summary:\nTraining Loss: 0.4618, Accuracy: 99.81%\nEpoch 1638/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.10it/s, loss=0.4631, acc=99.81%] \n\nEpoch 1638/2000 Summary:\nTraining Loss: 0.4631, Accuracy: 99.81%\nEpoch 1639/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1639/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1640/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.86it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1640/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1641/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1641/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1642/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1642/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1643/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.20it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1643/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1644/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.38it/s, loss=0.4614, acc=99.81%]\n\nEpoch 1644/2000 Summary:\nTraining Loss: 0.4614, Accuracy: 99.81%\nEpoch 1645/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.03it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1645/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1646/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1646/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1647/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.25it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1647/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1648/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.50it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1648/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1649/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.14it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1649/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1650/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.69it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1650/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1651/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1651/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1652/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.00it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1652/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1653/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.18it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1653/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1654/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.50it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1654/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1655/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.73it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1655/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1656/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.82it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1656/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1657/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1657/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1658/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1658/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1659/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4452, acc=100.00%]\n\nEpoch 1659/2000 Summary:\nTraining Loss: 0.4452, Accuracy: 100.00%\nEpoch 1660/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.84it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1660/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1661/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.00it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1661/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1662/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.89it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1662/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1663/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.73it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1663/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1664/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.89it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1664/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1665/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.88it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1665/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1666/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.25it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1666/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1667/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1667/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1668/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.82it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1668/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1669/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1669/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1670/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1670/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1671/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1671/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1672/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.79it/s, loss=0.4445, acc=100.00%]\n\nEpoch 1672/2000 Summary:\nTraining Loss: 0.4445, Accuracy: 100.00%\nEpoch 1673/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1673/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1674/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1674/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1675/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.05it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1675/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1676/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.24it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1676/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1677/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=0.4445, acc=100.00%]\n\nEpoch 1677/2000 Summary:\nTraining Loss: 0.4445, Accuracy: 100.00%\nEpoch 1678/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.10it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1678/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1679/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.37it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1679/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1680/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1680/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1681/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.57it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1681/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1682/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.17it/s, loss=0.4440, acc=100.00%]\n\nEpoch 1682/2000 Summary:\nTraining Loss: 0.4440, Accuracy: 100.00%\nEpoch 1683/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1683/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1684/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1684/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1685/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.4442, acc=100.00%]\n\nEpoch 1685/2000 Summary:\nTraining Loss: 0.4442, Accuracy: 100.00%\nEpoch 1686/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1686/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1687/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1687/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1688/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1688/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1689/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.97it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1689/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1690/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.44it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1690/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1691/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.45it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1691/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1692/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1692/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1693/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1693/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1694/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1694/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1695/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.89it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1695/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1696/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.74it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1696/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1697/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1697/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1698/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1698/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1699/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.02it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1699/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1700/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.91it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1700/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1701/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.16it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1701/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1702/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.10it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1702/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1703/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.82it/s, loss=0.4571, acc=100.00%]\n\nEpoch 1703/2000 Summary:\nTraining Loss: 0.4571, Accuracy: 100.00%\nEpoch 1704/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.22it/s, loss=0.4577, acc=100.00%]\n\nEpoch 1704/2000 Summary:\nTraining Loss: 0.4577, Accuracy: 100.00%\nEpoch 1705/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.95it/s, loss=0.4443, acc=100.00%]\n\nEpoch 1705/2000 Summary:\nTraining Loss: 0.4443, Accuracy: 100.00%\nEpoch 1706/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1706/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1707/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4451, acc=100.00%]\n\nEpoch 1707/2000 Summary:\nTraining Loss: 0.4451, Accuracy: 100.00%\nEpoch 1708/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.75it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1708/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1709/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1709/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1710/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.27it/s, loss=0.4572, acc=100.00%]\n\nEpoch 1710/2000 Summary:\nTraining Loss: 0.4572, Accuracy: 100.00%\nEpoch 1711/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1711/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1712/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.4443, acc=100.00%]\n\nEpoch 1712/2000 Summary:\nTraining Loss: 0.4443, Accuracy: 100.00%\nEpoch 1713/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.67it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1713/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1714/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.19it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1714/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1715/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.16it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1715/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1716/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.91it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1716/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1717/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.75it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1717/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1718/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.16it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1718/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1719/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1719/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1720/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.83it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1720/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1721/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.73it/s, loss=0.4454, acc=100.00%]\n\nEpoch 1721/2000 Summary:\nTraining Loss: 0.4454, Accuracy: 100.00%\nEpoch 1722/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.28it/s, loss=0.4445, acc=100.00%]\n\nEpoch 1722/2000 Summary:\nTraining Loss: 0.4445, Accuracy: 100.00%\nEpoch 1723/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.71it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1723/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1724/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1724/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1725/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.95it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1725/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1726/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.66it/s, loss=0.4599, acc=100.00%]\n\nEpoch 1726/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 1727/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.54it/s, loss=0.4443, acc=100.00%]\n\nEpoch 1727/2000 Summary:\nTraining Loss: 0.4443, Accuracy: 100.00%\nEpoch 1728/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.89it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1728/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1729/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.50it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1729/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1730/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4579, acc=100.00%]\n\nEpoch 1730/2000 Summary:\nTraining Loss: 0.4579, Accuracy: 100.00%\nEpoch 1731/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.27it/s, loss=0.4576, acc=100.00%]\n\nEpoch 1731/2000 Summary:\nTraining Loss: 0.4576, Accuracy: 100.00%\nEpoch 1732/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4576, acc=100.00%]\n\nEpoch 1732/2000 Summary:\nTraining Loss: 0.4576, Accuracy: 100.00%\nEpoch 1733/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.79it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1733/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1734/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1734/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1735/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4456, acc=100.00%]\n\nEpoch 1735/2000 Summary:\nTraining Loss: 0.4456, Accuracy: 100.00%\nEpoch 1736/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.88it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1736/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1737/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.18it/s, loss=0.4454, acc=100.00%]\n\nEpoch 1737/2000 Summary:\nTraining Loss: 0.4454, Accuracy: 100.00%\nEpoch 1738/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1738/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1739/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1739/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1740/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.62it/s, loss=0.4572, acc=100.00%]\n\nEpoch 1740/2000 Summary:\nTraining Loss: 0.4572, Accuracy: 100.00%\nEpoch 1741/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.37it/s, loss=0.4577, acc=100.00%]\n\nEpoch 1741/2000 Summary:\nTraining Loss: 0.4577, Accuracy: 100.00%\nEpoch 1742/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1742/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1743/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.03it/s, loss=0.4577, acc=100.00%]\n\nEpoch 1743/2000 Summary:\nTraining Loss: 0.4577, Accuracy: 100.00%\nEpoch 1744/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1744/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1745/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1745/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1746/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.70it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1746/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1747/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.57it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1747/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1748/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.23it/s, loss=0.4600, acc=100.00%]\n\nEpoch 1748/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 1749/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.13it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1749/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1750/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.84it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1750/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1751/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1751/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1752/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.09it/s, loss=0.4443, acc=100.00%]\n\nEpoch 1752/2000 Summary:\nTraining Loss: 0.4443, Accuracy: 100.00%\nEpoch 1753/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4451, acc=100.00%]\n\nEpoch 1753/2000 Summary:\nTraining Loss: 0.4451, Accuracy: 100.00%\nEpoch 1754/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.40it/s, loss=0.4440, acc=100.00%]\n\nEpoch 1754/2000 Summary:\nTraining Loss: 0.4440, Accuracy: 100.00%\nEpoch 1755/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.07it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1755/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1756/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.21it/s, loss=0.4764, acc=98.70%]\n\nEpoch 1756/2000 Summary:\nTraining Loss: 0.4764, Accuracy: 98.70%\nEpoch 1757/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.53it/s, loss=0.4895, acc=98.33%]\n\nEpoch 1757/2000 Summary:\nTraining Loss: 0.4895, Accuracy: 98.33%\nEpoch 1758/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.05it/s, loss=0.4750, acc=99.07%]\n\nEpoch 1758/2000 Summary:\nTraining Loss: 0.4750, Accuracy: 99.07%\nEpoch 1759/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.73it/s, loss=0.4620, acc=98.70%]\n\nEpoch 1759/2000 Summary:\nTraining Loss: 0.4620, Accuracy: 98.70%\nEpoch 1760/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4721, acc=99.07%]\n\nEpoch 1760/2000 Summary:\nTraining Loss: 0.4721, Accuracy: 99.07%\nEpoch 1761/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.55it/s, loss=0.4712, acc=98.89%]\n\nEpoch 1761/2000 Summary:\nTraining Loss: 0.4712, Accuracy: 98.89%\nEpoch 1762/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4658, acc=99.63%]\n\nEpoch 1762/2000 Summary:\nTraining Loss: 0.4658, Accuracy: 99.63%\nEpoch 1763/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4610, acc=100.00%]\n\nEpoch 1763/2000 Summary:\nTraining Loss: 0.4610, Accuracy: 100.00%\nEpoch 1764/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.44it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1764/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1765/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1765/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1766/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4597, acc=100.00%]\n\nEpoch 1766/2000 Summary:\nTraining Loss: 0.4597, Accuracy: 100.00%\nEpoch 1767/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4608, acc=99.81%] \n\nEpoch 1767/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 99.81%\nEpoch 1768/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.25it/s, loss=0.4609, acc=99.81%] \n\nEpoch 1768/2000 Summary:\nTraining Loss: 0.4609, Accuracy: 99.81%\nEpoch 1769/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1769/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1770/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4577, acc=100.00%]\n\nEpoch 1770/2000 Summary:\nTraining Loss: 0.4577, Accuracy: 100.00%\nEpoch 1771/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.85it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1771/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1772/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.31it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1772/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1773/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.13it/s, loss=0.4447, acc=100.00%]\n\nEpoch 1773/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 1774/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.48it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1774/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1775/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4442, acc=100.00%]\n\nEpoch 1775/2000 Summary:\nTraining Loss: 0.4442, Accuracy: 100.00%\nEpoch 1776/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4577, acc=100.00%]\n\nEpoch 1776/2000 Summary:\nTraining Loss: 0.4577, Accuracy: 100.00%\nEpoch 1777/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.35it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1777/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1778/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.31it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1778/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1779/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.4462, acc=100.00%]\n\nEpoch 1779/2000 Summary:\nTraining Loss: 0.4462, Accuracy: 100.00%\nEpoch 1780/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.27it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1780/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1781/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1781/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1782/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4447, acc=100.00%]\n\nEpoch 1782/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 1783/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.61it/s, loss=0.4600, acc=100.00%]\n\nEpoch 1783/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 1784/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.80it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1784/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1785/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4610, acc=99.81%] \n\nEpoch 1785/2000 Summary:\nTraining Loss: 0.4610, Accuracy: 99.81%\nEpoch 1786/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.85it/s, loss=0.4602, acc=100.00%]\n\nEpoch 1786/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 1787/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1787/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1788/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.88it/s, loss=0.4447, acc=100.00%]\n\nEpoch 1788/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 1789/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=0.4452, acc=100.00%]\n\nEpoch 1789/2000 Summary:\nTraining Loss: 0.4452, Accuracy: 100.00%\nEpoch 1790/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.63it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1790/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1791/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1791/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1792/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.10it/s, loss=0.4460, acc=100.00%]\n\nEpoch 1792/2000 Summary:\nTraining Loss: 0.4460, Accuracy: 100.00%\nEpoch 1793/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1793/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1794/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.51it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1794/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1795/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.15it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1795/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1796/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4455, acc=100.00%]\n\nEpoch 1796/2000 Summary:\nTraining Loss: 0.4455, Accuracy: 100.00%\nEpoch 1797/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.16it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1797/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1798/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.66it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1798/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1799/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1799/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1800/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.77it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1800/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1801/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.43it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1801/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1802/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1802/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1803/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.38it/s, loss=0.4617, acc=99.81%] \n\nEpoch 1803/2000 Summary:\nTraining Loss: 0.4617, Accuracy: 99.81%\nEpoch 1804/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.59it/s, loss=0.4694, acc=99.26%]\n\nEpoch 1804/2000 Summary:\nTraining Loss: 0.4694, Accuracy: 99.26%\nEpoch 1805/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.98it/s, loss=0.4592, acc=99.81%] \n\nEpoch 1805/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 99.81%\nEpoch 1806/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1806/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1807/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1807/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1808/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.75it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1808/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1809/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.19it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1809/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1810/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.15it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1810/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1811/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1811/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1812/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.52it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1812/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1813/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.41it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1813/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1814/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.76it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1814/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1815/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1815/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1816/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.90it/s, loss=0.4449, acc=100.00%]\n\nEpoch 1816/2000 Summary:\nTraining Loss: 0.4449, Accuracy: 100.00%\nEpoch 1817/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.11it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1817/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1818/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.72it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1818/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1819/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1819/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1820/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1820/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1821/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.25it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1821/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1822/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1822/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1823/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1823/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1824/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.93it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1824/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1825/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1825/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1826/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1826/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1827/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.68it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1827/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1828/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.28it/s, loss=0.4578, acc=100.00%]\n\nEpoch 1828/2000 Summary:\nTraining Loss: 0.4578, Accuracy: 100.00%\nEpoch 1829/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.05it/s, loss=0.4447, acc=100.00%]\n\nEpoch 1829/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 1830/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.43it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1830/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1831/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.77it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1831/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1832/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.74it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1832/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1833/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.43it/s, loss=0.4578, acc=100.00%]\n\nEpoch 1833/2000 Summary:\nTraining Loss: 0.4578, Accuracy: 100.00%\nEpoch 1834/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.24it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1834/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1835/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.62it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1835/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1836/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1836/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1837/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.79it/s, loss=0.4442, acc=100.00%]\n\nEpoch 1837/2000 Summary:\nTraining Loss: 0.4442, Accuracy: 100.00%\nEpoch 1838/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.55it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1838/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1839/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.01it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1839/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1840/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.30it/s, loss=0.4448, acc=100.00%]\n\nEpoch 1840/2000 Summary:\nTraining Loss: 0.4448, Accuracy: 100.00%\nEpoch 1841/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.84it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1841/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1842/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1842/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1843/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4600, acc=100.00%]\n\nEpoch 1843/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 1844/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4577, acc=100.00%]\n\nEpoch 1844/2000 Summary:\nTraining Loss: 0.4577, Accuracy: 100.00%\nEpoch 1845/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4439, acc=100.00%]\n\nEpoch 1845/2000 Summary:\nTraining Loss: 0.4439, Accuracy: 100.00%\nEpoch 1846/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.13it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1846/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1847/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.66it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1847/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1848/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.57it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1848/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1849/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.81it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1849/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1850/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1850/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1851/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.94it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1851/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1852/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.16it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1852/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1853/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.58it/s, loss=0.4579, acc=100.00%]\n\nEpoch 1853/2000 Summary:\nTraining Loss: 0.4579, Accuracy: 100.00%\nEpoch 1854/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.83it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1854/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1855/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1855/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1856/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1856/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1857/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.73it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1857/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1858/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.76it/s, loss=0.4578, acc=100.00%]\n\nEpoch 1858/2000 Summary:\nTraining Loss: 0.4578, Accuracy: 100.00%\nEpoch 1859/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.50it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1859/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1860/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1860/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1861/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.77it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1861/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1862/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.94it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1862/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1863/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.87it/s, loss=0.4575, acc=100.00%]\n\nEpoch 1863/2000 Summary:\nTraining Loss: 0.4575, Accuracy: 100.00%\nEpoch 1864/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.44it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1864/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1865/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.89it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1865/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1866/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.76it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1866/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1867/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.66it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1867/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1868/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.52it/s, loss=0.4569, acc=100.00%]\n\nEpoch 1868/2000 Summary:\nTraining Loss: 0.4569, Accuracy: 100.00%\nEpoch 1869/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4574, acc=100.00%]\n\nEpoch 1869/2000 Summary:\nTraining Loss: 0.4574, Accuracy: 100.00%\nEpoch 1870/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.04it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1870/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1871/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1871/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1872/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.40it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1872/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1873/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.08it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1873/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1874/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1874/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1875/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.16it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1875/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1876/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.46it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1876/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1877/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4591, acc=100.00%]\n\nEpoch 1877/2000 Summary:\nTraining Loss: 0.4591, Accuracy: 100.00%\nEpoch 1878/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1878/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1879/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.67it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1879/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1880/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=0.4579, acc=100.00%]\n\nEpoch 1880/2000 Summary:\nTraining Loss: 0.4579, Accuracy: 100.00%\nEpoch 1881/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1881/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1882/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.20it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1882/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1883/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.98it/s, loss=0.4578, acc=100.00%]\n\nEpoch 1883/2000 Summary:\nTraining Loss: 0.4578, Accuracy: 100.00%\nEpoch 1884/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.57it/s, loss=0.4568, acc=100.00%]\n\nEpoch 1884/2000 Summary:\nTraining Loss: 0.4568, Accuracy: 100.00%\nEpoch 1885/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.23it/s, loss=0.4574, acc=100.00%]\n\nEpoch 1885/2000 Summary:\nTraining Loss: 0.4574, Accuracy: 100.00%\nEpoch 1886/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.70it/s, loss=0.4445, acc=100.00%]\n\nEpoch 1886/2000 Summary:\nTraining Loss: 0.4445, Accuracy: 100.00%\nEpoch 1887/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.17it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1887/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1888/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.45it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1888/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1889/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.31it/s, loss=0.4576, acc=100.00%]\n\nEpoch 1889/2000 Summary:\nTraining Loss: 0.4576, Accuracy: 100.00%\nEpoch 1890/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.13it/s, loss=0.4576, acc=100.00%]\n\nEpoch 1890/2000 Summary:\nTraining Loss: 0.4576, Accuracy: 100.00%\nEpoch 1891/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.64it/s, loss=0.4599, acc=100.00%]\n\nEpoch 1891/2000 Summary:\nTraining Loss: 0.4599, Accuracy: 100.00%\nEpoch 1892/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.12it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1892/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1893/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.74it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1893/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1894/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.21it/s, loss=0.4450, acc=100.00%]\n\nEpoch 1894/2000 Summary:\nTraining Loss: 0.4450, Accuracy: 100.00%\nEpoch 1895/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.13it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1895/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1896/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.71it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1896/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1897/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.4449, acc=100.00%]\n\nEpoch 1897/2000 Summary:\nTraining Loss: 0.4449, Accuracy: 100.00%\nEpoch 1898/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.57it/s, loss=0.4589, acc=100.00%]\n\nEpoch 1898/2000 Summary:\nTraining Loss: 0.4589, Accuracy: 100.00%\nEpoch 1899/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1899/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1900/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.49it/s, loss=0.4449, acc=100.00%]\n\nEpoch 1900/2000 Summary:\nTraining Loss: 0.4449, Accuracy: 100.00%\nEpoch 1901/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.15it/s, loss=0.4448, acc=100.00%]\n\nEpoch 1901/2000 Summary:\nTraining Loss: 0.4448, Accuracy: 100.00%\nEpoch 1902/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4577, acc=100.00%]\n\nEpoch 1902/2000 Summary:\nTraining Loss: 0.4577, Accuracy: 100.00%\nEpoch 1903/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.76it/s, loss=0.4577, acc=100.00%]\n\nEpoch 1903/2000 Summary:\nTraining Loss: 0.4577, Accuracy: 100.00%\nEpoch 1904/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.02it/s, loss=0.4571, acc=100.00%]\n\nEpoch 1904/2000 Summary:\nTraining Loss: 0.4571, Accuracy: 100.00%\nEpoch 1905/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.96it/s, loss=0.4574, acc=100.00%]\n\nEpoch 1905/2000 Summary:\nTraining Loss: 0.4574, Accuracy: 100.00%\nEpoch 1906/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1906/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1907/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1907/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1908/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.78it/s, loss=0.4574, acc=100.00%]\n\nEpoch 1908/2000 Summary:\nTraining Loss: 0.4574, Accuracy: 100.00%\nEpoch 1909/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.93it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1909/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1910/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.33it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1910/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1911/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.55it/s, loss=0.4617, acc=99.63%] \n\nEpoch 1911/2000 Summary:\nTraining Loss: 0.4617, Accuracy: 99.63%\nEpoch 1912/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.76it/s, loss=0.4834, acc=98.70%]\n\nEpoch 1912/2000 Summary:\nTraining Loss: 0.4834, Accuracy: 98.70%\nEpoch 1913/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.39it/s, loss=0.4974, acc=97.59%]\n\nEpoch 1913/2000 Summary:\nTraining Loss: 0.4974, Accuracy: 97.59%\nEpoch 1914/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4716, acc=99.26%]\n\nEpoch 1914/2000 Summary:\nTraining Loss: 0.4716, Accuracy: 99.26%\nEpoch 1915/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.4662, acc=99.81%]\n\nEpoch 1915/2000 Summary:\nTraining Loss: 0.4662, Accuracy: 99.81%\nEpoch 1916/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.90it/s, loss=0.4612, acc=100.00%]\n\nEpoch 1916/2000 Summary:\nTraining Loss: 0.4612, Accuracy: 100.00%\nEpoch 1917/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.64it/s, loss=0.4614, acc=99.81%] \n\nEpoch 1917/2000 Summary:\nTraining Loss: 0.4614, Accuracy: 99.81%\nEpoch 1918/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.51it/s, loss=0.4626, acc=99.81%] \n\nEpoch 1918/2000 Summary:\nTraining Loss: 0.4626, Accuracy: 99.81%\nEpoch 1919/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.09it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1919/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1920/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.87it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1920/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1921/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.72it/s, loss=0.4600, acc=100.00%]\n\nEpoch 1921/2000 Summary:\nTraining Loss: 0.4600, Accuracy: 100.00%\nEpoch 1922/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.29it/s, loss=0.4578, acc=100.00%]\n\nEpoch 1922/2000 Summary:\nTraining Loss: 0.4578, Accuracy: 100.00%\nEpoch 1923/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.47it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1923/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1924/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.28it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1924/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1925/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.57it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1925/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1926/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.80it/s, loss=0.4607, acc=99.81%] \n\nEpoch 1926/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 99.81%\nEpoch 1927/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.00it/s, loss=0.4614, acc=99.81%] \n\nEpoch 1927/2000 Summary:\nTraining Loss: 0.4614, Accuracy: 99.81%\nEpoch 1928/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.69it/s, loss=0.4474, acc=100.00%]\n\nEpoch 1928/2000 Summary:\nTraining Loss: 0.4474, Accuracy: 100.00%\nEpoch 1929/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.27it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1929/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1930/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.25it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1930/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1931/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.06it/s, loss=0.4607, acc=99.81%] \n\nEpoch 1931/2000 Summary:\nTraining Loss: 0.4607, Accuracy: 99.81%\nEpoch 1932/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.92it/s, loss=0.4469, acc=99.81%]\n\nEpoch 1932/2000 Summary:\nTraining Loss: 0.4469, Accuracy: 99.81%\nEpoch 1933/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.05it/s, loss=0.4598, acc=100.00%]\n\nEpoch 1933/2000 Summary:\nTraining Loss: 0.4598, Accuracy: 100.00%\nEpoch 1934/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1934/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1935/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.50it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1935/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1936/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.62it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1936/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1937/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.76it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1937/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1938/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.31it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1938/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1939/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.65it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1939/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1940/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.55it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1940/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1941/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.24it/s, loss=0.4590, acc=99.26%]\n\nEpoch 1941/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 99.26%\nEpoch 1942/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.27it/s, loss=0.4645, acc=99.44%]\n\nEpoch 1942/2000 Summary:\nTraining Loss: 0.4645, Accuracy: 99.44%\nEpoch 1943/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.03it/s, loss=0.4661, acc=99.63%]\n\nEpoch 1943/2000 Summary:\nTraining Loss: 0.4661, Accuracy: 99.63%\nEpoch 1944/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.78it/s, loss=0.4643, acc=99.63%]\n\nEpoch 1944/2000 Summary:\nTraining Loss: 0.4643, Accuracy: 99.63%\nEpoch 1945/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.50it/s, loss=0.4628, acc=99.81%] \n\nEpoch 1945/2000 Summary:\nTraining Loss: 0.4628, Accuracy: 99.81%\nEpoch 1946/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.46it/s, loss=0.4651, acc=99.44%]\n\nEpoch 1946/2000 Summary:\nTraining Loss: 0.4651, Accuracy: 99.44%\nEpoch 1947/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.14it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1947/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1948/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4608, acc=99.81%] \n\nEpoch 1948/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 99.81%\nEpoch 1949/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4608, acc=99.81%] \n\nEpoch 1949/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 99.81%\nEpoch 1950/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.03it/s, loss=0.4608, acc=100.00%]\n\nEpoch 1950/2000 Summary:\nTraining Loss: 0.4608, Accuracy: 100.00%\nEpoch 1951/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.05it/s, loss=0.4620, acc=99.81%] \n\nEpoch 1951/2000 Summary:\nTraining Loss: 0.4620, Accuracy: 99.81%\nEpoch 1952/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.44it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1952/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1953/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4580, acc=100.00%]\n\nEpoch 1953/2000 Summary:\nTraining Loss: 0.4580, Accuracy: 100.00%\nEpoch 1954/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.02it/s, loss=0.4586, acc=99.81%] \n\nEpoch 1954/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 99.81%\nEpoch 1955/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.90it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1955/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1956/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.88it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1956/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1957/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.84it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1957/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1958/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.93it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1958/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1959/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.46it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1959/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1960/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 45.80it/s, loss=0.4595, acc=100.00%]\n\nEpoch 1960/2000 Summary:\nTraining Loss: 0.4595, Accuracy: 100.00%\nEpoch 1961/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.10it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1961/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1962/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.50it/s, loss=0.4624, acc=99.63%]\n\nEpoch 1962/2000 Summary:\nTraining Loss: 0.4624, Accuracy: 99.63%\nEpoch 1963/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.13it/s, loss=0.4641, acc=99.63%]\n\nEpoch 1963/2000 Summary:\nTraining Loss: 0.4641, Accuracy: 99.63%\nEpoch 1964/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.74it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1964/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1965/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.04it/s, loss=0.4593, acc=100.00%]\n\nEpoch 1965/2000 Summary:\nTraining Loss: 0.4593, Accuracy: 100.00%\nEpoch 1966/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.62it/s, loss=0.4596, acc=100.00%]\n\nEpoch 1966/2000 Summary:\nTraining Loss: 0.4596, Accuracy: 100.00%\nEpoch 1967/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.53it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1967/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1968/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.56it/s, loss=0.4579, acc=100.00%]\n\nEpoch 1968/2000 Summary:\nTraining Loss: 0.4579, Accuracy: 100.00%\nEpoch 1969/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=0.4602, acc=100.00%]\n\nEpoch 1969/2000 Summary:\nTraining Loss: 0.4602, Accuracy: 100.00%\nEpoch 1970/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.41it/s, loss=0.4585, acc=100.00%]\n\nEpoch 1970/2000 Summary:\nTraining Loss: 0.4585, Accuracy: 100.00%\nEpoch 1971/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.18it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1971/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1972/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.60it/s, loss=0.4581, acc=100.00%]\n\nEpoch 1972/2000 Summary:\nTraining Loss: 0.4581, Accuracy: 100.00%\nEpoch 1973/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.07it/s, loss=0.4453, acc=100.00%]\n\nEpoch 1973/2000 Summary:\nTraining Loss: 0.4453, Accuracy: 100.00%\nEpoch 1974/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.98it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1974/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1975/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.18it/s, loss=0.4575, acc=100.00%]\n\nEpoch 1975/2000 Summary:\nTraining Loss: 0.4575, Accuracy: 100.00%\nEpoch 1976/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.26it/s, loss=0.4442, acc=100.00%]\n\nEpoch 1976/2000 Summary:\nTraining Loss: 0.4442, Accuracy: 100.00%\nEpoch 1977/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.22it/s, loss=0.4576, acc=100.00%]\n\nEpoch 1977/2000 Summary:\nTraining Loss: 0.4576, Accuracy: 100.00%\nEpoch 1978/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.55it/s, loss=0.4579, acc=100.00%]\n\nEpoch 1978/2000 Summary:\nTraining Loss: 0.4579, Accuracy: 100.00%\nEpoch 1979/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.34it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1979/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1980/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.47it/s, loss=0.4434, acc=100.00%]\n\nEpoch 1980/2000 Summary:\nTraining Loss: 0.4434, Accuracy: 100.00%\nEpoch 1981/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.51it/s, loss=0.4590, acc=100.00%]\n\nEpoch 1981/2000 Summary:\nTraining Loss: 0.4590, Accuracy: 100.00%\nEpoch 1982/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.23it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1982/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1983/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.16it/s, loss=0.4583, acc=100.00%]\n\nEpoch 1983/2000 Summary:\nTraining Loss: 0.4583, Accuracy: 100.00%\nEpoch 1984/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.05it/s, loss=0.4574, acc=100.00%]\n\nEpoch 1984/2000 Summary:\nTraining Loss: 0.4574, Accuracy: 100.00%\nEpoch 1985/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.91it/s, loss=0.4447, acc=100.00%]\n\nEpoch 1985/2000 Summary:\nTraining Loss: 0.4447, Accuracy: 100.00%\nEpoch 1986/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.63it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1986/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1987/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.01it/s, loss=0.4592, acc=100.00%]\n\nEpoch 1987/2000 Summary:\nTraining Loss: 0.4592, Accuracy: 100.00%\nEpoch 1988/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4655, acc=99.44%] \n\nEpoch 1988/2000 Summary:\nTraining Loss: 0.4655, Accuracy: 99.44%\nEpoch 1989/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.71it/s, loss=0.4601, acc=100.00%]\n\nEpoch 1989/2000 Summary:\nTraining Loss: 0.4601, Accuracy: 100.00%\nEpoch 1990/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 48.00it/s, loss=0.4594, acc=100.00%]\n\nEpoch 1990/2000 Summary:\nTraining Loss: 0.4594, Accuracy: 100.00%\nEpoch 1991/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.32it/s, loss=0.4587, acc=100.00%]\n\nEpoch 1991/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nEpoch 1992/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.01it/s, loss=0.4574, acc=100.00%]\n\nEpoch 1992/2000 Summary:\nTraining Loss: 0.4574, Accuracy: 100.00%\nEpoch 1993/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.68it/s, loss=0.4584, acc=100.00%]\n\nEpoch 1993/2000 Summary:\nTraining Loss: 0.4584, Accuracy: 100.00%\nEpoch 1994/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.42it/s, loss=0.4586, acc=100.00%]\n\nEpoch 1994/2000 Summary:\nTraining Loss: 0.4586, Accuracy: 100.00%\nEpoch 1995/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.32it/s, loss=0.4579, acc=100.00%]\n\nEpoch 1995/2000 Summary:\nTraining Loss: 0.4579, Accuracy: 100.00%\nEpoch 1996/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 46.27it/s, loss=0.4575, acc=100.00%]\n\nEpoch 1996/2000 Summary:\nTraining Loss: 0.4575, Accuracy: 100.00%\nEpoch 1997/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.26it/s, loss=0.4588, acc=100.00%]\n\nEpoch 1997/2000 Summary:\nTraining Loss: 0.4588, Accuracy: 100.00%\nEpoch 1998/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.30it/s, loss=0.4582, acc=100.00%]\n\nEpoch 1998/2000 Summary:\nTraining Loss: 0.4582, Accuracy: 100.00%\nEpoch 1999/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4578, acc=100.00%]\n\nEpoch 1999/2000 Summary:\nTraining Loss: 0.4578, Accuracy: 100.00%\nEpoch 2000/2000 [Train]: 100%|██████████| 34/34 [00:00<00:00, 47.36it/s, loss=0.4587, acc=100.00%]\n\nEpoch 2000/2000 Summary:\nTraining Loss: 0.4587, Accuracy: 100.00%\nTest Accuracy: 64.91%\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1741303098756
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "start=time.time()\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        X_batch = batch['X']\n",
        "        y_batch = batch['y']\n",
        "\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move data to device\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "end = time.time()\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "print(\"Time per sample:\", (end-start)*1000/total)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Test Accuracy: 64.91%\nTime per sample: 0.831443330515986\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1741303178509
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        X_batch = batch['X']\n",
        "        y_batch = batch['y']\n",
        "\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move data to device\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())  # Collect predictions\n",
        "        all_labels.extend(y_batch.cpu().numpy())  # Collect true labels\n",
        "\n",
        "# Calculate precision, recall, F1 score (macro averaged), and accuracy\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro', zero_division=0)\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy * 100}\")\n",
        "print(f\"Test Precision (Macro): {precision}\")\n",
        "print(f\"Test Recall (Macro): {recall}\")\n",
        "print(f\"Test F1 Score (Macro): {f1}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Test Accuracy: 64.90683229813664\nTest Precision (Macro): 0.6718821948096114\nTest Recall (Macro): 0.6498316498316499\nTest F1 Score (Macro): 0.6395877784159046\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1741303183935
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract values from history\n",
        "train_loss = history[\"train_loss\"]\n",
        "#val_loss = history[\"val_loss\"]\n",
        "train_acc = history[\"train_acc\"]\n",
        "#val_acc = history[\"val_acc\"]\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot Loss Curve\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss, 'b-', label=\"Train Loss\")\n",
        "#plt.plot(epochs, val_loss, 'r-', label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# Plot Accuracy Curve\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_acc, 'b-',label=\"Train Accuracy\")\n",
        "#plt.plot(epochs, val_acc, 'r-', label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x500 with 2 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAHWCAYAAAALjsguAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAACVaklEQVR4nOzdd3wT9f8H8FfapnvTDYWWvZFZKkOEQhlWpsyvgCiIgD+wuBDZKIiCCDIcDAdLkaUCUhkiyoYyZChLZsss3W3a3O+PM6tJ21yb9JL29Xw8+rjL5e7yzrtpL+/7fO5zCkEQBBARERERERGR7BzkDoCIiIiIiIiIRCzSiYiIiIiIiGwEi3QiIiIiIiIiG8EinYiIiIiIiMhGsEgnIiIiIiIishEs0omIiIiIiIhsBIt0IiIiIiIiIhvBIp2IiIiIiIjIRrBIJyIiIiIiIrIRLNKJiIiIiIiIbASLdCIbsnr1aigUChw7dkzuUMySmJiI//3vfwgPD4eLiwv8/f0RExODVatWIT8/X+7wiIiILG7p0qVQKBSIioqSOxS7lJycjNdffx1169aFu7s7PDw80Lx5c8yePRspKSlyh0dkE5zkDoCI7NOXX36J0aNHIzg4GM8//zxq1aqFtLQ07N69Gy+++CLu3LmDd955R+4wiYiILGrNmjWIiIjAkSNHcOnSJdSsWVPukOzG0aNH0b17d6Snp+N///sfmjdvDgA4duwY5s6di/3792PXrl0yR0kkPxbpRCTZoUOHMHr0aERHR2P79u3w8vLSPjdhwgQcO3YMZ8+etchrZWRkwMPDwyL7IiIiKo2rV6/izz//xKZNm/Dyyy9jzZo1mDZtmtxhmWRrx8+UlBT07t0bjo6OOHnyJOrWrWvw/HvvvYcvvvjCIq9la++dSCp2dyeyQydPnkS3bt3g7e0NT09PdOrUCYcOHTJYR6VSYcaMGahVqxZcXV1RqVIltG3bFgkJCdp1kpKS8MILL6BKlSpwcXFBaGgoevbsiWvXrhX5+jNmzIBCocCaNWsMCnSNFi1aYPjw4QCAffv2QaFQYN++fQbrXLt2DQqFAqtXr9YuGz58ODw9PXH58mV0794dXl5eGDJkCMaNGwdPT09kZmYavdagQYMQEhJi0L1+x44daNeuHTw8PODl5YUePXrgr7/+KvI9ERERFWfNmjXw8/NDjx490K9fP6xZs8bkeikpKXjttdcQEREBFxcXVKlSBUOHDsX9+/e162RnZ2P69OmoXbs2XF1dERoaij59+uDy5csALHP8BIDff/8dzz33HKpWrQoXFxeEh4fjtddeQ1ZWllHcFy5cQP/+/REYGAg3NzfUqVMHkydPBgDs3bsXCoUCmzdvNtpu7dq1UCgUOHjwYKG5++yzz3Dr1i0sWLDAqEAHgODgYLz77rvaxwqFAtOnTzdaLyIiQvsdA9BdKvjbb79hzJgxCAoKQpUqVbBx40btclOxKBQKgwaFCxcuoF+/fvD394erqytatGiBbdu2Ffp+iKyJLelEduavv/5Cu3bt4O3tjTfffBNKpRKfffYZOnTogN9++017jdz06dMxZ84cvPTSS2jVqhVSU1Nx7NgxnDhxAp07dwYA9O3bF3/99RdeffVVRERE4O7du0hISMD169cRERFh8vUzMzOxe/dutG/fHlWrVrX4+8vLy0NsbCzatm2Ljz76CO7u7oiIiMCSJUvw888/47nnnjOI5ccff8Tw4cPh6OgIAPjmm28wbNgwxMbG4oMPPkBmZiaWLVuGtm3b4uTJk4W+LyIiouKsWbMGffr0gbOzMwYNGoRly5bh6NGjaNmypXad9PR0tGvXDufPn8eIESPQrFkz3L9/H9u2bcPNmzcREBCA/Px8PPPMM9i9ezcGDhyI8ePHIy0tDQkJCTh79ixq1KghOTZTx08A+P7775GZmYlXXnkFlSpVwpEjR7B48WLcvHkT33//vXb706dPo127dlAqlRg1ahQiIiJw+fJl/Pjjj3jvvffQoUMHhIeHY82aNejdu7dRXmrUqIHo6OhC49u2bRvc3NzQr18/ye/NHGPGjEFgYCCmTp2KjIwM9OjRA56envjuu+/w1FNPGay7YcMGNGjQAA0bNgQgfrdq06YNKleujLfffhseHh747rvv0KtXL/zwww9G75fI6gQishmrVq0SAAhHjx4tdJ1evXoJzs7OwuXLl7XLbt++LXh5eQnt27fXLmvSpInQo0ePQvfz6NEjAYDw4YcfSorx1KlTAgBh/PjxZq2/d+9eAYCwd+9eg+VXr14VAAirVq3SLhs2bJgAQHj77bcN1lWr1ULlypWFvn37Giz/7rvvBADC/v37BUEQhLS0NMHX11cYOXKkwXpJSUmCj4+P0XIiIiJzHTt2TAAgJCQkCIIgHpuqVKlidDycOnWqAEDYtGmT0T7UarUgCIKwcuVKAYCwYMGCQtexxPFTEAQhMzPTaNmcOXMEhUIh/Pvvv9pl7du3F7y8vAyW6ccjCIIwadIkwcXFRUhJSdEuu3v3ruDk5CRMmzbN6HX0+fn5CU2aNClyHX0ATO6zWrVqwrBhw7SPNd+d2rZtK+Tl5RmsO2jQICEoKMhg+Z07dwQHBwdh5syZ2mWdOnUSGjVqJGRnZ2uXqdVq4cknnxRq1apldsxElsLu7kR2JD8/H7t27UKvXr1QvXp17fLQ0FAMHjwYBw4cQGpqKgDA19cXf/31F/755x+T+3Jzc4OzszP27duHR48emR2DZv+murlbyiuvvGLwWKFQ4LnnnsP27duRnp6uXb5hwwZUrlwZbdu2BQAkJCQgJSUFgwYNwv3797U/jo6OiIqKwt69e60WMxERlW9r1qxBcHAwnn76aQDisWnAgAFYv369wSVXP/zwA5o0aWKy9VWhUGjXCQgIwKuvvlroOiVR8PgJiMd7jYyMDNy/fx9PPvkkBEHAyZMnAQD37t3D/v37MWLECKNecvrxDB06FDk5Odi4caN22YYNG5CXl4f//e9/RcaWmppq1e8OI0eO1Paq0xgwYADu3r1rcMnAxo0boVarMWDAAADAw4cPsWfPHvTv3x9paWna7w4PHjxAbGws/vnnH9y6dctqcROZwiKdyI7cu3cPmZmZqFOnjtFz9erVg1qtxo0bNwAAM2fOREpKCmrXro1GjRrhjTfewOnTp7Xru7i44IMPPsCOHTsQHByM9u3bY968eUhKSioyBm9vbwBAWlqaBd+ZjpOTE6pUqWK0fMCAAcjKytJeH5aeno7t27fjueee036B0JyQ6NixIwIDAw1+du3ahbt371olZiIiKt/y8/Oxfv16PP3007h69SouXbqES5cuISoqCsnJydi9e7d23cuXL2u7URfm8uXLqFOnDpycLHflaWHHz+vXr2P48OHw9/eHp6cnAgMDtd2/Hz9+DAC4cuUKABQbd926ddGyZUuDa/HXrFmD1q1bFzvKvbe3t9W+OwBAZGSk0bKuXbvCx8cHGzZs0C7bsGEDnnjiCdSuXRsAcOnSJQiCgClTphh9d9AMCsjvD1TWeE06UTnVvn17XL58GVu3bsWuXbvw5Zdf4uOPP8by5cvx0ksvARBHYo+Li8OWLVvwyy+/YMqUKZgzZw727NmDpk2bmtxvzZo14eTkhDNnzpgVR2EtAoXdR93FxQUODsbnD1u3bo2IiAh89913GDx4MH788UdkZWVpz4QDgFqtBiBelx4SEmK0D0t+GSIioopjz549uHPnDtavX4/169cbPb9mzRp06dLFoq9pieNnfn4+OnfujIcPH+Ktt95C3bp14eHhgVu3bmH48OHa46YUQ4cOxfjx43Hz5k3k5OTg0KFD+PTTT4vdrm7dukhMTERubi6cnZ0lv65GYe9fv8eAhouLC3r16oXNmzdj6dKlSE5Oxh9//IH3339fu44mB6+//jpiY2NN7pu32aOyxm+sRHYkMDAQ7u7uuHjxotFzFy5cgIODA8LDw7XL/P398cILL+CFF15Aeno62rdvj+nTp2uLdACoUaMGJk6ciIkTJ+Kff/7BE088gfnz5+Pbb781GYO7uzs6duyIPXv24MaNGwavZ4qfnx8AcaRbff/++6+5b1urf//++OSTT5CamooNGzYgIiICrVu3NngvABAUFISYmBjJ+yciIjJlzZo1CAoKwpIlS4ye27RpEzZv3ozly5fDzc0NNWrUKPY2pDVq1MDhw4ehUqmgVCpNrmOJ4+eZM2fw999/46uvvsLQoUO1y/Xv9AJAewmdObdPHThwIOLj47Fu3TpkZWVBqVQanDAvTFxcHA4ePIgffvgBgwYNKnZ9Pz8/o/eem5uLO3fuFLutvgEDBuCrr77C7t27cf78eQiCYBCv5r0rlUp+dyCbwe7uRHbE0dERXbp0wdatWw1uk5acnIy1a9eibdu22u7oDx48MNjW09MTNWvWRE5ODgBxZPTs7GyDdWrUqAEvLy/tOoWZNm0aBEHA888/b3CNuMbx48fx1VdfAQCqVasGR0dH7N+/32CdpUuXmvem9QwYMAA5OTn46quvsHPnTvTv39/g+djYWHh7e+P999+HSqUy2v7evXuSX5OIiCq2rKwsbNq0Cc888wz69etn9DNu3DikpaVpL8fq27cvTp06ZfJWZYIgaNe5f/++yRZozTqWOH5qrtHW7FMz/8knnxisFxgYiPbt22PlypW4fv26yXg0AgIC0K1bN3z77bdYs2YNunbtioCAgGJjGT16NEJDQzFx4kT8/fffRs/fvXsXs2fP1j6uUaOG0Xv//PPPC21JL0xMTAz8/f2xYcMGbNiwAa1atTLoGh8UFIQOHTrgs88+M3kCgN8dSA5sSSeyQStXrsTOnTuNlo8fPx6zZ89GQkIC2rZtizFjxsDJyQmfffYZcnJyMG/ePO269evXR4cOHdC8eXP4+/vj2LFj2LhxI8aNGwcA+Pvvv9GpUyf0798f9evXh5OTEzZv3ozk5GQMHDiwyPiefPJJLFmyBGPGjEHdunXx/PPPo1atWkhLS8O+ffuwbds27YHWx8cHzz33HBYvXgyFQoEaNWrgp59+KtH1Xc2aNUPNmjUxefJk5OTkGJ259/b2xrJly/D888+jWbNmGDhwIAIDA3H9+nX8/PPPaNOmjVld8oiIiDS2bduGtLQ0PPvssyafb926NQIDA7FmzRoMGDAAb7zxBjZu3IjnnnsOI0aMQPPmzfHw4UNs27YNy5cvR5MmTTB06FB8/fXXiI+Px5EjR9CuXTtkZGTg119/xZgxY9CzZ0+LHD/r1q2LGjVq4PXXX8etW7fg7e2NH374weSAsYsWLULbtm3RrFkzjBo1CpGRkbh27Rp+/vlnJCYmGqw7dOhQ7a3UZs2aZVYsfn5+2Lx5M7p3744nnngC//vf/9C8eXMAwIkTJ7Bu3TqDW7i99NJLGD16NPr27YvOnTvj1KlT+OWXX8w6IaBPqVSiT58+WL9+PTIyMvDRRx8ZrbNkyRK0bdsWjRo1wsiRI1G9enUkJyfj4MGDuHnzJk6dOiXpNYlKTbZx5YnIiOY2IoX93LhxQxAEQThx4oQQGxsreHp6Cu7u7sLTTz8t/Pnnnwb7mj17ttCqVSvB19dXcHNzE+rWrSu89957Qm5uriAIgnD//n1h7NixQt26dQUPDw/Bx8dHiIqKEr777juz4z1+/LgwePBgISwsTFAqlYKfn5/QqVMn4auvvhLy8/O16927d0/o27ev4O7uLvj5+Qkvv/yycPbsWZO3kPHw8CjyNSdPniwAEGrWrFnoOnv37hViY2MFHx8fwdXVVahRo4YwfPhw4dixY2a/NyIiIkEQhLi4OMHV1VXIyMgodJ3hw4cLSqVSuH//viAIgvDgwQNh3LhxQuXKlQVnZ2ehSpUqwrBhw7TPC4J4a7TJkycLkZGRglKpFEJCQoR+/foZ3GLVEsfPc+fOCTExMYKnp6cQEBAgjBw5Uns7Vf19CIIgnD17Vujdu7fg6+sruLq6CnXq1BGmTJlitM+cnBzBz89P8PHxEbKyssxJo9bt27eF1157Tahdu7bg6uoquLu7C82bNxfee+894fHjx9r18vPzhbfeeksICAgQ3N3dhdjYWOHSpUuF3oKtqNvXJiQkCAAEhUKh/S5V0OXLl4WhQ4cKISEhglKpFCpXriw888wzwsaNGyW9PyJLUAhCgT4sREREREREhcjLy0NYWBji4uKwYsUKucMhKnd4TToREREREZlty5YtuHfvnsFgdERkOWxJJyIiIiKiYh0+fBinT5/GrFmzEBAQgBMnTsgdElG5xJZ0IiIiIiIq1rJly/DKK68gKCgIX3/9tdzhEJVbbEknIiIiIiIishFsSSciIiIiIiKyESzSiYiIiIiIiGyEk9wBlDW1Wo3bt2/Dy8sLCoVC7nCIiIggCALS0tIQFhYGBweeP7cEHu+JiMiWSDnWV7gi/fbt2wgPD5c7DCIiIiM3btxAlSpV5A6jXODxnoiIbJE5x/oKV6R7eXkBEJPj7e1dqn2pVCrs2rULXbp0gVKptER45R5zJh1zJh1zJh1zJp0lc5aamorw8HDtMYpKj8d7eTFn0jFn0jBf0jFn0sl1rK9wRbqmy5u3t7dFDtru7u7w9vbmB91MzJl0zJl0zJl0zJl01sgZu2VbDo/38mLOpGPOpGG+pGPOpJPrWM8L34iIiIiIiIhsBIt0IiIiIiIiIhvBIp2IiIiIiIjIRlS4a9KJiOyFIAjIy8tDfn6+1V9LpVLByckJ2dnZZfJ65YGUnDk6OsLJyYnXnBMREVGxWKQTEdmg3Nxc3LlzB5mZmWXyeoIgICQkBDdu3GAhaSapOXN3d0doaCicnZ3LIDoiIiKyVyzSiYhsjFqtxtWrV+Ho6IiwsDA4OztbvXBWq9VIT0+Hp6cnHBx4JZQ5zM2ZIAjIzc3FvXv3cPXqVdSqVYs5JiIiokKxSCcisjG5ublQq9UIDw+Hu7t7mbymWq1Gbm4uXF1dWUCaSUrO3NzcoFQq8e+//2q3ISIiIjKF38SIiGwUi+Xyhb9PIiIiMge/MRARERERERHZCBbpRERERERERDaCRToREdm0iIgILFy4UO4wyEz79+9HXFwcwsLCoFAosGXLFoPnBUHA1KlTERoaCjc3N8TExOCff/4xWOfhw4cYMmQIvL294evrixdffBHp6ell+C6IiIjkI2uRXtyB3JQ1a9agSZMm2lvZjBgxAg8ePLB+sEREVCSFQlHkz/Tp00u036NHj2LUqFGliq1Dhw6YMGFCqfZB5snIyECTJk2wZMkSk8/PmzcPixYtwvLly3H48GF4eHggNjYW2dnZ2nWGDBmCv/76CwkJCfjpp5+wf//+Un8GiIiI7IWso7trDuQjRoxAnz59il3/jz/+wNChQ/Hxxx8jLi4Ot27dwujRozFy5Ehs2rSpDCImIqLC3LlzRzu/YcMGTJ06FRcvXtQu8/T01M4LgoD8/Hw4ORV/GAoMDLRsoGRV3bp1Q7du3Uw+JwgCFi5ciHfffRc9e/YEAHz99dcIDg7Gli1bMHDgQJw/fx47d+7E0aNH0aJFCwDA4sWL0b17d3z00UcICwsrs/dCREQkB1mL9KIO5KYcPHgQERER+L//+z8AQGRkJF5++WV88MEH1gqxWBs21MaWLY5YuRKw8m2MiagCEwQgM9N6+1ergYwMwNER0B+E3N3d/P9tISEh2nkfHx8oFArtsn379uHpp5/G9u3b8e677+LMmTPYtWsXwsPDER8fj0OHDiEjIwP16tXDnDlzEBMTo91XREQEJkyYoG0JVygU+OKLL/Dzzz/jl19+QeXKlTF//nw8++yzJX7/P/zwA6ZOnYpLly4hNDQUr776KiZOnKh9funSpfj4449x48YN+Pj4oF27dvjuu+8AABs3bsSsWbNw6dIluLu7o2nTpti6dSs8PDxKHE95dfXqVSQlJRn8fn18fBAVFYWDBw9i4MCBOHjwIHx9fbUFOgDExMTAwcEBhw8fRu/evU3uOycnBzk5OdrHqampAACVSgWVSlWquDXbl3Y/lpaSIk7z84HQUGWp9+fpKSA9veg/+IYNBQDAhQtAXp5u3QYNBPz1l/62SgA9DbYx5eJFQKUyfs2aNQVcuqRAeLgAHx/j7c6eVSAsTIC/v/Fzbm4Cjh4V/5FVry7A1J0sz57VvWazZmrk5pr/JU6tBs6dU6B2bQHOzoWvl5sL/P23uF/9HOTnA+fPm3o9JapV64DJkx2hUIjr//03ULt20fHcvg1ERgrIySn5F1H9fBT1+wKAtDTg338VaNhQ0G6n2UYQoP0c1K0rwIzzsLhzB3jwQIGICAF653KLJQiOSE83zFdBmvgaNBAs8j3d0RGoVUvAlSsw6zOjn1dNDAVzJoW5v6ezZxXavyH99y4Ijnj8uCNu3tT9vzAnDs3rurkJyMoyHb9+bAXVqSNAWcp/UZq/p+Let76S5LggzecsMDAPLVuWbl9SjiF2dZ/06OhovPPOO9i+fTu6deuGu3fvYuPGjejevXuh21jzoJ2bq8K6dfUAAC+/nIfmzUv/QSjvbPWLji1jzqSz95ypVCoIggC1Wg21Wg1ALKC9va15hZIDAF+jpampapSk1tTEXXD69ttvY968eahevTr8/Pxw48YNdO3aFbNmzYKLiwu++eYbxMXF4fz586hatap2f5p8aMyYMQNz587FBx98gE8//RRDhgzB1atX4W/qG3sh+9A4fvw4+vfvj2nTpqF///74888/MW7cOPj5+WH48OE4duwY/u///g9fffUVnnzySTx8+BAHDhyAIAhISkrCkCFD8MEHH6BXr15IS0vDgQMHkJ+fb/RaarUagiBApVLB0dHR4Dl7/axKlZSUBAAIDg42WB4cHKx9LikpCUFBQQbPOzk5wd/fX7uOKXPmzMGMGTOMlu/atQvupqq0EkhISLDIfkojPx/Yu7cqPv20qcX3XVyBDhT+RdywQDdvm6JcuiRuc+OGAjdumF7n9m0Fbt829Yzu9a5cKf61T5wo2f9WTQFuDnNz8O+/xmckzp4tfruHDy3XUmRurPrrmdrmwgVpMV27JvU9KACYOINjQlGfT6lOnSrZvgrGUJK/Cynba/6GDF9XAcCrxHFoCnSp2128WPafT6nrFk78nO3f/zvu3XtYqj1lSmhtsasivU2bNlizZg0GDBiA7Oxs5OXlIS4urtDr3gDrHrQPHAgDIJ5SWb/+NJKTCzmKkBFb+KJjb5gz6ew1Z05OTggJCUF6ejpyc3MBiEW6qSLa2lJTU5GfL3277OxsCIKgPTGqOTC99dZbiIqK0q4XGRmJyMhI7ePXX38dP/zwA7777jvtNchqtRrZ2dnafQHAwIED0aNHD+0+Fy9ejH379hm00OrLy8tDbm6uwT405s2bh6eeekrbS6tPnz5ITEzEhx9+iD59+uDixYtwd3dH+/bt4eXlBT8/P9SoUQNpaWlITk5GXl4eYmJi4O/vD39/f1SrVg1qtdrotXJzc5GVlYX9+/cjLy/P4DkpB24ybdKkSYiPj9c+Tk1NRXh4OLp06QJvb+9S7VulUiEhIQGdO3eGsrTNQRLk54t/+5cuAc8954SsLOD+fet02wsIEMza9/z5+ahfX0C3boZfIX/4IQ8vvuiIlBTjfUyenI+2bY0bMhISFFiwwNFoeUETJ+YjJka3vf5rv/ZaPrp00T333XcOWLVKV3TXrClg8WLjf2IF4x80SI2hQ41P4pmiv+2OHXnFrhMRIWDZsnyTzxU0Y8afaNasGZKTnfDSS9JeZ/TofPTsKb3BaNYsB/z5p5gzT08B339f+D/9nBygVy/j+DduzIOHBzBypCNu3hQ/A199lYcC59uKjL9+fQHz55t/wMnLy8OJEyfQrFkzo0unBAHo3l23bMmSfFSvXrrGtD//VGDWLN3nddq0fLRuXfg+09KA/v0N41IqBW3PkaVL86B3+CtW//6OSEvT/X3Fx+ejc2fj1zf1+dJ8fsTaydXkc4WZOdMBBw+Kn4/AQAGOjoCTE7BsWb62p0TB3ABA48YCatcW8McfCrz3Xj5CQ4t/j4X56y8FXn9dt39TMW/c6IAVKwxPuG3fnlfqHhSaz9nQoc0RGFi6//+mvoMUxq6K9HPnzmH8+PGYOnUqYmNjcefOHbzxxhsYPXo0VqxYYXIbax60d+/WzX/ySTN8+GGjUu2vIpDri449Y86ks/ecZWdn48aNG/D09ISrq3gw9fISW7WtRRAEpKWlwcvLCwq9I5q7u3eJDnCurq5QKBTa/7Oak6Lt2rUz+N+bnp6OGTNmYPv27bhz5w7y8vKQlZWFe/fuaddzcHCAq6urwXYtWrTQPvb29oa3tzfS09ML/b/u5OQEZ2dnk89fvnwZzz77rMFzTz/9NJYvXw4PDw88++yz+PDDD9GsWTPExsYiNjYWvXv3hpubGxo2bIiOHTuibdu26NKlCzp37ox+/frBz8/P6HWys7Ph5uaG9u3ba3+vGlIO3PZMc/lDcnIyQvW+sSUnJ+OJJ57QrnP37l2D7fLy8vDw4UODSyoKcnFxgYuLi9FypVJpsf8DltyXOdq3Bw4dKtm2q1cD//wDvPee4fLKlYGbN8X5uDjgp5+AF14AVq5U4Px5oHdvwM8P2LhRXLfg33/r1o548knDZYcPA61aOaFPH2DhQuC113TPLVuWh9GjTX/dbNcOWLBAnO/RA/j5Z9Pv5Y03HFGg84XWhx86Qr9jyrlzhs8fP66At3fxX3cHD3ZA167mtagHBAD374vzXbua3refH/DokTh/7JgClSoVHsMvvwBduojHru3b7yE21hFqtRNeekm3TmGvo69BA0d07WrWWzCwbh3w55/ifEqKAo6O0suDPn2coFAAS5YAPXsCzz0HDB0qbT9ii6/526hUAvLzxXwplYVvFxICjBlT/Mmg4hQ8YT1qlCOkDJFx9Cjwzz8KDB4sFrmvvCItP0uWAEOH6h7Pnetosgt5377ADz/oHm/apPv8qFQC3n33EGbPbg0AyMtDsb/vo0eBgwfF+dWrFdB1YNZt17w5MGuWbpvTp4FGjRTQ9WopXclZpw7w+uvi/PTppv8eqlQB9MvBpk2LPiFmLs3nLDCw9P//pWxvV0X6nDlz0KZNG7zxxhsAgMaNG8PDwwPt2rXD7NmzDQ74GtY8aNeta/jXao/FgFzK+otOecCcSWevOcvPz4dCoYCDgwMc9C4Q9/IqYqNSErvWA56eCoPXLCnNPgpOvby8DPb/5ptvIiEhAR999BFq1qwJNzc39OvXDyqVymA9TT40XFxcjJ7Xfx1TCu6jqOf04/bx8cGJEyewb98+7Nq1C9OnT8fMmTNx+PBhODo6YteuXTh06BB27dqFJUuWYMqUKTh8+LBBDwHNvhQKhcnPpT1+TksiMjISISEh2L17t7YoT01NxeHDh/HKK68AEC9tS0lJwfHjx9G8eXMAwJ49e6BWqw16YZR3mZnSCvQpU4AnnwTCw8VtW7QQr50ePFgcWyIzE8jKAmrW1G3zww/A1aviF2AAqFdPvNa8KJorSjZuFL8sr1sHNGyoe75vX8Mi/cUXC29p1O/Q+NFH4rXVJ0/qlg0YIL6Hgq2x69YBgwYBffoABa4cgf75r0GDgMLaY159FVi8WPc4IKDQMI3ExQGrVqHIAu2/TlAAYPK6eY033xQL9IL0/yWY++/BnOu/TdE/thTMp7k0J3OefRY4fx6oXr1k+7GG//7VlFrB30NhJ470OTiIn2FA/Jts3lyMR//v0FwFOmAV+rmYOBE4cUI84TZsGNCoQBti8+bJOH1ahTp1lGb9vpOTdfP6n2t9gYHA/v3iiUXA8r9//bEfCpzj1ip4eC/pZ9lW2FWRnpmZadSdRXNdnyCU/fXgoaG8Bp2IqDT++OMPDB8+XDsYWHp6Oq5du1amMdSrVw9//PGHUVy1a9fWHmOcnJwQExODmJgYTJs2Db6+vtizZw9iYmKgUCjQpk0btGnTBlOnTkW1atWwefNmg15cFUl6ejouXbqkfXz16lUkJibC398fVatWxYQJEzB79mzUqlULkZGRmDJlCsLCwtCrVy8A4u+ja9euGDlyJJYvXw6VSoVx48Zh4MCBFWZk9+xsSB4LYuZM42WOjkD9+oVv4+ysK9ALU6kSoLnT7WefAXXrivN9+4o/BZloFymUQgH8+KM4cFjdusDWrYDeUBRYv970dgMHij+maFqvAdM50fjwQ8MivVIl8+NesACIiBBPAhRGvERJVFRvpHffNb1cv+AYN67w7U+dApo0EedLWpSYU2zqGzoU+Ppr4OWXxdcuWJBpPiO2wlIDO+sPM/Lpp+blu2B5olCIJ8NKQr9Q1bRsmxIdDVy5UvjzCoX4OzL35I/+yYGCJwr0tWsnnrxzdpb+/6s4+rEWVqRXq2b4+L82Xbsla5Fe3IF80qRJuHXrFr7++msAQFxcHEaOHIlly5Zpu7tPmDABrVq1kuXAXZLrNImISKdWrVrYtGkT4uLioFAoMGXKFJODu1nCvXv3kJiYaLAsNDQUEydORMuWLTFr1iwMGDAABw8exKeffoqlS5cCAH766SdcuXIF7du3h5+fH7Zv3w61Wo06derg2LFjOHz4MGJjYxEUFITDhw/j3r17qFfSb2HlwLFjx/D0009rH2tOVgwbNgyrV6/Gm2++iYyMDIwaNQopKSlo27Ytdu7caXAJwJo1azBu3Dh06tQJDg4O6Nu3LxYtWlTm70Uuhw9LWz8tzTpxAMCOHcCIEWJRa05X6qJGOzflmWd08+HhYlfprVul7UOfphs6AJOjwmu4uABvvw3MnSs+1j85UBxfX2Dq1BKFBwDYvh146y2xNd6cHlJFfd/UbyUtaZE+ahSwebNhV+qirF4NTJoE1KpludZKe+hMlJ2tm/+v40+xLNmG2LcvsHw58NRTQOvWlttvcfQPZ8WNcWrqxJ0l6P9fKexEgYcH8O+/wI0bYst+cXdFsHWyFunFHcjv3LmD69eva58fPnw40tLS8Omnn2LixInw9fVFx44dZbsFm/4/zSIukyMiokIsWLAAI0aMwJNPPomAgAC89dZbVrs+e+3atVi7dq3BslmzZuHdd9/Fd999h6lTp2LWrFkIDQ3FzJkzMXz4cACAr68vNm3ahOnTpyM7Oxu1atXCunXr0KBBA2RmZmL//v345JNPkJqaimrVqmH+/PmSbi9a3nTo0KHI3m0KhQIzZ87EzCKaOf39/Y1+VxXFd9+J3byL8/334oBysbGQdNsqqVq2BM6cMX/90sZS2st6pk8Xr4sHxGK6KM8/LxbpTzwhrQdAaXXrJv6Yq6jzlvqtxKVpST9xwvz1NS2xliRlADWpLNWSrl+kW+CqMMlcXYHffy/71x05EvjvDqho167sXx8wLNIbNCh8vapVpZ1ws2WyFunFHchXr15ttOzVV1/Fq6++asWozKf/T1NqVyEiovJs+PDh2iIXKPz/fUREBPbs2WOwbOzYsQaPC3Z/N7WfFM0Nowuxb9++Ip/v27cv+hbSBNC2bVuT22ta03fs2GGR6/iJAPELcWFcXXWFQo0aQL9+ZROTFE5OQGio2IW9UaN7kHpXirlzxcHfxowp2ev7+OiuoS2udbZ+feDyZet8h6tdW7zHuSWY23PTHq/B/fVXYPx4YNky672GpYr0KlWkb9O1K7BzJ2DPw2m4uwOpqUBKSslyYAn6RXpgoDwxlDW7uibd1uj/09S/9oiIiIioJIrqSJKZCezaBVy/Lo5cbKuOHgVWrMhHtWrHAJi+LWJhKlcGjh8v3esXd9svfdYa4CwxUWzRj4sr/b6Kug5Ynz0W6Z06mXcf+NIo6YB6BbVtK16LLuVqpi++AFauNL97vK3y8rLu4LXF0f9s23s3dnOxSC8F/ZZ0FulERERUGrdumV7+229il2yFQuzebusqVwYmTVJj+/ZChoKuANzcxOu2LcHcYTpsaUR1W1LU2ARSFejoVawqVUo3fgGJFApxAEuVSt6TBWWJRXop6LekFzeQAhEREVFROnUyvbxlS7Hoo4qpuO7uCQlit3177lJtDU8+Kd7/ffRouSMhSyjqVoblEYv0UtA/s1nYfQOJiIiIzHHxouFjFxdxtGIW6BVbcUV6TIz4Q4b27BHHRoiIkDsSIuk40k0p6BfpbEknIksramBNsj/8fVJRTH08vv+eA9OS5e85XVG4uLBAJ/vFIr0U9M9ssiWdiCxF+d+QxJmZmTJHQpak+X0q7eGGwFTmCt7m7J13LDPoGNmvzz8XL3WYPl3uSIiorLG7eymo1bp7OuTniz/2OLImEdkWR0dH+Pr64u7duwAAd3d3KCx1D5lCqNVq5ObmIjs7m7cTM5O5ORMEAZmZmbh79y58fX3hyAMFFXD1KtCkieGyGTPkiYVsx8iRRd+Sj4jKLxbppVDwGqFjxzhoBxFZRkhICABoC3VrEwQBWVlZcHNzs/oJgfJCas58fX21v1cifaZu6WSp20YREZH94SGgFAreEsPcW2QQERVHoVAgNDQUQUFBUJXBoBcqlQr79+9H+/bt2R3bTFJyplQq2YJOhcrJkTsCIiKyJSzSS8HDQ0ClSll48EAcdpWNT0RkaY6OjmVS3Dk6OiIvLw+urq4s0s3EnBEREZE18MLDUhg2TMCKFbtQs6Y4JGtenswBERERERERkV1jkW4Bmkau4u5jSURERFScdu3kjoCIiOTE7u4WwCKdiIiIpLpyBdixw3j5xo1lHwsREdkOFukWcO6ceDH65MnAwYMyB0NERER2oW5dwNS4kEFBZR8LERHZDnZ3t6BDh+SOgIiIiOxFGdy4gYiI7BCLdCIiIiIb8fzzckdARERyY5FOREREZCMWL5Y7AiIikhuLdCIiIiIbcPEi4OMjdxRERCQ3FulERERENsCJw/kSERFYpBMRERGVuZMnjZdFRpZ9HEREZHtYpBMRERGVscuXDR/fuAEoFPLEQkREtoVFugVUrizIHQIRERHZkawsw8dVqsgTBxER2R4W6RbwySf5AIAWLWQOhIiIiOzC0KFyR0BERLaKRboFuLiIU7Va3jiIiIiIiIjIvrFItwBXV3GamSlvHERERGT7cnIMH3foIEsYRERko1ikW4Cvr3hN+qNHMgdCRERENi8tzfDxr7/KEwcREdkmFukW4OMjTh8/ljcOIiIisn2pqbr5WrUAR0f5YiEiItvDIt0CnJ3FqUolbxxERERk+/Rb0j095YuDiIhsE4t0C3ByEqf5+YDAu7ERERFREfRb0t3c5IuDiIhsE4t0C9AU6YBYqBMREREV5tw53by7u3xxEBGRbWKRbgH6RXpennxxEBERkW374w9g9GjdY7akExFRQSzSLUCp1M3zunQiIiIqzGefGT5mkU5ERAWxSLcAtqQTERGROQqOXRMWJk8cRERku1ikW4D+rVNYpBMREZG5pk2TOwIiIrI1LNItwMFB/AFYpBMREVHh9C+La9MG8PWVLRQiIrJRLNItRNPl/dIleeMgIiIi27Vhg24+N1e+OIiIyHaxSLcQzZnxR4/kjYOIiIjsg7Oz3BEQEZEtYpFuIR06iNOMDFnDICIiIjsRGyt3BEREZItYpFtITo44Xb9e3jiIiIjINhU8kf/mm/LEQUREto1FuoX8+ac43bZN3jiIiIjINnl66uaHDgVcXOSLhYiIbBeLdCIiIiIrO37c8PHcufLEQUREtk/WIn3//v2Ii4tDWFgYFAoFtmzZUuw2OTk5mDx5MqpVqwYXFxdERERg5cqV1g+WiIiIqIQSEgwf+/jIEwcREdk+JzlfPCMjA02aNMGIESPQp08fs7bp378/kpOTsWLFCtSsWRN37tyBWq22cqREREREJedU4BuXm5s8cRARke2TtUjv1q0bunXrZvb6O3fuxG+//YYrV67A398fABAREWGl6KSZMgWYNUvuKIiIiMgWOTrq5g8dAhQK+WIhIiLbJmuRLtW2bdvQokULzJs3D9988w08PDzw7LPPYtasWXAr5JR0Tk4OcjRDrwNITU0FAKhUKqg0NzcvIc32KpUKTz+twKxZTgbLyZh+zsg8zJl0zJl0zJl0lswZ817+ZWeL09BQICpK3liIiMi22VWRfuXKFRw4cACurq7YvHkz7t+/jzFjxuDBgwdYtWqVyW3mzJmDGTNmGC3ftWsX3N3dLRJXQkICjh4NBtAaALBly044O7MLflESCl6cR8VizqRjzqRjzqSzRM4yMzMtEAnZMs3t1/r2lTcOIiKyfXZVpKvVaigUCqxZswY+/424smDBAvTr1w9Lly412Zo+adIkxMfHax+npqYiPDwcXbp0gbe3d6niUalUSEhIQOfOndGokRLvvScub9euKypVKtWuyy39nCmVSrnDsQvMmXTMmXTMmXSWzJmmlxeVX5oi3cND3jiIiMj22VWRHhoaisqVK2sLdACoV68eBEHAzZs3UatWLaNtXFxc4GLiRqRKpdJiX0SVSiWqV9ftKy9PCX7HLZol819RMGfSMWfSMWfSWSJnzHn5xyKdiIjMZVf3SW/Tpg1u376N9PR07bK///4bDg4OqFKlioyRiby8xGlWlrxxEBERkW3RXJPOUd2JiKg4shbp6enpSExMRGJiIgDg6tWrSExMxPXr1wGIXdWHDh2qXX/w4MGoVKkSXnjhBZw7dw779+/HG2+8gREjRhQ6cFxZ0oSgORATERERAYBmbEB2miAiouLIWqQfO3YMTZs2RdOmTQEA8fHxaNq0KaZOnQoAuHPnjrZgBwBPT08kJCQgJSUFLVq0wJAhQxAXF4dFixbJEn9BmiKdLelERESkLzdXnDo7yxsHERHZPlmvSe/QoQMEQSj0+dWrVxstq1u3rs2OPuzw3ykPzXVnRERERABb0omIyHx2dU26rbt6VZxOnixvHERERGRbWKQTEZG5WKRbwcGDckdAREREtoTd3YmIyFws0omIiIisjC3pRERkLhbpFtSpkzgdPlzWMIiIiMjGsEgnIiJzsUi3oKefFqdOsg7HR0RERLaG3d2JiMhcLNItSHPg1RyIiYiIiAC2pBMRkflYpFuQl5c41bu1OxERERHOnBGnLNKJiKg4LNItqG5dcZqUJG8cREREZDtu3dLNOzrKFwcREdkHFukWpGlJT0+XNw4iIiJblZ+fjylTpiAyMhJubm6oUaMGZs2aBUEQtOsIgoCpU6ciNDQUbm5uiImJwT///CNj1KXz6JFuXtPtnYiIqDAs0i3I01OcskgnIiIy7YMPPsCyZcvw6aef4vz58/jggw8wb948LF68WLvOvHnzsGjRIixfvhyHDx+Gh4cHYmNjkZ2dLWPkJZefr5vPyZEvDiIisg8ch9yCNEV6Roa8cRAREdmqP//8Ez179kSPHj0AABEREVi3bh2OHDkCQGxFX7hwId5991307NkTAPD1118jODgYW7ZswcCBA2WLvaT0vxe4usoXBxER2QcW6Rbk4SFOVSpxhHfeZoWIiMjQk08+ic8//xx///03ateujVOnTuHAgQNYsGABAODq1atISkpCTEyMdhsfHx9ERUXh4MGDhRbpOTk5yNFrpk5NTQUAqFQqqErZx1yzfUn3k5WlgOYrV3S0qkJ0eS9tzioi5kwa5ks65kw6S+ZMyj5YpFuQpkgHxC7v/v7yxUJERGSL3n77baSmpqJu3bpwdHREfn4+3nvvPQwZMgQAkPTf6KvBwcEG2wUHB2ufM2XOnDmYMWOG0fJdu3bB3d3dIrEnJCSUaLszZwIAtEF4eCp27txrkVjsRUlzVpExZ9IwX9IxZ9JZImeZmZlmr8si3YKUSrH1PDdX7NrGIp2IiMjQd999hzVr1mDt2rVo0KABEhMTMWHCBISFhWHYsGEl3u+kSZMQHx+vfZyamorw8HB06dIF3t7epYpZpVIhISEBnTt3hrIE91BTKhUAAE9PL3Tv3r1UsdiL0uasImLOpGG+pGPOpLNkzjQ9vMzBIt3CPD2Bhw85eBwREZEpb7zxBt5++21tt/VGjRrh33//xZw5czBs2DCEhIQAAJKTkxEaGqrdLjk5GU888USh+3VxcYGLi4vRcqVSabEvoyXd1+uvi9Pz5xUV7ouxJfNfUTBn0jBf0jFn0lkiZ1K25+juFqbp8s4inYiIyFhmZiYcHAy/fjg6OkKtVgMAIiMjERISgt27d2ufT01NxeHDhxEdHV2msVrK+fNyR0BERPaELekWxtuwERERFS4uLg7vvfceqlatigYNGuDkyZNYsGABRowYAQBQKBSYMGECZs+ejVq1aiEyMhJTpkxBWFgYevXqJW/wJcBbrhERkVQs0i2Mt2EjIiIq3OLFizFlyhSMGTMGd+/eRVhYGF5++WVMnTpVu86bb76JjIwMjBo1CikpKWjbti127twJVzu8f9myZXJHQERE9oZFuoWxJZ2IiKhwXl5eWLhwIRYuXFjoOgqFAjNnzsTMmTPLLjAruXJF7giIiMje8Jp0C2ORTkRERBqVK8sdARER2RsW6RamuRUru7sTERHRf4PVExERmY1FuoVpRtZXqeSNg4iIiOT30ktyR0BERPaGRbqFsUgnIiIijbw8uSMgIiJ7wyLdwlikExERERERUUmxSLcwFulEREQEAIIgdwRERGSPWKRbmKZIZ/c2IiKiii03V+4IiIjIHrFItzDNrde2bZM3DiIiIpJXTo7cERARkT1ikW5hX34pTs+dkzcOIiIiklfBIr1qVXniICIi+8Ii3cJiYuSOgIiIiGyBfpEeHAwcPSpfLEREZD9YpFvY66+L0/r15Y2DiIiI5KVfpF+6BAQFyRcLERHZDxbpFubuLk4zMuSNg4iIiOSlKdIrVQI8PeWNhYiI7AeLdAvz9xenN25wVFciIqKKTFOku7jIGwcREdkXFukWVquWOFWr2ZpORERUkWVni1MW6UREJAWLdAtTKgGFQpzXHJyJiIio4mFLOhERlQSLdAtTKHQHY94flYiIqOJikU5ERCXBIt0KXF3FKVvSiYiIKi4W6UREVBIs0q2ALelEREQVmyAAkyeL8yzSiYhIChbpVqBpSWeRTkREVDEdPw6cPSvOs0gnIiIpWKRbgeZgzO7uREREFZNKpZvnSXsiIpKCRboVsLs7ERFRxeag9w0rKEi+OIiIyP7IWqTv378fcXFxCAsLg0KhwJYtW8ze9o8//oCTkxOeeOIJq8VXUuzuTkREVLHpfwdwdJQvDiIisj+yFukZGRlo0qQJlixZImm7lJQUDB06FJ06dbJSZKXD7u5EREQVW26ubj4vT744iIjI/jjJ+eLdunVDt27dJG83evRoDB48GI6OjpJa38uKt7c4ffRI3jiIiIhIHvot6SzSiYhIClmL9JJYtWoVrly5gm+//RazZ88udv2cnBzk6B0pU1NTAQAqlQoq/VFdSkCzfcH9VKniAMAR167lQ6VSl+o1ypvCckaFY86kY86kY86ks2TOmPfyhy3pRERUUnZVpP/zzz94++238fvvv8PJybzQ58yZgxkzZhgt37VrF9zd3S0SV0JCgsHju3frA6iFv/66iu3b/7LIa5Q3BXNGxWPOpGPOpGPOpLNEzjIzMy0QCdkStqQTEVFJ2U2Rnp+fj8GDB2PGjBmoXbu22dtNmjQJ8fHx2sepqakIDw9Hly5d4K3pl15CKpUKCQkJ6Ny5M5RKpXb5sWMO2LIFCAmJRPfu1Ur1GuVNYTmjwjFn0jFn0jFn0lkyZ5peXlR+6Bfp7ChBRERS2E2RnpaWhmPHjuHkyZMYN24cAECtVkMQBDg5OWHXrl3o2LGj0XYuLi5w0YzkpkepVFrsi2jBfan/6+H+2WeOWL6cQ7qaYsn8VxTMmXTMmXTMmXSWyBlzXv6wuzsREZWU3RTp3t7eOHPmjMGypUuXYs+ePdi4cSMiIyNliswYR3UnIiKq2PRb0p97Tr44iIjI/shapKenp+PSpUvax1evXkViYiL8/f1RtWpVTJo0Cbdu3cLXX38NBwcHNGzY0GD7oKAguLq6Gi2XW1wcsGABULWq3JEQERGRHDQt6ZUqAWPGyBsLERHZF1mL9GPHjuHpp5/WPtZcOz5s2DCsXr0ad+7cwfXr1+UKr8Tc3MSpQiFvHERERCQPTUt6z56AI698IyIiCWQt0jt06ABBEAp9fvXq1UVuP336dEyfPt2yQVmA5hJ4/a5uREREVHFovgM4O8sbBxER2R8HuQMojzRFuv6gMURERFRxaL4DmBi7loiIqEgs0q2ALelEREQVG1vSiYiopFikWwGLdCIiooqNLelERFRSLNKtQHNAzsvT3TOdiIiIKg62pBMRUUmxSLcC/bPmbE0nIiKqeDTHf7akExGRVCzSrUD/rDmLdCIioorn66/FKVvSiYhIKhbpVqB/QM7IkC8OIiIiKnsPHujmjxyRLw4iIrJPLNKtQKHQzf/+u3xxEBERUdn7/HPdfFqafHEQEZF9YpFuZe7uckdAREREZUn/UjelUr44iIjIPrFIt5J27cSp5hYsREREVDHoX+rGIp2IiKRikW4lmuvSOXAcERFRxXLxom7+uefki4OIiOwTi3Qr0dxyhUU6ERFRxfLjj7r5vn3li4OIiOwTi3Qr0RTp7O5ORERUcRQ87usPJktERGQOFulWcueOOP3kE3njICIiorLz7ru6eQd+yyIiohLg4cNKDh0SpxcuyBsHERERlZ1ly3TzvMMLERGVBIt0IiIiIgtRqXTzUVHyxUFERPaLRToRERGRhegX6YsWyRcHERHZLxbpRERERBaiVuvmg4Lki4OIiOwXi3QiIiIiK9Dc6YWIiEgKFulW8v77ckdAREREcmKRTkREJcEi3Upeekk3z3ulExERVTxKpdwREBGRPWKRbiW+vrr506dlC4OIiIhkolDIHQEREdkjFulWolQCkZHifEqKrKEQERERERGRnWCRbkVhYeL08WN54yAiIiIiIiL7wCLdijw9xWl6urxxEBERERERkX1gkW5Fbm7iNCtL3jiIiIiobNSuLU63bJE1DCIismMs0q3I3V2cskgnIiKqGPLzxWlgoLxxEBGR/WKRbkWalvTMTHnjICIiorKhue2qo6O8cRARkf1ikW5FbEknIiKqOPLygBs3xHkW6UREVFIs0q2ILelERETGbt26hf/973+oVKkS3Nzc0KhRIxw7dkz7vCAImDp1KkJDQ+Hm5oaYmBj8888/MkZsnsuXdfN5efLFQURE9o1FuhWxJZ2IiMjQo0eP0KZNGyiVSuzYsQPnzp3D/Pnz4efnp11n3rx5WLRoEZYvX47Dhw/Dw8MDsbGxyM7OljHy4m3dqpvnsZ+IiErKSe4AyjO2pBMRERn64IMPEB4ejlWrVmmXRUZGaucFQcDChQvx7rvvomfPngCAr7/+GsHBwdiyZQsGDhxY5jGb6623dPM2fj6BiIhsGIt0K+It2IiIiAxt27YNsbGxeO655/Dbb7+hcuXKGDNmDEaOHAkAuHr1KpKSkhATE6PdxsfHB1FRUTh48GChRXpOTg5ycnK0j1NTUwEAKpUKKpWqVDFrti9+P0rtXJ06KpTyZe2a+TkjDeZMGuZLOuZMOkvmTMo+WKRbkaa7+/HjwP37QECAvPEQERHJ7cqVK1i2bBni4+Pxzjvv4OjRo/i///s/ODs7Y9iwYUhKSgIABAcHG2wXHBysfc6UOXPmYMaMGUbLd+3aBXfNAbmUEhISilmjp3buzJntOHPGIi9r14rPGRXEnEnDfEnHnElniZxlSuhezSLdijQt6VeuAOHhbFEnIiJSq9Vo0aIF3n//fQBA06ZNcfbsWSxfvhzDhg0r8X4nTZqE+Ph47ePU1FSEh4ejS5cu8Pb2LlXMKpUKCQkJ6Ny5M5RKZfEbAOjevXupXtPelSRnFR1zJg3zJR1zJp0lc6bp4WUOFulWpH/intemERERAaGhoahfv77Bsnr16uGHH34AAISEhAAAkpOTERoaql0nOTkZTzzxRKH7dXFxgYuLi9FypVJpsS+jxe1LoQAEQbcuWTb/FQVzJg3zJR1zJp0lciZle47ubkWennJHQEREVLyIiAjMnDkT169ft/prtWnTBhcvXjRY9vfff6NatWoAxEHkQkJCsHv3bu3zqampOHz4MKKjo60eX2n06ydOK3gjOhERlRKLdCuqWlXuCIiIiIo3YcIEbNq0CdWrV0fnzp2xfv16g0HYLOm1117DoUOH8P777+PSpUtYu3YtPv/8c4wdOxYAoFAoMGHCBMyePRvbtm3DmTNnMHToUISFhaFXr15WiclS8vPF6TPPyBsHERHZNxbpVqR3y1ciIiKbNWHCBCQmJuLIkSOoV68eXn31VYSGhmLcuHE4ceKERV+rZcuW2Lx5M9atW4eGDRti1qxZWLhwIYYMGaJd580338Srr76KUaNGoWXLlkhPT8fOnTvh6upq0Vgs7dAhccpepEREVBos0q3Iw0PuCIiIiMzXrFkzLFq0CLdv38a0adPw5ZdfomXLlnjiiSewcuVKCJoLrkvpmWeewZkzZ5CdnY3z589rb7+moVAoMHPmTCQlJSE7Oxu//vorateubZHXthZBAG7fFucljA1ERERkhAPHWZFmdHeN/HzA0VGeWIiIiIqjUqmwefNmrFq1CgkJCWjdujVefPFF3Lx5E++88w5+/fVXrF27Vu4wbZJarZu/f1++OIiIyP7J2pK+f/9+xMXFISwsDAqFAlu2bCly/U2bNqFz584IDAyEt7c3oqOj8csvv5RNsCWgUABNm+oeS7h/PRERUZk5ceKEQRf3Bg0a4OzZszhw4ABeeOEFTJkyBb/++is2b94sd6g2S79IVyjki4OIiOyfrEV6RkYGmjRpgiVLlpi1/v79+9G5c2ds374dx48fx9NPP424uDicPHnSypGW3IEDuvncXPniICIiKkzLli3xzz//YNmyZbh16xY++ugj1K1b12CdyMhIDBw4UKYIbZ9+ke7AiwmJiKgUZO3u3q1bN3Tr1s3s9RcuXGjw+P3338fWrVvx448/oql+k7UN0b9lK1vSiYjIFl25ckV7C7TCeHh4YNWqVWUUkf3RjOwOsEgnIqLSsetr0tVqNdLS0uDv71/oOjk5OQa3kUn9bzQXlUoFVSmrZs32xe3HwcEJarUCGRkqeHuX6iXtnrk5Ix3mTDrmTDrmTDpL5kzuvN+9exdJSUmIiooyWH748GE4OjqiRYsWMkVmP9iSTkRElmLXRfpHH32E9PR09O/fv9B15syZgxkzZhgt37VrF9zd3S0SR0JCQpHPOzo+A7XaEbt27UVgYJZFXtPeFZczMsacScecScecSWeJnGVmZlogkpIbO3Ys3nzzTaMi/datW/jggw9w+PBhmSKzH7wmnYiILMVui/S1a9dixowZ2Lp1K4KCggpdb9KkSYiPj9c+Tk1NRXh4OLp06QLvUjZrq1QqJCQkoHPnzlAWcVNUV1cHqFRAmzZPo2bNUr2k3TM3Z6TDnEnHnEnHnElnyZylynzPrnPnzqFZs2ZGy5s2bYpz587JEJH90e/u3r27fHEQEZH9s8siff369XjppZfw/fffIyYmpsh1XVxc4KJ/Yfh/lEqlxb6IFrcv3VNK8LuvyJL5ryiYM+mYM+mYM+kskTO5c+7i4oLk5GRUr17dYPmdO3fg5GSXXxXKnH5LuonzHURERGazu6um1q1bhxdeeAHr1q1Djx495A7HLM7O4pSjuxMRkS3q0qULJk2ahMePH2uXpaSk4J133kHnzp1ljMx+sLs7ERFZiqynx9PT03Hp0iXt46tXryIxMRH+/v6oWrUqJk2ahFu3buHrr78GIHZxHzZsGD755BNERUUhKSkJAODm5gYfHx9Z3oM5NA0kHI+JiIhs0UcffYT27dujWrVq2rulJCYmIjg4GN98843M0dkHTXd3hYJFOhERlY6sLenHjh1D06ZNtV8I4uPj0bRpU0ydOhWA2M3u+vXr2vU///xz5OXlYezYsQgNDdX+jB8/Xpb4zcWWdCIismWVK1fG6dOnMW/ePNSvXx/NmzfHJ598gjNnziA8PFzu8OxCRoY4FQR54yAiIvsna0t6hw4dIBRxNFu9erXB43379lk3ICthSzoREdk6Dw8PjBo1Su4w7NaECXJHQERE5QVHgykDmrPrp04BTz0lbyxERESFOXfuHK5fv47cAl2/nn32WZkish8//SR3BEREVF6UqEi/ceMGFAoFqlSpAgA4cuQI1q5di/r16/MsvAk3bojT8eOB//s/eWMhIiIq6MqVK+jduzfOnDkDhUKh7eWm+O/i6nz9+4sRERGRVZXomvTBgwdj7969AICkpCR07twZR44cweTJkzFz5kyLBkhERETWNX78eERGRuLu3btwd3fHX3/9hf3796NFixZ2e6kZERGRvSpRkX727Fm0atUKAPDdd9+hYcOG+PPPP7FmzRqj68iJiIjIth08eBAzZ85EQEAAHBwc4ODggLZt22LOnDn4P3YBIyIiKlMlKtJVKhVcXFwAAL/++qv2WrW6devizp07louunPDwkDsCIiKiwuXn58PLywsAEBAQgNu3bwMAqlWrhosXL8oZGhERUYVToiK9QYMGWL58OX7//XckJCSga9euAIDbt2+jUqVKFg2wPFi5Upw++aS8cRAREZnSsGFDnDp1CgAQFRWFefPm4Y8//sDMmTNRvXp1maMjIiKqWEpUpH/wwQf47LPP0KFDBwwaNAhNmjQBAGzbtk3bDZ503N3FaU6OvHEQERGZ8u6770KtVgMAZs6ciatXr6Jdu3bYvn07Fi1aJHN0REREFUuJRnfv0KED7t+/j9TUVPj5+WmXjxo1Cu6aipS0/rsyAAXuaENERGQTYmNjtfM1a9bEhQsX8PDhQ/j5+WlHeCciIqKyUaKW9KysLOTk5GgL9H///RcLFy7ExYsXERQUZNEAywNNkc6WdCIisjUqlQpOTk44e/aswXJ/f38W6Ga6eVPuCIiIqDwpUZHes2dPfP311wCAlJQUREVFYf78+ejVqxeWLVtm0QDLA1dXccoinYiIbI1SqUTVqlV5L/RSeOIJuSMgIqLypERF+okTJ9CuXTsAwMaNGxEcHIx///0XX3/9Na9dM4Et6UREZMsmT56Md955Bw8fPpQ7FLv04IFuvmdP+eIgIqLyoUTXpGdmZmpv1bJr1y706dMHDg4OaN26Nf7991+LBlgesEgnIiJb9umnn+LSpUsICwtDtWrV4FHg3qEnTpyQKTL7ExUldwRERGTvSlSk16xZE1u2bEHv3r3xyy+/4LXXXgMA3L17F97e3hYNsDzQFOnZ2fLGQUREZEqvXr3kDqHccCrRNysiIiKdEh1Kpk6disGDB+O1115Dx44dER0dDUBsVW/atKlFAywPNOctsrIAlQpQKuWNh4iISN+0adPkDqHccHOTOwIiIrJ3JSrS+/Xrh7Zt2+LOnTvae6QDQKdOndC7d2+LBVde+Pjo5m/dAiIiZAuFiIiIrEgzWCwREVFJlbhTVkhICEJCQnDzv/uOVKlSBa1atbJYYOWJkxPg6Ajk5wMXL7JIJyIi2+Lg4FDk7dY48rv52JJORESlVaIiXa1WY/bs2Zg/fz7S09MBAF5eXpg4cSImT54MB4cSDRpfrrVoARw+DGRmyh0JERGRoc2bNxs8VqlUOHnyJL766ivMmDFDpqjsk2YcGiIiopIqUZE+efJkrFixAnPnzkWbNm0AAAcOHMD06dORnZ2N9957z6JBlgeHD4vTL74AeEUAERHZkp4m7hvWr18/NGjQABs2bMCLL74oQ1T2ydlZ7giIiMjelahI/+qrr/Dll1/i2Wef1S5r3LgxKleujDFjxrBIL8KOHXJHQEREZJ7WrVtj1KhRcodhV9iZkIiISqtEh5KHDx+ibt26Rsvr1q2Lhw8fljqo8ui/28obDCJHRERkq7KysrBo0SJUrlxZ7lDsCot0IiIqrRK1pDdp0gSffvopFi1aZLD8008/RePGjS0SWHnzwQfAmDFAp05yR0JERGTIz8/PYOA4QRCQlpYGd3d3fPvttzJGZn9YpBMRUWmVqEifN28eevTogV9//VV7j/SDBw/ixo0b2L59u0UDLC/c3cXppk3A7dtAWJi88RAREWl8/PHHBkW6g4MDAgMDERUVBT8/Pxkjs32PHhk+dnSUJw4iIio/SlSkP/XUU/j777+xZMkSXLhwAQDQp08fjBo1CrNnz0a7du0sGmR5oD/a63PPAX/8IV8sRERE+oYPHy53CHbr/fcNH7MlnYiISqvE90kPCwszGiDu1KlTWLFiBT7//PNSB1be6J9Z//NP+eIgIiIqaNWqVfD09MRzzz1nsPz7779HZmYmhg0bJlNktu/OHcPHLNKJiKi0eCgpI2lpckdARERk2pw5cxAQEGC0PCgoCO8XbComAwVvucbu7kREVFos0ssID9pERGSrrl+/jsjISKPl1apVw/Xr12WIyH507Gj4WO/SfiIiohJhkV5G1Gq5IyAiIjItKCgIp0+fNlp+6tQpVKpUSYaI7EfB7u083hMRUWlJuia9T58+RT6fkpJSmljKNR60iYjIVg0aNAj/93//By8vL7Rv3x4A8Ntvv2H8+PEYOHCgzNHZtvx8w8c83hMRUWlJKtJ9fHyKfX7o0KGlCqi84kGbiIhs1axZs3Dt2jV06tQJTk7iVwO1Wo2hQ4fymvRiFDy+FyzaiYiIpJJUpK9atcpacZR7NWrIHQEREZFpzs7O2LBhA2bPno3ExES4ubmhUaNGqFatmtyh2Ty2pBMRkaWV+BZsJM3TTwOtWgFHjsgdCRERkWm1atVCrVq15A7DrrAlnYiILI0Dx5URhQKYO1f3mGfaiYjIVvTt2xcffPCB0fJ58+YZ3TudDE2fbviYx3ciIiotFull6MkndfOPH8sXBxERkb79+/eje/fuRsu7deuG/fv3yxCR/bh1y/Axi3QiIiotFullyMUFcHMT5x89kjcWIiIijfT0dDg7OxstVyqVSE1NlSEi+8Xu7kREVFos0suYn5845d3qiIjIVjRq1AgbNmwwWr5+/XrUr19fhojsV3S03BEQEZG948BxZczPD7h9my3pRERkO6ZMmYI+ffrg8uXL6NixIwBg9+7dWLt2LTZu3ChzdPZBqQRu3gSCguSOhIiI7B1b0stYdrY4XbJE3jiIiIg04uLisGXLFly6dAljxozBxIkTcevWLezZswc1a9aUOzy74O3NAp2IiCyDLell7PJlcbp5s7xxEBER6evRowd69OgBAEhNTcW6devw+uuv4/jx48jnhdYmCYJu3onfqIiIyELYkk5EREQAxFHehw0bhrCwMMyfPx8dO3bEoUOH5A7LZumfu/D3ly8OIiIqX3jel4iIqAJLSkrC6tWrsWLFCqSmpqJ///7IycnBli1bOGhcMfLydPNVq8oXBxERlS+ytqTv378fcXFxCAsLg0KhwJYtW4rdZt++fWjWrBlcXFxQs2ZNrF692upxEhERlUdxcXGoU6cOTp8+jYULF+L27dtYvHix3GHZDf0ind3diYjIUmQt0jMyMtCkSRMsMXMUtatXr6JHjx54+umnkZiYiAkTJuCll17CL7/8YuVIiYiIyp8dO3bgxRdfxIwZM9CjRw84OjrKHZJd0b+FvFIpXxxERFS+yHret1u3bujWrZvZ6y9fvhyRkZGYP38+AKBevXo4cOAAPv74Y8TGxlorTKvJzgZcXeWOgoiIKqoDBw5gxYoVaN68OerVq4fnn38eAwcOlDssu6HfRsCWdCIishS7OqQcPHgQMTExBstiY2MxYcKEQrfJyclBTk6O9nHqf6e9VSoVVCpVqeLRbC9tP7pT7RkZKlS0RouS5axiY86kY86kY86ks2TO5Mp769at0bp1ayxcuBAbNmzAypUrER8fD7VajYSEBISHh8PLy0uW2OxBlSq6+Yp2PCciIuuxqyI9KSkJwcHBBsuCg4ORmpqKrKwsuLm5GW0zZ84czJgxw2j5rl274O7ubpG4EhISJKzdUzu3c2cCPD0r5hdiaTkjgDkrCeZMOuZMOkvkLDMz0wKRlJyHhwdGjBiBESNG4OLFi1ixYgXmzp2Lt99+G507d8a2bdtkjc9W6V+TrlDIFwcREZUvdlWkl8SkSZMQHx+vfZyamorw8HB06dIF3t7epdq3SqVCQkICOnfuDGUJLkZ7+unOCAwsVQh2p7Q5q4iYM+mYM+mYM+ksmbNU/YubZVanTh3MmzcPc+bMwY8//oiVK1fKHZLNYscTIiKyBrsq0kNCQpCcnGywLDk5Gd7e3iZb0QHAxcUFLi4uRsuVSqXFvoiWdF8ODsoKO9CMJfNfUTBn0jFn0jFn0lkiZ7aYc0dHR/Tq1Qu9evWSOxSbpV+ksyWdiIgsRdbR3aWKjo7G7t27DZYlJCQgOjpapohKR7+bHBEREdmX3FzdvINdfaMiIiJbJushJT09HYmJiUhMTAQg3mItMTER169fByB2VR86dKh2/dGjR+PKlSt48803ceHCBSxduhTfffcdXnvtNTnCLzUW6URERPaLLelERGQNshbpx44dQ9OmTdG0aVMAQHx8PJo2bYqpU6cCAO7cuaMt2AEgMjISP//8MxISEtCkSRPMnz8fX375pV3dfm3kSN38zp3yxUFERGQL5s6dC4VCYXCnluzsbIwdOxaVKlWCp6cn+vbta3S5my3Qb0lnkU5ERJYi6zXpHTp0gCAIhT6/evVqk9ucPHnSilFZ16JFwBdfiPMffwyMHi1vPERERHI5evQoPvvsMzRu3Nhg+WuvvYaff/4Z33//PXx8fDBu3Dj06dMHf/zxh0yRmsaWdCIisga7GjiuPHB11c3r3b6diIioQklPT8eQIUPwxRdfYPbs2drljx8/xooVK7B27Vp07NgRALBq1SrUq1cPhw4dQuvWrU3uLycnBzl6B1bNiPkqlarU96HXbF9wP9nZDgDEG6Sr1WqoVPmlep3ypLCcUeGYM2mYL+mYM+ksmTMp+2CRLiMW6UREVFGNHTsWPXr0QExMjEGRfvz4cahUKsTExGiX1a1bF1WrVsXBgwcLLdLnzJmDGTNmGC3ftWsX3N3dLRJzQkKCwePTp2sAaAgAePz4KrZvP2uR1ylPCuaMisecScN8ScecSWeJnGVmZpq9Lot0GSUlyR0BERFR2Vu/fj1OnDiBo0ePGj2XlJQEZ2dn+Pr6GiwPDg5GUhEHzkmTJiE+Pl77ODU1FeHh4ejSpQu8vb1LFa9KpUJCQgI6d+5scLu8M2d0Q/t8+WVV+PlVLdXrlCeF5YwKx5xJw3xJx5xJZ8mcaXp4mYNFugxq1gQuXRLnr18HqvKYTkREFcSNGzcwfvx4JCQkwFX/GrBScnFxgYuLi9FyS9zHvrB95f/Xu330aCAoiF94TbFk/isK5kwa5ks65kw6S+RMyva8q6cM9Hvq2eBgtURERFZz/Phx3L17F82aNYOTkxOcnJzw22+/YdGiRXByckJwcDByc3ORkpJisF1ycjJCQkLkCboQmssL+V2XiIgsiUW6DN57Tzevf/sWIiKi8q5Tp044c+YMEhMTtT8tWrTAkCFDtPNKpRK7d+/WbnPx4kVcv34d0dHRMkZujEU6ERFZA7u7y0C/e/vjx/LFQUREVNa8vLzQsGFDg2UeHh6oVKmSdvmLL76I+Ph4+Pv7w9vbG6+++iqio6MLHTROLtnZ4tSCvfaJiIhYpMulQwdg3z5AwvgBREREFcLHH38MBwcH9O3bFzk5OYiNjcXSpUvlDssIi3QiIrIGFuky8fERp2xJJyKiim7fvn0Gj11dXbFkyRIsWbJEnoDM9OCBOHVzkzcOIiIqX3hNukxYpBMREdm3H34QpxcuyBsHERGVLyzSZcIinYiIqHzIzJQ7AiIiKk9YpMvEz0+c3rsnbxxERERUOmPHyh0BERGVJyzSZVKrljj95x954yAiIqLS8fKSOwIiIipPWKTLJDRUnLIlnYiIyP6cP6+b533SiYjIklikyyQwUJyySCciIrI/LVro5p2d5YuDiIjKHxbpMtEU6ffvA2q1vLEQERGRNPqDxTnw2xQREVkQDysyCQgQp2o18PChvLEQERFRyalUckdARETlCYt0mSiVHOGdiIjIXvXurZuvVk2+OIiIqPxhkS6jR4/E6caN8sZBRERE0tSvL05ffBFwcZE3FiIiKl9YpNuAqVPljoCIiIikyMsTp97e8sZBRETlD4t0GUVGyh0BERERlUR+vjh1dJQ3DiIiKn9YpMuoWTO5IyAiIqKSYJFORETWwiJdRpMn6+ZPnZIvDiIiIpJGU6Q7OckbBxERlT8s0mUUEaGbf+012cIgIiIiiTTXpLMlnYiILI1Fuoz0B5vhPVaJiIjsB7u7ExGRtbBIl5H+gb11a/niICIiImnY3Z2IiKyFRbrM3nhDnKrV8sZBRERE5mN3dyIishYW6TJzdxenmZnyxkFERETmY3d3IiKyFhbpMtMU6VlZ8sZBRERE5mORTkRE1sIiXWZsSSciIrI/mu7uvCadiIgsjUW6zNzcxOnOnfLGQUREROZjSzoREVkLi3SZ+fiIU6VS3jiIiIjIfCzSiYjIWliky6x9e3H68CHvlU5ERGQveAs2IiKyFhbpMvPz082np8sXBxEREZnvxx/FKVvSiYjI0liky0yp1HV1z8iQNxYiIiKS5sgRuSMgIqLyhkW6DfDwEKcs0omIiOzLrVtyR0BEROUNi3QboCnS2d2diIjIvqjVckdARETlDYt0G8CWdCIiIvukGUCOiIjIUlik2wAW6URERPapUye5IyAiovKGRboNYJFORERkP/S7uA8dKl8cRERUPrFItwEs0omIiOxHXp5u3tlZvjiIiKh8sokifcmSJYiIiICrqyuioqJwpJj7mSxcuBB16tSBm5sbwsPD8dprryE7O7uMorU8DhxHRERkP/SLdCcn+eIgIqLySfYifcOGDYiPj8e0adNw4sQJNGnSBLGxsbh7967J9deuXYu3334b06ZNw/nz57FixQps2LAB77zzThlHbjk3bojTcePkjYOIiIiKp1Lp5lmkExGRpcl+aFmwYAFGjhyJF154AQCwfPly/Pzzz1i5ciXefvtto/X//PNPtGnTBoMHDwYAREREYNCgQTh8+LDJ/efk5CAnJ0f7ODU1FQCgUqmg0j/KloBm+9Lu5+hRpdE+yytL5awiYc6kY86kY86ks2TOmHf7wiKdiIisSdZDS25uLo4fP45JkyZplzk4OCAmJgYHDx40uc2TTz6Jb7/9FkeOHEGrVq1w5coVbN++Hc8//7zJ9efMmYMZM2YYLd+1axfc3d0t8j4SEhJKtf0LL9TAqlUNAQDr1v0KH59cS4Rl00qbs4qIOZOOOZOOOZPOEjnLzMy0QCRUVlJSxKmnJ+DoKGsoRERUDslapN+/fx/5+fkIDg42WB4cHIwLFy6Y3Gbw4MG4f/8+2rZtC0EQkJeXh9GjRxfa3X3SpEmIj4/XPk5NTUV4eDi6dOkCb2/vUsWvUqmQkJCAzp07Q6lUFr9BIQICFFi1SpwPDu6Mjh2FUsVlyyyVs4qEOZOOOZOOOZPOkjnT9PIi+3D/vjitVEneOIiIqHyyu05a+/btw/vvv4+lS5ciKioKly5dwvjx4zFr1ixMmTLFaH0XFxe4uLgYLVcqlRb7ImrJfeXmOqEifD+2ZM4qCuZMOuZMOuZMOkvkjDm3L5qOD5qBX4mIiCxJ1iI9ICAAjo6OSE5ONlienJyMkJAQk9tMmTIFzz//PF566SUAQKNGjZCRkYFRo0Zh8uTJcHCQfSw8yRQK3fyhQ0BcnHyxEBERUdE0Q92YaAMgIiIqNVkrWmdnZzRv3hy7d+/WLlOr1di9ezeio6NNbpOZmWlUiDv+d0GYINhnN/GoKN38++/LFwcREREVL/e/oWNYpBMRkTXI3t09Pj4ew4YNQ4sWLdCqVSssXLgQGRkZ2tHehw4disqVK2POnDkAgLi4OCxYsABNmzbVdnefMmUK4uLitMW6vSkYdlISUEhHAiIiIpIZW9KJiMiaZC/SBwwYgHv37mHq1KlISkrCE088gZ07d2oHk7t+/bpBy/m7774LhUKBd999F7du3UJgYCDi4uLw3nvvyfUWLGLyZEDzFi5dYpFORERkq1ikExGRNclepAPAuHHjMG7cOJPP7du3z+Cxk5MTpk2bhmnTppVBZGVn1ixdkX79uryxEBERUeFYpBMRkTXZ3yhr5ZRCoRswLiND3liIiIiocCzSiYjImlik2xB3d3F67568cRAREVHhWKQTEZE1sUi3IYmJ4nTWLFnDICIioiKwSCciImtikW5DatYUp9nZQF6evLEQERGRaSzSiYjImlik25BRo3Tzf/whXxxERERUOBbpRERkTSzSbYirq27+7l354iAiIqLCpaWJU09PeeMgIqLyiUW6DVEodPOLFskXBxERERXu/n1xGhAgbxxERFQ+sUi3IfpF+oEDQGamfLEQERGRaQ8eiNNKleSNg4iIyicW6TZEv0gHgIcP5YmDiIiICseWdCIisiYW6TaERToREZHtS08Xp7wmnYiIrIFFug1p3drwsaY7HREREdmO/Hxx6ugobxxERFQ+sUi3Ie7u4j3Sq1cXH7MlnYiIyPawSCciImtikW5jXFyAGjXE+exseWMhIiIiYyzSiYjImlik26ADB8Tp1KnyxkFERETGWKQTEZE1sUi3QVlZ4vTKFXnjICIiImMs0omIyJpYpBMRERGZ6c4d4N49cZ5FOhERWQOLdBunOVtPRERE8hs6VDfPIp2IiKyBRbqN4+BxRERUnsyZMwctW7aEl5cXgoKC0KtXL1y8eNFgnezsbIwdOxaVKlWCp6cn+vbti+TkZJkiNnTsmG6eRToREVkDi3Qbd+eO3BEQERFZzm+//YaxY8fi0KFDSEhIgEqlQpcuXZCRkaFd57XXXsOPP/6I77//Hr/99htu376NPn36yBi1aSzSiYjIGpzkDoCMHToEtG4tzsfFAefPyxsPERGRpezcudPg8erVqxEUFITjx4+jffv2ePz4MVasWIG1a9eiY8eOAIBVq1ahXr16OHToEFprDpAySUnRzbNIJyIia2CRboOionTzFy7IFwcREZG1PX78GADg7+8PADh+/DhUKhViYmK069StWxdVq1bFwYMHCy3Sc3JykJOTo32cmpoKAFCpVFCpVKWKUbO9OFVql6vVKpRy1+WWYc7IHMyZNMyXdMyZdJbMmZR9sEgnIiIiWajVakyYMAFt2rRBw4YNAQBJSUlwdnaGr6+vwbrBwcFISkoqdF9z5szBjBkzjJbv2rUL7u7uFok3ISEBQE+9fe9DcHCmRfZdXok5IymYM2mYL+mYM+kskbPMTPOPFyzSbdTSpcCYMUBYmNyREBERWcfYsWNx9uxZHDhwoNT7mjRpEuLj47WPU1NTER4eji5dusDb27tU+1apVEhISEDnzp0Nlvfu3QEFziXQf/RzplQqi9+AmDOJmC/pmDPpLJkzTQ8vc7BIt1FduohTDhxHRETl0bhx4/DTTz9h//79qFKlinZ5SEgIcnNzkZKSYtCanpycjJCQkEL35+LiAhcXF6PlSqXSYl9GC+4nMJBfcotjyfxXFMyZNMyXdMyZdJbImZTtObq7jQoKEqeCALz8sryxEBERWYogCBg3bhw2b96MPXv2IDIy0uD55s2bQ6lUYvfu3dplFy9exPXr1xEdHV3W4RaqfXu5IyAiovKKLek2ystLN//558BLLwEtW8oXDxERkSWMHTsWa9euxdatW+Hl5aW9ztzHxwdubm7w8fHBiy++iPj4ePj7+8Pb2xuvvvoqoqOjZR/ZXZ8Tv0EREZGV8BBjJ1q1As6dA+rVkzsSIiKiklu2bBkAoEOHDgbLV61aheHDhwMAPv74Yzg4OKBv377IyclBbGwsli5dWsaRFo1FOhERWQsPMTZs0CBg3Trd42PHWKQTEZF9EwSh2HVcXV2xZMkSLFmypAwiMp9arZtnkU5ERNbCa9Jt2DvvGD52dJQnDiIiIgLu3dPN9+kjXxxERFS+sUi3YfrXpQOAA39bREREslm9Wncgfu45GQMhIqJyjWWfDXN3N3zMlnQiIiL5KBS6ed69iIiIrIVFug0rWKRnZckTBxERERmeLOc16UREZC0s0m2Ym5vh4zFj5ImDiIiIgNBQ3aB3LNKJiMhaWKTbsILXoGdkyBMHERERAZ6e4tTf37DrOxERkSWxSLdxd+/KHQEREREBgEolTuvXlzcOIiIq31ik27jAQCAmRu4oiIiIKC9PnHLQOCIisiYW6XagenXdvFotXxxEREQVmaZI5/XoRERkTSzS7YCzs27+2DH54iAiIqrI2JJORERlgUW6HRg7Vje/bJl8cRAREVVkbEknIqKywCLdDtStC4SGivOrV8saChERUYW1b5/4tSklRd44iIiofLOJIn3JkiWIiIiAq6sroqKicOTIkSLXT0lJwdixYxEaGgoXFxfUrl0b27dvL6No5eHjI3cEREREFduGDeLXpv37ZQ6EiIjKNdmL9A0bNiA+Ph7Tpk3DiRMn0KRJE8TGxuJuIfcey83NRefOnXHt2jVs3LgRFy9exBdffIHKlSuXceRlq0oV3XxmpnxxEBERERERkfXIXqQvWLAAI0eOxAsvvID69etj+fLlcHd3x8qVK02uv3LlSjx8+BBbtmxBmzZtEBERgaeeegpNmjQp48jL1mef6eZv3JAvDiIiIiIiIrIeWYc+yc3NxfHjxzFp0iTtMgcHB8TExODgwYMmt9m2bRuio6MxduxYbN26FYGBgRg8eDDeeustODo6Gq2fk5ODnJwc7ePU1FQAgEqlgkqlKlX8mu1Lux9zhIcDgDic7E8/5aN6dfu8F1tZ5qy8YM6kY86kY86ks2TOmHciIiLSkLVIv3//PvLz8xEcHGywPDg4GBcuXDC5zZUrV7Bnzx4MGTIE27dvx6VLlzBmzBioVCpMmzbNaP05c+ZgxowZRst37doFd3d3i7yPhIQEi+yneD0BAK+/7oiIiJ/h5CSU0etaXtnlrPxgzqRjzqRjzqSzRM4yeR0TERER/cfubiKiVqsRFBSEzz//HI6OjmjevDlu3bqFDz/80GSRPmnSJMTHx2sfp6amIjw8HF26dIG3t3epYlGpVEhISEDnzp2hLOObptat2w21a5fpS1qEnDmzV8yZdMyZdMyZdJbMmaaXFxEREZGsRXpAQAAcHR2RnJxssDw5ORkhISEmtwkNDYVSqTTo2l6vXj0kJSUhNzcXzs7OBuu7uLjAxcXFaD9KpdJiX0QtuS9zff65Ep98UqYvaVFy5MzeMWfSMWfSMWfSWSJnzDkRERFpyDpwnLOzM5o3b47du3drl6nVauzevRvR0dEmt2nTpg0uXboEtVp3Tfbff/+N0NBQowK9vJk4UTe/aBFQ4NwGERERlYFXXpE7AiIiKs9kH909Pj4eX3zxBb766iucP38er7zyCjIyMvDCCy8AAIYOHWowsNwrr7yChw8fYvz48fj777/x888/4/3338fYsWPlegtl5qOPgMWLdY8/+EC+WIiIiCqa5s3FBoIePWQOhIiIyjXZr0kfMGAA7t27h6lTpyIpKQlPPPEEdu7cqR1M7vr163Bw0J1LCA8Pxy+//ILXXnsNjRs3RuXKlTF+/Hi89dZbcr2FMhUUpJtftQpYsEC+WIiIiCoSlUoBADBxMxkiIiKLkb1IB4Bx48Zh3LhxJp/bt2+f0bLo6GgcOnTIylHZpi5ddPMpKcD+/UD79rKFQ0REVCEIAnD6tFikq+3zLqhERGQnZO/uTtL4+ho+fuopWcIgIiKqUPQL87/+ki8OIiIq/1iklwM3b8odARERUfmWn6/7yqRSyRgIERGVeyzS7ZBCYfg4PFyeOIiIiCqK/Hzdwfe/sW2JiIisgkW6Hbp82XiZIJR9HERERBXF8ePB2vmAABkDISKico9Fuh2KjBQHjNP3yy/yxEJERFQRfPRRS+28k00Mu0tEROUVi3Q71a4dcO+e7nG3bsBvv8kXDxERUUVR8LIzIiIiS2KRbscKdrfr0AFISpIlFCIiIiIiIrIAFul2btYsw8ehofLEQURERERERKXHIt3OvfsuEBZmuOz994ErV+SJh4iIiIiIiEqORXo5cOuW4ePJk4EaNeSJhYiIiIiIiEqORXo50aCB8bJvvin7OIiIiMqjli3vAADc3WUOhIiIyj0W6eXEr78aLxs+vMzDICIiKpe8vXMBiJeZERERWROL9HIiJATYtMlwmVoN/PCDPPEQERGVJ3l54lcmpVLmQIiIqNxjkV6O9O5t3Hrerx8gCLKEQ0REVG7k54s3R2eRTkRE1sYivZxZsMB4WY0aQG5u2cdC8vv3XyAtTe4oiIjsH1vSiYiorLBIL2f8/MRbsOm7ehX48Ud54iHLEwSgTx8gLq7oXhLXrgEREUBoaFlFRkRUfmla0p2dZQ6EiIjKPRbp5dCkScbFW79+gIcHkJEhT0xkOSkpwObNwE8/AXfuFL7eb7+JU/7OiYhKLz+fLelERFQ2WKSXY++8Y/g4MxPw9OQ16vYuP183r1AUvp4D/7oLlZMDpKbKHQUR2RN2dyciorLiJHcAZD0zZhh3fQfEEd/79Sv7eADgww8d8M03bdG+vdg1X4qDB4F584D584Hq1aW/9s2bwMyZwKuvAo0aSd/ekgSh6AK7KHl55q3n6Fiy/Zd3eXlAvXrAo0fipSC+vnJHRET2gAPHEZU/giAgLy8P+fotIOWYSqWCk5MTsrOzK8x7Li2pOVMqlXC0wJdwFunlmJMT8M8/QK1ahsufe07sMu3iAsTHi4PKzZ8P+PhI2//Dh8C5c0B0tPkF4eTJjgAq4csv8/HGG9Je78knxemtW8CRI9K2BYBRo4AdO4AvvxRvTyeX1q2Bw4fFkw6tW0vfXn8QQJWq8PXsvUi/cgU4e1a89r6kJzRMSUkRi3NAnDZtarl9S6FWA8nJHDPAErKzxf9nlvycEBWkUokt6S4uMgdCRBaRm5uLO3fuIDMzU+5QyowgCAgJCcGNGzeg4EHTLFJzplAoUKVKFXh6epbqdVmkl3M1a4othgEBht2kC7Ye7tkDnDypK9RTU8X7rvfsWXiLd1QUcOmSOD9iBLBihTh/9qxYSMfGGq7/6JFuPj29+NhPnQKqVAEqVTJcrnlNqc6eFafmdvdPTAQqVwYCA0v2eoU5fFicRkeX7NKDnBzdfFGt6vpFen6+/RXtNWqI0x07gK5dLbdf/RMbcp5EHj4c+OYb4MABoE0b+eIorb17gbAwoE4deV7/5k2xZ0SvXmI+iawlO1v8ylTK711EZAPUajWuXr0KR0dHhIWFwdnZuUIUrWq1Gunp6fD09IQDr4s0i5ScCYKAe/fu4ebNm6hVq1apWtRZpFcAvr5i62tRn5OrV4FBg4Dt28XH//d/wFdficXRjh2mt9Evlleu1BXpmq7kZ84ADRvq1lmyRDdfXEv2yZNAs2biYHfmFPTm8PAwf92ffwaeeQaIiQESEizz+oBhUd6uXcn2YW5Luv7/EZWqbIr0ixeBX38FRo603AjI+/ZZr0gvKn9SnDsHvPQSMG2a8cmpwmgKym++sd8i/auvxJMNgHxjXXz7rfg/4ttvWaSTdWVlsUgnKi9yc3OhVqsRHh4Od3d3ucMpM2q1Grm5uXB1dWWRbiapOQsMDMS1a9egUqlKVaTzt1NBODgU/yV6xw6xe/yff4pfvgFg507j9cztKv7XX4aP9YvL4vaxa5c41YxMLqUAKGxdJwmnpNavF6e//mr+NubQbwU31c35m2+Avn2LbuHVz2NRLen9+5veRoqrV8UuxNOnm7d+3brAuHGGJ2RKy9Kt3fqFeUnzUtDw4eLlC+aeTND/vdnz6PuaAl1OwcG6+ayswtfbvbtkl8kQAeIxKz1dvBjdy0vmYIjIYliokqVZqkcGP5lkoHZt41a9n38Gnn9eLNYUCiAoCEhKMt5WEAwLZM11vxr63calFkdDhpi33k8/iV/aNT0C9OkP9lPUSYLUVLFVzlwJCWJPAgBYt068dv7GDdPr6hcR+gW7xtCh4mUGTzxR+OuZ25KuX9yaei1zPPWUOJ0xo/h19UdLL23vA/3PkaXHD7BGS3pKim7enBNKX3whbX0qnH6rpqn/SwCwf7/YKyYqCujcWd4xKcg+7dunQFaWeBCpWVPmYIiIqNxjkV6BNWsGbNsGzJ1b9HrPPGNYtD54YLoV+OFDcQAnjUmTCm/p9fc3P84DB8TiV+PRI2DsWNP3CI+LA+7dE6+lL0i/SJ85s/DX+/hjw8fFFVFdugAvvihe8z54sNiiGh8vPnfkiDivKWD1xyYpqgX17Fng8WPTz+kX3IWd7CjY+lzSFmMprdj6RbqUSxQEQew9MHCgbpn+58gSLelqNfD118Dff5esSL93r+jn9VvWNAMiHj4MLF1q+vNj6iRSaWRnAxs3Gp4s2LtXPLn24IHhet9/b7heWVCrgR9/NP03W1r6v8P33jN9QmriRN38r78CR48Wv9/cXLFnEREAdO2q64rF0d2JiMjaWKRXMOPGidOhQ4Hjx8Wi9q23xNby0goLA6pVM1w2e7Y4vX9fvM5dY906Bxw6VPi+9LvZm7p2e+lSoG3bwrc3dXJAv7t7US3DBbt2F9WFVt/Nm7p5TUt6VJRY9E+daryv4gqlc+dML9cvuH/6yfQ6BQuVkhbp5r53AEhL080LgvjZ2ru3+O2SksTeAxs26HKiX/BborV77Vpg2DBxcDOpRfqnn4q9RxYsKHwd/SJ9/nxx2rq1eDJp2zbj9fV/b5ZoSZ8/X7xrg5+frijv2FE8uaZ/F4XXXxcvg/DzA7ZsKf3r6ivqfaxdCzz7rPj3YGn6n+0VK4CPPjJep+Dv2ZyeJbGxYs8iU5f8EBERlScRERFYuHCh3GGQHhbpFcz8+eK1mZ99Zri8e3ddd3VBEFtxHz0SW4g1wsKK3ndurnGL44wZYhf5giOknzmjQHS02Er/6qtigZucDNy+LRaG+/YV/16uXCn6y7Z+ayxg3PphqqgwVdzrF4wF6X/5178EpWBcZ86IU/2iV3+0e1M++QS4dk38XejHql+UzJpletuC772kRbqUFnH9PB04IBaiHTvqlp0/L56sKNhDQL+lXBOn/r6WLi19oX7ggG5ef1/6JxYK8+qr4lS/NbYgb+/Cnys4NkNBa9fq5vfsAf79V/fY3AJ+1SrdfECA4XP6AzzqjxXQu7fY+0XfmTMBaNHCCbt3m/e6+revK+p3pLl2vbDLQEqj4Gf74EHjdQr+PZjT3V3zP2j58hKFReUIbyVMRLZCoVAU+TPd3EGECjh69ChGjRplkRjXrVsHR0dHjB071iL7q6hYpFcwzs5i4eTqWvR63t7iqPBffqkr3G/dEovYv/7SjRRe2gExf/5ZbKkMDwdCQsRbnknZp6urWBzXrGl8j2Q3N9119AoF8Ntvhs87OIg/CoX4focMEUfnLig2Fpg3T+y+PGKEWFQtWQJs3gy8+aZuvTFjdPOJiYZf7hUK8Uv/6dO6ZZcvi93hf/oJuHvX+Br+DRuAyEggMFCJjz5qgUePxEIoMdFwvStXxFHVc3N1RV3BFnBNN/usLLEw0/99amiWaYotQTAsvI4eLboQK65nQP364kmFWrUMl+sXUGlp4n4KnhjRHDc0n0X9ONLTiz/hoV/s6l+3/OKLYm42by75dfuA8UBShZ28KczNm8D48UCnTkBEhLhsyxbxb3Dr1uK3L+q+zUUV+vqfRwCYMqUNTp9WICbGvJHS9d/bzZtiz4nr1w3XOXvWsMjp0UPscg8YFssl7VFgzu+t4P+U3Fzzf99FxcXxBCoGSw0wSURUWnfu3NH+LFy4EN7e3gbLXn/9de26giAgr6gRhvUEBgZabJT7FStW4M0338S6deuQXfAseRnLted/4EIF8/jxYwGA8Pjx41LvKzc3V9iyZYuQm5trgcjsV16eIDx+LAiffioI7doJQuPGgnDggCDEx+u3zYs/tWurhREjThst5w9/LPHTvLll9qNUyv9e9H8UCvljqCg/UnNdp84DISen9McASx6bSGSpnD5+bPg7J/PwO5J0zJk0pclXVlaWcO7cOSErK0u7TK0WhPT0sv9Rq0v2/letWiX4+PhoH+/du1cAIGzfvl1o1qyZoFQqhb179wqXLl0Snn32WSEoKEjw8PAQmjZtKvzyyy8G+6pWrZrw8ccfax8DEL744guhV69egpubm1CzZk1h69atxcZ05coVwc3NTUhJSRGioqKENWvWGK2zYsUKoX79+oKzs7MQEhIijB07Vvvco0ePhFGjRglBQUGCi4uL0KBBA+HHH38UBEEQpk2bJjRp0sRgXx9//LFQrVo17eNhw4YJPXv2FGbPni2EhoYKERERgiAIwtdffy00b95c8PT0FIKDg4VBgwYJycnJBvs6e/as0KNHD8HLy0vw9PQU2rZtK1y6dEnYu3ev4OTkJNy6dctg/fHjxwtt27Y1en+mPlsaUo5LbEmnUnN0FFuix44VR1E+dUocIX7+fOOvtGfP5uHZZ68gN1eFU6fE275dvCiOBv7ll+ItvDQ++kj82bVLbHU+f17sEv/tt8APPxjG0Ly5br5PH+Nr4/WZM1I5UPj13pYg5XZwpeHmVjavYyuOH7fMfiw16rulCILcEVQcUnN98aI/B5gr52zt/wERWUdmpnjHkLL+0R9U2BLefvttzJ07F+fPn0fjxo2Rnp6O7t27Y/fu3Th+/Dg6deqEnj174nrBrm8FzJgxA/3798fp06fRvXt3DBkyBA8LXidXwKpVq9CjRw/4+Pjgf//7H1asWGHw/LJlyzB27FiMGjUKZ86cwbZt21Dzv1tmqNVqdOvWDX/88Qe+/fZbnDt3DnPnzpV8r/Hdu3fj4sWLSEhIwE//fZlXqVSYNWsWTp06hS1btuDatWsYrncf2Vu3bqF9+/ZwcXHBnj17cPz4cYwYMQJ5eXlo3749IiIi8K3eKNoqlQpr1qzBiBEjJMUmRRmVCkTGGjcWfwBxgCbA8Br4wmhuxyb1y/Tly+LJhMBA8drotDSxy2tAgNid8eFDcUCt69eBGjV095ZPSxO/pKWliV16MzPFkwUqlXj98Isvitf5u7oCDRqIJwiuXxf/8f7yCzB6tC6Gb78Vr+1/6imxC3Bqqnitc5MmuhHhATEelUqMKTxctzwmRuw2/uab4jX2e/eKsTx8KA7Od+KEGF/z5uKJkqFDgTVrDO9nPW+euM9vvxXjrl5dHF1961bD7s+1a4snExYvFkflPnVKfF9Xr4pxeHuLt57Lzha7E/fuDXh4iL/T+/fFEzYXLqDQAQIrVxa712s0aSK+BgC0by9e/jBvnjjCdp8+Yn69vcXfo77GjcW4mzQB6tXT3eNeX/36xgPxzZwpDj747be6W+hptGol/Z7azz4LvPyy2J3bHNHRwOef605u1a0rvs9ffjE82aBQiLcVLOz2YgDQoYPYXT4jQ/x9HT5c+LozZ4oj3efkGF8j7u+fBUFwRe3aiiL3oW/MGHFwPP2BEwuKjRUva1mxQrzsxNR146XRt6/YdX7zZvFxtWqG1/YD4q0RO3cGFi0q/vKIgnx9C7+cY/z4E6hdu5HUkMmO6PeWnDIlH4C0L4xERGVp5syZ6Ny5s/axv78/mjRpAkAshCdPnowdO3Zg27ZtGKcZUdqE4cOHY9CgQQCA999/H4sWLcKRI0fQtWtXk+ur1WqsXr0aixcvBgAMHDgQEydOxNWrVxEZGQkAmD17NiZOnIjx48drt2vZsiUA4Ndff8WRI0dw/vx51P6vMKhevbrk9+/h4YEvv/wSzs7O2mX6xXT16tWxaNEitGzZEunp6fD09MSSJUvg4+OD9evXQ/nfIFaaGNRqNf73v/9h9erVePO/61x//PFHZGdno3///pLjMxeLdKowatQwfOzlpbuW2NlZLAoB42umNev4+xfeQq9fBANAw4bi9OWXxeJJc/2r/v3eHRyASpWA1avFx76+4jXvgFiAK5Vi8evoKCA/X7z4t+D9xwcMMB2PvmHDgDlzxB4LgG60b/1bngFi8aa5xrhHD+OeBKbuVf/WW4W/7gsvGD4OC9PdgkvKCZZq1QyvUb96VTyxAIiFa3Cw4frr1olnOLdv347u3btr/9kW5umnxeKxIE0uPDyk31JOioJjJbz3nrTtCzL1eypoyhTjZWLOdpnMmSYXL79seiA1/QHpijJnjnnrFbRiBfDSS+J8aXsVlHBMHZPEnN0AwCK9PNO0pCuV+ZgyRQ0W6UTlk7u7tOO9JV/Xklq0aGHwOD09HdOnT8fPP/+MO3fuIC8vD1lZWcW2pDfWtKRBLHy9vb1x9+7dQtdPSEhARkYGunfvDgAICAhA586dsXLlSsyaNQt3797F7du30alTJ5PbJyYmokqVKtriuKQaNWpkUKADwPHjxzF9+nScOnUKjx49gvq/QXGuX7+O+vXrIzExEe3atSv0O+PgwYPx3nvv4dChQ2jdujVWr16N/v37w8PDo1SxFoVFOpGV+fiIA8MVp7C/89hYAdu3K1CzpgDAjFHITAgK0hXpRalUSbyF1zPPlOhlivTTT+Jt+ObOLd1+HPQu0imL7vzF3dWgIilwzCsz5gy+R2QtmiLdycmM2wIQkd1SKAr/LmZPChaOr7/+OhISEvDRRx+hevXqyM/Px4gRI4odVM34hL1CW9yasmLFCjx8+BBuel/O1Go1Tp8+jRkzZhgsN6W45x0cHCAUOFOvMnE9UsH3n5GRgdjYWMTGxmLNmjUIDAzE9evXERsbq81Bca8dGBiIZ555BqtWrUJkZCR27NiBfebciqoUeE06kZVt3Sq2/BZ3X+pevcRu5AVbOb/8Mh+DBp3Hzp3mjdBpyooV4j2qi4vh1Clx5O2RI0v8UoVq1ky8FVpR97c3R1iYeCmBv784tRZND7BXXrHea9iLKVPEyxPeflue1+/SRZwWNdYEkbVovsc6OXFwCCKyP3/88QeGDx+O3r17o1GjRggKCsK1a9cs+hoPHjzA1q1bsX79eiQmJmp/Tp48iUePHmHXrl3w8vJCREQEdhdyn9fGjRvj5s2b+Pvvv00+HxgYiKSkJINCPbHgLY9MuHDhAh48eIC5c+eiXbt2qFu3rlGPgMaNG+P33383WfRrvPjii9iwYQM+//xz1KhRA23atCn2tUuDLelEVta6tfF11KY4Oxt3ZwfEa+YHDPgbVavWLHEMtWoVfm24vsqVgX79SvwyZUKpFK/D19xCz1o+/lg8WaG5dKEimzlTHHBRrhbtKlXESxuKuh89kbVUrQrs2pWHw4ePAmgldzhERJLUqlULmzZtQlxcHARBwDvvvFNki3hJfPPNN6hUqRL69+8PRYEvC927d8eKFSvQtWtXTJ8+HaNHj0ZQUBC6deuGtLQ0/PHHH3j11Vfx1FNPoX379ujbty8WLFiAmjVr4sKFC1AoFOjatSs6dOiAe/fuYd68eejXrx927tyJHTt2wLuYLwdVq1aFs7MzFi9ejNGjR+Ps2bOYNWuWwTrjxo3D4sWLMXDgQEyaNAk+Pj44dOgQWrVqhVr/XQcbGxsLb29vzJ49GzNnzrRo/kxhSzoR2R13d3EgOWtychIHpbPmiQB7IneX8+Dgine3ArINHh5Ahw4CGjW6L3coRESSLViwAH5+fnjyySfRs2dPdOzYEc2aNbPoa6xcuRK9e/c2KtABoG/fvti2bRvu37+PYcOGYeHChVi6dCkaNGiAZ555Bv/o3SLlhx9+QMuWLTFo0CDUr18fb775JvLz8wEA9erVw9KlS7FkyRI0adIER44cMbgvfGECAwOxevVqfP/996hfvz7mzp2Ljz76yGCdSpUqYc+ePUhPT8dTTz2F5s2b44svvjDo8u/g4IDhw4cjPz8fQ4cOLWmqzMaWdCIiIiIiIjsyfPhwg9uIdejQweiabQCIiIjAnj17AIjXiKempmLixIlw0GuFKNj93dR+Ugq7zQmA0/q3Byqgf//+BqOgv/zyy3j55ZdNruvv74+VBW+5o2f06NEYrX/bJADvvPOOdn61ZjTmAgYNGqQdqV6j4Hts3LgxfvnlF6Nt9Xsd3Lp1C927d0doaGihMVoKi3QiIiIiIiIiEx4/fozTp09j7dq12LZtW5m8JjtyEhERkU1asmQJIiIi4OrqiqioKBw5ckTukIiIqIIZMmQIunbtitGjRxvcg96a2JJORERENmfDhg2Ij4/H8uXLERUVhYULFyI2NhYXL15EUFCQ3OEREVEF8dNPP8Hb29vgEgFrY0s6ERER2ZwFCxZg5MiReOGFF1C/fn0sX74c7u7uRV6vSEREVB7YREv6kiVL8OGHHyIpKQlNmjTB4sWL0apV8bc5Wb9+PQYNGoSePXtiS3E3gCYiIiK7kJubi+PHj2PSpEnaZQ4ODoiJicHBgwdNbpOTk4OcnBzt49TUVACASqUq8t635tBsX9r9VCTMmXTMmTSlyVdeXh4EQUB+fr7Fb0dmyzSDpQmCUKHed2lIzVl+fj4EQUBeXp7RZ1PKZ1X2Ir2k3dmuXbuG119/He3atSvDaImIiMja7t+/j/z8fAQHBxssDw4OxoULF0xuM2fOHMyYMcNo+a5du+Du7m6RuBISEiyyn4qEOZOOOZOmJPlSKBQIDQ3Fw4cP4eXlZYWobFtaWprcIdgdc3OWmZmJzMxM7N2716ioz8zMNPv1ZC/S9buzAcDy5cvx888/Y+XKlXj77bdNbpOfn48hQ4ZgxowZ+P3334u8JQDPrNsW5kw65kw65kw65kw6S+aMeS+9SZMmIT4+Xvs4NTUV4eHh6NKlC7y9vUu1b5VKhYSEBHTu3NngvrlUOOZMOuZMmtLmKzk5GampqXB1dYW7u7vJe3yXN4IgICMjAx4eHhXi/VqClJyp1WpkZGSgUqVKaNy4sdH6mjrUHLIW6SXpzgYAM2fORFBQEF588UX8/vvvRb4Gz6zbJuZMOuZMOuZMOuZMOkvkTMrZ9YogICAAjo6OSE5ONlienJyMkJAQk9u4uLjAxcXFaLlSqbRYwWPJfVUUzJl0zJk0Jc1X5cqV4ejoiPv371shKtskCAKysrLg5ubGIt1MUnPm4OCAypUrw9nZ2eg5KZ9TWYv0knRnO3DgAFasWIHExESzXoNn1m0LcyYdcyYdcyYdcyadJXMm5ex6ReDs7IzmzZtj9+7d6NWrFwCxhWL37t0YN26cvMERUbmg6fIeFBRUYXozqVQq7N+/H+3bt+ex3kxSc+bs7GyRUeBl7+4uRVpaGp5//nl88cUXCAgIMGsbnlm3TcyZdMyZdMyZdMyZdJbIGXNuLD4+HsOGDUOLFi3QqlUrLFy4EBkZGdrL44iILMHR0RGOjo5yh1EmHB0dkZeXB1dXVx53zCRXzmQt0qV2Z7t8+TKuXbuGuLg47TLNBflOTk64ePEiatSoYd2giYiIyOoGDBiAe/fuYerUqUhKSsITTzyBnTt3GvW+IyIiKm9kvU+6fnc2DU13tujoaKP169atizNnziAxMVH78+yzz+Lpp59GYmIiwsPDyzJ8IiIisqJx48bh33//RU5ODg4fPoyoqCi5QyIiIrI62bu7F9edbejQoahcuTLmzJkDV1dXNGzY0GB7X19fADBaTkRERERERGRvZC/Si+vOdv36dYtcfK+huSG9JQbpUalUyMzMRGpqKq/rMBNzJh1zJh1zJh1zJp0lc6Y5JmmOUVR6PN7LizmTjjmThvmSjjmTTq5jvUKoYN8Ibt68yW7xRERkk27cuIEqVarIHUa5wOM9ERHZInOO9RWuSFer1bh9+za8vLxKfX9Aze3cbty4UerbuVUUzJl0zJl0zJl0zJl0lsyZIAhIS0tDWFiYRXuPVWQ83suLOZOOOZOG+ZKOOZNOrmO97N3dy5qDg4PFWym8vb35QZeIOZOOOZOOOZOOOZPOUjnz8fGxQDSkweO9bWDOpGPOpGG+pGPOpCvrYz1P1xMRERERERHZCBbpRERERERERDaCRXopuLi4YNq0aXBxcZE7FLvBnEnHnEnHnEnHnEnHnFUc/F1Lx5xJx5xJw3xJx5xJJ1fOKtzAcURERERERES2ii3pRERERERERDaCRToRERERERGRjWCRTkRERERERGQjWKQTERERERER2QgW6aWwZMkSREREwNXVFVFRUThy5IjcIcli+vTpUCgUBj9169bVPp+dnY2xY8eiUqVK8PT0RN++fZGcnGywj+vXr6NHjx5wd3dHUFAQ3njjDeTl5ZX1W7Ga/fv3Iy4uDmFhYVAoFNiyZYvB84IgYOrUqQgNDYWbmxtiYmLwzz//GKzz8OFDDBkyBN7e3vD19cWLL76I9PR0g3VOnz6Ndu3awdXVFeHh4Zg3b56135rVFJez4cOHG33uunbtarBORcvZnDlz0LJlS3h5eSEoKAi9evXCxYsXDdax1N/jvn370KxZM7i4uKBmzZpYvXq1td+exZmTrw4dOhh9zkaPHm2wTkXJV0XFY70Oj/fF4/FeGh7rpeOxXjq7PN4LVCLr168XnJ2dhZUrVwp//fWXMHLkSMHX11dITk6WO7QyN23aNKFBgwbCnTt3tD/37t3TPj969GghPDxc2L17t3Ds2DGhdevWwpNPPql9Pi8vT2jYsKEQExMjnDx5Uti+fbsQEBAgTJo0SY63YxXbt28XJk+eLGzatEkAIGzevNng+blz5wo+Pj7Cli1bhFOnTgnPPvusEBkZKWRlZWnX6dq1q9CkSRPh0KFDwu+//y7UrFlTGDRokPb5x48fC8HBwcKQIUOEs2fPCuvWrRPc3NyEzz77rKzepkUVl7Nhw4YJXbt2NfjcPXz40GCdipaz2NhYYdWqVcLZs2eFxMREoXv37kLVqlWF9PR07TqW+Hu8cuWK4O7uLsTHxwvnzp0TFi9eLDg6Ogo7d+4s0/dbWubk66mnnhJGjhxp8Dl7/Pix9vmKlK+KiMd6QzzeF4/He2l4rJeOx3rp7PF4zyK9hFq1aiWMHTtW+zg/P18ICwsT5syZI2NU8pg2bZrQpEkTk8+lpKQISqVS+P7777XLzp8/LwAQDh48KAiC+A/awcFBSEpK0q6zbNkywdvbW8jJybFq7HIoeBBSq9VCSEiI8OGHH2qXpaSkCC4uLsK6desEQRCEc+fOCQCEo0ePatfZsWOHoFAohFu3bgmCIAhLly4V/Pz8DHL21ltvCXXq1LHyO7K+wg7cPXv2LHSbip4zQRCEu3fvCgCE3377TRAEy/09vvnmm0KDBg0MXmvAgAFCbGystd+SVRXMlyCIB+3x48cXuk1FzldFwGO9IR7vpeHxXhoe60uGx3rp7OF4z+7uJZCbm4vjx48jJiZGu8zBwQExMTE4ePCgjJHJ559//kFYWBiqV6+OIUOG4Pr16wCA48ePQ6VSGeSqbt26qFq1qjZXBw8eRKNGjRAcHKxdJzY2Fqmpqfjrr7/K9o3I4OrVq0hKSjLIkY+PD6Kiogxy5OvrixYtWmjXiYmJgYODAw4fPqxdp3379nB2dtauExsbi4sXL+LRo0dl9G7K1r59+xAUFIQ6derglVdewYMHD7TPMWfA48ePAQD+/v4ALPf3ePDgQYN9aNax9/9/BfOlsWbNGgQEBKBhw4aYNGkSMjMztc9V5HyVdzzWm8bjfcnxeF8yPNYXjcd66ezheO8keQvC/fv3kZ+fb/BLAoDg4GBcuHBBpqjkExUVhdWrV6NOnTq4c+cOZsyYgXbt2uHs2bNISkqCs7MzfH19DbYJDg5GUlISACApKclkLjXPlXea92gqB/o5CgoKMnjeyckJ/v7+ButERkYa7UPznJ+fn1Xil0vXrl3Rp08fREZG4vLly3jnnXfQrVs3HDx4EI6OjhU+Z2q1GhMmTECbNm3QsGFDALDY32Nh66SmpiIrKwtubm7WeEtWZSpfADB48GBUq1YNYWFhOH36NN566y1cvHgRmzZtAlBx81UR8FhvjMf70uHxXjoe64vGY7109nK8Z5FOpdatWzftfOPGjREVFYVq1arhu+++s9s/YLJ9AwcO1M43atQIjRs3Ro0aNbBv3z506tRJxshsw9ixY3H27FkcOHBA7lDsQmH5GjVqlHa+UaNGCA0NRadOnXD58mXUqFGjrMMkkhWP91TWeKwvGo/10tnL8Z7d3UsgICAAjo6ORqMkJicnIyQkRKaobIevry9q166NS5cuISQkBLm5uUhJSTFYRz9XISEhJnOpea6807zHoj5PISEhuHv3rsHzeXl5ePjwIfP4n+rVqyMgIACXLl0CULFzNm7cOPz000/Yu3cvqlSpol1uqb/Hwtbx9va2yy/qheXLlKioKAAw+JxVtHxVFDzWF4/He2l4vC89Hut1eKyXzp6O9yzSS8DZ2RnNmzfH7t27tcvUajV2796N6OhoGSOzDenp6bh8+TJCQ0PRvHlzKJVKg1xdvHgR169f1+YqOjoaZ86cMfgnm5CQAG9vb9SvX7/M4y9rkZGRCAkJMchRamoqDh8+bJCjlJQUHD9+XLvOnj17oFartf9EoqOjsX//fqhUKu06CQkJqFOnjl135TLXzZs38eDBA4SGhgKomDkTBAHjxo3D5s2bsWfPHqPufZb6e4yOjjbYh2Yde/v/V1y+TElMTAQAg89ZRclXRcNjffF4vJeGx/vS47Gex/qSsMvjveSh5kgQBPG2LC4uLsLq1auFc+fOCaNGjRJ8fX0NRvyrKCZOnCjs27dPuHr1qvDHH38IMTExQkBAgHD37l1BEMTbQFStWlXYs2ePcOzYMSE6OlqIjo7Wbq+5pUGXLl2ExMREYefOnUJgYGC5uiVLWlqacPLkSeHkyZMCAGHBggXCyZMnhX///VcQBPGWLL6+vsLWrVuF06dPCz179jR5S5amTZsKhw8fFg4cOCDUqlXL4BYjKSkpQnBwsPD8888LZ8+eFdavXy+4u7vb7S1GispZWlqa8PrrrwsHDx4Url69Kvz6669Cs2bNhFq1agnZ2dnafVS0nL3yyiuCj4+PsG/fPoNbiGRmZmrXscTfo+YWI2+88YZw/vx5YcmSJXZ5W5bi8nXp0iVh5syZwrFjx4SrV68KW7duFapXry60b99eu4+KlK+KiMd6QzzeF4/He2l4rJeOx3rp7PF4zyK9FBYvXixUrVpVcHZ2Flq1aiUcOnRI7pBkMWDAACE0NFRwdnYWKleuLAwYMEC4dOmS9vmsrCxhzJgxgp+fn+Du7i707t1buHPnjsE+rl27JnTr1k1w+//27iYkqj2M4/hvLB1mpoSxmWxqUYgiJlRQEZYFNWAaBMZEFENMLhLNpEW1iLJsEbSIajcglJsiwaCQyqLClRAF0SQ0uasWIb0uHCMJfO6iy1wO3tutezWPM98PHJhz/ufl+f9heM7DefP5LBQK2eHDh+3bt2+/uyvTZmBgwCRNmhKJhJl9/yxLR0eHlZaWmtfrtWg0asPDw459fPz40fbs2WPz5s2z4uJia2pqstHRUcc6qVTKamtrzev12pIlS+zs2bO/q4tT7kdj9uXLF6urq7NwOGyFhYW2dOlS279//6QT53wbs78bL0nW3d2dXWeq/o8DAwO2atUqKyoqsrKyMscxZot/G683b97Ypk2brKSkxLxer5WXl9vRo0cd3001y5/xylfk+r+Q7/8d+f7XkOt/Hbn+183GfO/5M3AAAAAAADDDeCYdAAAAAACXoEgHAAAAAMAlKNIBAAAAAHAJinQAAAAAAFyCIh0AAAAAAJegSAcAAAAAwCUo0gEAAAAAcAmKdAAAAAAAXIIiHcC083g8unnz5kyHAQAAphH5HpgaFOlAjtu3b588Hs+kqb6+fqZDAwAAU4R8D+SOuTMdAIDpV19fr+7ubscyr9c7Q9EAAIDpQL4HcgNX0oE84PV6tWjRIscUDAYlfb81LZlMqqGhQT6fT2VlZbp+/bpj+6GhIW3ZskU+n08LFixQc3OzMpmMY53Lly+rurpaXq9XkUhEBw8edLR/+PBBO3bskN/vV0VFhfr6+rJtnz9/VjweVzgcls/nU0VFxaSTDAAA8GPkeyA3UKQDUEdHh2KxmFKplOLxuHbv3q10Oi1JGhsb09atWxUMBvXkyRP19vbqwYMHjqScTCbV1tam5uZmDQ0Nqa+vT+Xl5Y5jnD59Wrt27dLz58+1bds2xeNxffr0KXv8Fy9eqL+/X+l0WslkUqFQ6PcNAAAAeYB8D8wSBiCnJRIJmzNnjgUCAcd05swZMzOTZC0tLY5t1q1bZ62trWZm1tXVZcFg0DKZTLb99u3bVlBQYCMjI2ZmtnjxYjt+/Pg/xiDJTpw4kZ3PZDImyfr7+83MbPv27dbU1DQ1HQYAIA+R74HcwTPpQB7YvHmzksmkY1lJSUn2d01NjaOtpqZGz549kySl02mtXLlSgUAg275hwwZNTExoeHhYHo9Hb9++VTQa/WEMK1asyP4OBAIqLi7Wu3fvJEmtra2KxWJ6+vSp6urq1NjYqPXr1/+nvgIAkK/I90BuoEgH8kAgEJh0O9pU8fl8P7VeYWGhY97j8WhiYkKS1NDQoNevX+vOnTu6f/++otGo2tradO7cuSmPFwCAXEW+B3IDz6QD0KNHjybNV1VVSZKqqqqUSqU0NjaWbR8cHFRBQYEqKys1f/58LVu2TA8fPvxfMYTDYSUSCV25ckUXL15UV1fX/9ofAABwIt8DswNX0oE8MD4+rpGREceyuXPnZl/W0tvbqzVr1qi2tlZXr17V48ePdenSJUlSPB7XqVOnlEgk1NnZqffv36u9vV179+5VaWmpJKmzs1MtLS1auHChGhoaNDo6qsHBQbW3t/9UfCdPntTq1atVXV2t8fFx3bp1K3vSAAAAfg75HsgNFOlAHrh7964ikYhjWWVlpV6+fCnp+5tYe3p6dODAAUUiEV27dk3Lly+XJPn9ft27d0+HDh3S2rVr5ff7FYvFdP78+ey+EomEvn79qgsXLujIkSMKhULauXPnT8dXVFSkY8eO6dWrV/L5fNq4caN6enqmoOcAAOQP8j2QGzxmZjMdBICZ4/F4dOPGDTU2Ns50KAAAYJqQ74HZg2fSAQAAAABwCYp0AAAAAABcgtvdAQAAAABwCa6kAwAAAADgEhTpAAAAAAC4BEU6AAAAAAAuQZEOAAAAAIBLUKQDAAAAAOASFOkAAAAAALgERToAAAAAAC5BkQ4AAAAAgEv8AWzvruKEYdyZAAAAAElFTkSuQmCC"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1741170376689
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        X_batch = batch['X']\n",
        "        y_batch = batch['y']\n",
        "\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move data to device\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Test Accuracy: 90.69%\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1740092046232
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report and confusion matrix\n",
        "model.eval()\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        X_batch = batch['X']\n",
        "        y_batch = batch['y']\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        true_labels.extend(y_batch.cpu().numpy())\n",
        "        predicted_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "# Classification Report\n",
        "print(\"Classification Report:\")\n",
        "report = classification_report(true_labels, predicted_labels, target_names=train_loader.dataset.idx_to_gloss.values(), zero_division=0)\n",
        "print(report)\n",
        "\n",
        "# Confusion Matrix (optional for large datasets)\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Visualizing diagonal counts for correct predictions\n",
        "diag_counts = np.diag(conf_matrix)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(range(len(diag_counts)), diag_counts, color='blue')\n",
        "plt.xlabel(\"Class Index\")\n",
        "plt.ylabel(\"Correct Predictions\")\n",
        "plt.title(\"Correct Predictions per Class (Diagonal of Confusion Matrix)\")\n",
        "plt.show()\n",
        "\n",
        "# Heatmap for confusion matrix (cropped or full)\n",
        "plt.figure(figsize=(15, 12))\n",
        "sns.heatmap(conf_matrix[:50, :50], annot=False, fmt='d', cmap=\"YlGnBu\")\n",
        "plt.title(\"Confusion Matrix (First 50 Classes)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Classification Report:\n"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DistillationNPYDataset' object has no attribute 'idx_to_gloss'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Classification Report\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report(true_labels, predicted_labels, target_names\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midx_to_gloss\u001b[49m\u001b[38;5;241m.\u001b[39mvalues(), zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(report)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Confusion Matrix (optional for large datasets)\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DistillationNPYDataset' object has no attribute 'idx_to_gloss'"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1740021469063
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}